{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from numpy import set_printoptions\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "pd.options.display.max_columns=None\n",
    "import seaborn as sns \n",
    "from pandas import read_csv\n",
    "import io\n",
    "import base64\n",
    "import json\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.drawing.image import Image as XLImage\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "#from mlens.ensemble import SuperLearner\n",
    "\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CARGUE DE DATOS Y CONEXIÓN A DRIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=899973764197-biu188dkvsgi2al0fh29udm7keak0lh0.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A63859%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.readonly&state=hjT4QdUrDWgxDL7rBy0cLA2QUVwVNh&access_type=offline\n",
      "Descargando Limpieza de datos 1 UD.ipynb: 100%\n",
      "Descargando industrial10.csv: 100%\n",
      "Descargando industrial9.csv: 100%\n",
      "Descargando industrial8.csv: 100%\n",
      "Descargando industrial7.csv: 100%\n",
      "Descargando industrial6.csv: 100%\n",
      "Descargando industrial5.csv: 100%\n",
      "Descargando industrial3.csv: 100%\n",
      "Descargando industrial4.csv: 100%\n",
      "Descargando industrial2.csv: 100%\n",
      "Descargando industrial1.csv: 100%\n",
      "Descarga completa\n",
      "Archivos descargados:\n",
      "industrial1.csv\n",
      "industrial10.csv\n",
      "industrial2.csv\n",
      "industrial3.csv\n",
      "industrial4.csv\n",
      "industrial5.csv\n",
      "industrial6.csv\n",
      "industrial7.csv\n",
      "industrial8.csv\n",
      "industrial9.csv\n",
      "Limpieza de datos 1 UD.ipynb\n"
     ]
    }
   ],
   "source": [
    "SCOPES = ['https://www.googleapis.com/auth/drive.readonly']\n",
    "\n",
    "creds = None\n",
    "if os.path.exists('token.json'):\n",
    "    creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "if not creds or not creds.valid:\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "        creds.refresh(Request())\n",
    "    else:\n",
    "        flow = InstalledAppFlow.from_client_secrets_file('C:/Users/Intevo/Desktop/UNIVERSIDAD DISTRITAL PROYECTO FOLDER/credentials.json', SCOPES) # Reemplazar con la ruta correcta\n",
    "        creds = flow.run_local_server(port=0)\n",
    "    with open('C:/Users/Intevo/Desktop/UNIVERSIDAD DISTRITAL PROYECTO FOLDER/token.json', 'w') as token:\n",
    "        token.write(creds.to_json())\n",
    "        \n",
    "# Crear una instancia de la API de Drive\n",
    "drive_service = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "# ID de la carpeta de Google Drive\n",
    "folder_id = '1hQeetmO4XIObUefS_nzePqKqq3VksUEC'\n",
    "\n",
    "# Ruta de destino para guardar los archivos descargados\n",
    "save_path = 'C:/Users/Intevo/Desktop/UNIVERSIDAD DISTRITAL PROYECTO FOLDER/UNIVERSIDAD-DISTRITAL-PROYECTO/MÓDULO ANALÍTICA PREDICTIVA/DATOS'  # Reemplazar con la ruta deseada\n",
    "\n",
    "# Función para descargar archivos de la carpeta de Drive\n",
    "def download_folder(folder_id, save_path):\n",
    "    results = drive_service.files().list(\n",
    "        q=f\"'{folder_id}' in parents and trashed=false\",\n",
    "        fields='files(id, name)').execute()\n",
    "    items = results.get('files', [])\n",
    "    for item in items:\n",
    "        file_id = item['id']\n",
    "        file_name = item['name']\n",
    "        request = drive_service.files().get_media(fileId=file_id)\n",
    "        fh = io.FileIO(os.path.join(save_path, file_name), 'wb')\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "        done = False\n",
    "        while done is False:\n",
    "            status, done = downloader.next_chunk()\n",
    "            print(f\"Descargando {file_name}: {int(status.progress() * 100)}%\")\n",
    "    print(\"Descarga completa\")\n",
    "\n",
    "# Descargar archivos de la carpeta\n",
    "download_folder(folder_id, save_path)\n",
    "\n",
    "# Listar archivos descargados\n",
    "files = os.listdir(save_path)\n",
    "print(\"Archivos descargados:\")\n",
    "for file in files:\n",
    "    print(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nvariables_por_carrera = {\\n    'industrial': {\\n        '1': ['PG_ICFES', 'CON_MAT_ICFES', 'FISICA_ICFES','QUIMICA_ICFES','IDIOMA_ICFES','LOCALIDAD','RENDIMIENTO_UNO', 'PROMEDIO_UNO'],\\n        '2': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'FISICA_ICFES', 'BIOLOGIA_ICFES', 'IDIOMA_ICFES', 'LOCALIDAD', 'PROMEDIO_UNO', 'CAR_UNO', 'NCC_UNO', 'NAA_UNO', 'NOTA_DIFERENCIAL', 'NOTA_DIBUJO', 'NOTA_QUIMICA', 'NOTA_CFJC', 'NOTA_TEXTOS', 'NOTA_SEMINARIO', 'NOTA_EE_UNO','RENDIMIENTO_DOS', 'PROMEDIO_DOS'],\\n        '3': ['PROMEDIO_UNO', 'NAA_UNO', 'NOTA_DIFERENCIAL', 'NOTA_DIBUJO', 'NOTA_TEXTOS', 'NOTA_EE_UNO', 'PROMEDIO_DOS', 'NCC_DOS', 'NCA_DOS', 'NAA_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_PBASICA', 'NOTA_EE_DOS', 'RENDIMIENTO_TRES', 'PROMEDIO_TRES'],\\n        '4': ['PROMEDIO_UNO', 'NOTA_EE_UNO', 'PROMEDIO_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'NAA_TRES', 'NOTA_MULTIVARIADO', 'NOTA_ESTADISTICA_UNO', 'NOTA_TERMODINAMICA', 'NOTA_TGS', 'NOTA_EE_TRES','RENDIMIENTO_CUATRO', 'PROMEDIO_CUATRO'],\\n        '5': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_EE_DOS','PROMEDIO_TRES', 'NAA_TRES', 'NOTA_MULTIVARIADO', 'NOTA_TERMODINAMICA', 'NOTA_ECUACIONES', 'NOTA_ESTADISTICA_DOS', 'NOTA_FISICA_DOS', 'NOTA_MECANICA', 'NOTA_PROCESOSQ', 'RENDIMIENTO_CINCO', 'RENDIMIENTO_CINCO'],\\n        '6': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_ADMINISTRACION', 'NOTA_LENGUA_UNO', 'NOTA_EI_UNO', 'NOTA_EI_DOS', 'RENDIMIENTO_SEIS', 'PROMEDIO_SEIS'],\\n        '7': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_LENGUA_UNO', 'NOTA_EI_DOS', 'PROMEDIO_SEIS', 'NCA_SEIS', 'NOTA_PLINEAL', 'NOTA_DISE O', 'NOTA_EI_TRES','RENDIMIENTO_SIETE', 'PROMEDIO_SIETE'],\\n        '8': ['PROMEDIO_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_LENGUA_UNO','PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'RENDIMIENTO_OCHO', 'PROMEDIO_OCHO'],\\n        '9': ['PROMEDIO_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'PROMEDIO_OCHO', 'NCC_OCHO', 'NOTA_LOG_UNO', 'NOTA_GOPERACIONES','NOTA_CALIDAD_DOS', 'NOTA_LENGUA_DOS', 'NOTA_CONTEXTO', 'RENDIMIENTO_NUEVE', 'PROMEDIO_NUEVE'],\\n        '10': ['PROMEDIO_SEIS', 'PROMEDIO_SIETE', 'PROMEDIO_OCHO', 'NOTA_CALIDAD_DOS', 'PROMEDIO_NUEVE', 'NAA_NUEVE', 'NOTA_GRADO_UNO', 'NOTA_LOG_DOS', 'NOTA_FINANZAS', 'NOTA_HISTORIA', 'RENDIMIENTO_DIEZ', 'PROMEDIO_DIEZ']\\n    },\\n    'sistemas': {\\n        '1': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'FISICA_ICFES', 'QUIMICA_ICFES', 'IDIOMA_ICFES', 'LOCALIDAD', 'RENDIMIENTO_UNO', 'PROMEDIO_UNO'],\\n        '2': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'IDIOMA_ICFES', 'PROMEDIO_UNO', 'NOTA_DIFERENCIAL', 'NOTA_PROG_BASICA', 'NOTA_CATEDRA_FJC', 'NOTA_TEXTOS', 'NOTA_SEMINARIO', 'NOTA_CATEDRA_DEM', 'NOTA_CATEDRA_CON', 'NOTA_LOGICA', 'RENDIMIENTO_DOS', 'PROMEDIO_DOS'],\\n        '3': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'IDIOMA_ICFES', 'PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_PROG_BASICA', 'NOTA_TEXTOS', 'NOTA_CATEDRA_DEM', 'NOTA_INTEGRAL', 'NOTA_PROG_ORIENTADA', 'NOTA_ETICA', 'RENDIMIENTO_TRES', 'PROMEDIO_TRES'],\\n        '4': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'IDIOMA_ICFES', 'PROMEDIO_UNO', 'PROMEDIO_DOS', 'PROMEDIO_TRES', 'NOTA_PROG_BASICA', 'NOTA_TEXTOS', 'NOTA_CATEDRA_DEM', 'NOTA_INTEGRAL', 'NOTA_PROG_ORIENTADA', 'NOTA_ETICA', 'NOTA_FISICA_DOS', 'NOTA_TGS', 'NOTA_PROG_AVANZADA', 'RENDIMIENTO_CUATRO', 'PROMEDIO_CUATRO'],\\n        '5': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NAA_TRES', 'NOTA_MULTIVARIADO', 'NOTA_TERMODINAMICA', 'NOTA_ECUACIONES', 'NOTA_ESTADISTICA_DOS', 'NOTA_FISICA_DOS', 'NOTA_MECANICA', 'NOTA_PROCESOSQ', 'RENDIMIENTO_CINCO', 'PROMEDIO_CINCO'],\\n        '6': ['PROMEDIO_UNO', 'NOTA_EE_UNO', 'PROMEDIO_DOS', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_ECONOMIA_UNO', 'NOTA_FISICA_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_ADMINISTRACION', 'NOTA_LENGUA_UNO', 'NOTA_EI_UNO', 'NOTA_EI_DOS', 'RENDIMIENTO_SEIS', 'PROMEDIO_SEIS'],\\n        '7': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_LENGUA_UNO', 'NOTA_EI_DOS', 'PROMEDIO_SEIS', 'NCA_SEIS', 'NOTA_PLINEAL', 'NOTA_DISE O', 'NOTA_EI_TRES', 'RENDIMIENTO_SIETE', 'PROMEDIO_SIETE'],\\n        '8': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_LENGUA_UNO', 'PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'RENDIMIENTO_OCHO', 'PROMEDIO_OCHO'],\\n        '9': ['PROMEDIO_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'PROMEDIO_OCHO', 'NCC_OCHO', 'NOTA_LOG_UNO', 'NOTA_GOPERACIONES', 'NOTA_CALIDAD_DOS', 'NOTA_LENGUA_DOS', 'NOTA_CONTEXTO', 'RENDIMIENTO_NUEVE', 'PROMEDIO_NUEVE'],\\n        '10': ['PROMEDIO_SEIS', 'PROMEDIO_SIETE', 'PROMEDIO_OCHO', 'NOTA_CALIDAD_DOS', 'PROMEDIO_NUEVE', 'NAA_NUEVE', 'NOTA_GRADO_UNO', 'NOTA_LOG_DOS', 'NOTA_FINANZAS', 'NOTA_HISTORIA', 'RENDIMIENTO_DIEZ', 'PROMEDIO_DIEZ']\\n    },\\n    'catastral': {\\n        '1': ['variable1_catastral', 'variable2_catastral', 'variable3_catastral'],\\n        '2': ['variable4_catastral', 'variable5_catastral', 'variable6_catastral']\\n    }\\n}\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "variables_por_carrera = {\n",
    "    'industrial': {\n",
    "        '1': ['PG_ICFES', 'CON_MAT_ICFES', 'FISICA_ICFES','QUIMICA_ICFES','IDIOMA_ICFES','LOCALIDAD','RENDIMIENTO_UNO', 'PROMEDIO_UNO'],\n",
    "        '2': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'FISICA_ICFES', 'BIOLOGIA_ICFES', 'IDIOMA_ICFES', 'LOCALIDAD', 'PROMEDIO_UNO', 'CAR_UNO', 'NCC_UNO', 'NAA_UNO', 'NOTA_DIFERENCIAL', 'NOTA_DIBUJO', 'NOTA_QUIMICA', 'NOTA_CFJC', 'NOTA_TEXTOS', 'NOTA_SEMINARIO', 'NOTA_EE_UNO','RENDIMIENTO_DOS', 'PROMEDIO_DOS'],\n",
    "        '3': ['PROMEDIO_UNO', 'NAA_UNO', 'NOTA_DIFERENCIAL', 'NOTA_DIBUJO', 'NOTA_TEXTOS', 'NOTA_EE_UNO', 'PROMEDIO_DOS', 'NCC_DOS', 'NCA_DOS', 'NAA_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_PBASICA', 'NOTA_EE_DOS', 'RENDIMIENTO_TRES', 'PROMEDIO_TRES'],\n",
    "        '4': ['PROMEDIO_UNO', 'NOTA_EE_UNO', 'PROMEDIO_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'NAA_TRES', 'NOTA_MULTIVARIADO', 'NOTA_ESTADISTICA_UNO', 'NOTA_TERMODINAMICA', 'NOTA_TGS', 'NOTA_EE_TRES','RENDIMIENTO_CUATRO', 'PROMEDIO_CUATRO'],\n",
    "        '5': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_EE_DOS','PROMEDIO_TRES', 'NAA_TRES', 'NOTA_MULTIVARIADO', 'NOTA_TERMODINAMICA', 'NOTA_ECUACIONES', 'NOTA_ESTADISTICA_DOS', 'NOTA_FISICA_DOS', 'NOTA_MECANICA', 'NOTA_PROCESOSQ', 'RENDIMIENTO_CINCO', 'RENDIMIENTO_CINCO'],\n",
    "        '6': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_ADMINISTRACION', 'NOTA_LENGUA_UNO', 'NOTA_EI_UNO', 'NOTA_EI_DOS', 'RENDIMIENTO_SEIS', 'PROMEDIO_SEIS'],\n",
    "        '7': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_LENGUA_UNO', 'NOTA_EI_DOS', 'PROMEDIO_SEIS', 'NCA_SEIS', 'NOTA_PLINEAL', 'NOTA_DISE O', 'NOTA_EI_TRES','RENDIMIENTO_SIETE', 'PROMEDIO_SIETE'],\n",
    "        '8': ['PROMEDIO_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_LENGUA_UNO','PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'RENDIMIENTO_OCHO', 'PROMEDIO_OCHO'],\n",
    "        '9': ['PROMEDIO_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'PROMEDIO_OCHO', 'NCC_OCHO', 'NOTA_LOG_UNO', 'NOTA_GOPERACIONES','NOTA_CALIDAD_DOS', 'NOTA_LENGUA_DOS', 'NOTA_CONTEXTO', 'RENDIMIENTO_NUEVE', 'PROMEDIO_NUEVE'],\n",
    "        '10': ['PROMEDIO_SEIS', 'PROMEDIO_SIETE', 'PROMEDIO_OCHO', 'NOTA_CALIDAD_DOS', 'PROMEDIO_NUEVE', 'NAA_NUEVE', 'NOTA_GRADO_UNO', 'NOTA_LOG_DOS', 'NOTA_FINANZAS', 'NOTA_HISTORIA', 'RENDIMIENTO_DIEZ', 'PROMEDIO_DIEZ']\n",
    "    },\n",
    "    'sistemas': {\n",
    "        '1': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'FISICA_ICFES', 'QUIMICA_ICFES', 'IDIOMA_ICFES', 'LOCALIDAD', 'RENDIMIENTO_UNO', 'PROMEDIO_UNO'],\n",
    "        '2': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'IDIOMA_ICFES', 'PROMEDIO_UNO', 'NOTA_DIFERENCIAL', 'NOTA_PROG_BASICA', 'NOTA_CATEDRA_FJC', 'NOTA_TEXTOS', 'NOTA_SEMINARIO', 'NOTA_CATEDRA_DEM', 'NOTA_CATEDRA_CON', 'NOTA_LOGICA', 'RENDIMIENTO_DOS', 'PROMEDIO_DOS'],\n",
    "        '3': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'IDIOMA_ICFES', 'PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_PROG_BASICA', 'NOTA_TEXTOS', 'NOTA_CATEDRA_DEM', 'NOTA_INTEGRAL', 'NOTA_PROG_ORIENTADA', 'NOTA_ETICA', 'RENDIMIENTO_TRES', 'PROMEDIO_TRES'],\n",
    "        '4': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'IDIOMA_ICFES', 'PROMEDIO_UNO', 'PROMEDIO_DOS', 'PROMEDIO_TRES', 'NOTA_PROG_BASICA', 'NOTA_TEXTOS', 'NOTA_CATEDRA_DEM', 'NOTA_INTEGRAL', 'NOTA_PROG_ORIENTADA', 'NOTA_ETICA', 'NOTA_FISICA_DOS', 'NOTA_TGS', 'NOTA_PROG_AVANZADA', 'RENDIMIENTO_CUATRO', 'PROMEDIO_CUATRO'],\n",
    "        '5': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NAA_TRES', 'NOTA_MULTIVARIADO', 'NOTA_TERMODINAMICA', 'NOTA_ECUACIONES', 'NOTA_ESTADISTICA_DOS', 'NOTA_FISICA_DOS', 'NOTA_MECANICA', 'NOTA_PROCESOSQ', 'RENDIMIENTO_CINCO', 'PROMEDIO_CINCO'],\n",
    "        '6': ['PROMEDIO_UNO', 'NOTA_EE_UNO', 'PROMEDIO_DOS', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_ECONOMIA_UNO', 'NOTA_FISICA_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_ADMINISTRACION', 'NOTA_LENGUA_UNO', 'NOTA_EI_UNO', 'NOTA_EI_DOS', 'RENDIMIENTO_SEIS', 'PROMEDIO_SEIS'],\n",
    "        '7': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_LENGUA_UNO', 'NOTA_EI_DOS', 'PROMEDIO_SEIS', 'NCA_SEIS', 'NOTA_PLINEAL', 'NOTA_DISE O', 'NOTA_EI_TRES', 'RENDIMIENTO_SIETE', 'PROMEDIO_SIETE'],\n",
    "        '8': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_LENGUA_UNO', 'PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'RENDIMIENTO_OCHO', 'PROMEDIO_OCHO'],\n",
    "        '9': ['PROMEDIO_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'PROMEDIO_OCHO', 'NCC_OCHO', 'NOTA_LOG_UNO', 'NOTA_GOPERACIONES', 'NOTA_CALIDAD_DOS', 'NOTA_LENGUA_DOS', 'NOTA_CONTEXTO', 'RENDIMIENTO_NUEVE', 'PROMEDIO_NUEVE'],\n",
    "        '10': ['PROMEDIO_SEIS', 'PROMEDIO_SIETE', 'PROMEDIO_OCHO', 'NOTA_CALIDAD_DOS', 'PROMEDIO_NUEVE', 'NAA_NUEVE', 'NOTA_GRADO_UNO', 'NOTA_LOG_DOS', 'NOTA_FINANZAS', 'NOTA_HISTORIA', 'RENDIMIENTO_DIEZ', 'PROMEDIO_DIEZ']\n",
    "    },\n",
    "    'catastral': {\n",
    "        '1': ['variable1_catastral', 'variable2_catastral', 'variable3_catastral'],\n",
    "        '2': ['variable4_catastral', 'variable5_catastral', 'variable6_catastral']\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_por_carrera = {\n",
    "    'industrial': {\n",
    "        '1': ['PG_ICFES', 'CON_MAT_ICFES', 'FISICA_ICFES','QUIMICA_ICFES','IDIOMA_ICFES','LOCALIDAD','RENDIMIENTO_UNO'],\n",
    "        '2': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'FISICA_ICFES', 'BIOLOGIA_ICFES', 'IDIOMA_ICFES', 'LOCALIDAD', 'PROMEDIO_UNO', 'CAR_UNO', 'NCC_UNO', 'NAA_UNO', 'NOTA_DIFERENCIAL', 'NOTA_DIBUJO', 'NOTA_QUIMICA', 'NOTA_CFJC', 'NOTA_TEXTOS', 'NOTA_SEMINARIO', 'NOTA_EE_UNO','RENDIMIENTO_DOS'],\n",
    "        '3': ['PROMEDIO_UNO', 'NAA_UNO', 'NOTA_DIFERENCIAL', 'NOTA_DIBUJO', 'NOTA_TEXTOS', 'NOTA_EE_UNO', 'PROMEDIO_DOS', 'NCC_DOS', 'NCA_DOS', 'NAA_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_PBASICA', 'NOTA_EE_DOS', 'RENDIMIENTO_TRES'],\n",
    "        '4': ['PROMEDIO_UNO', 'NOTA_EE_UNO', 'PROMEDIO_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'NAA_TRES', 'NOTA_MULTIVARIADO', 'NOTA_ESTADISTICA_UNO', 'NOTA_TERMODINAMICA', 'NOTA_TGS', 'NOTA_EE_TRES','RENDIMIENTO_CUATRO'],\n",
    "        '5': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_EE_DOS','PROMEDIO_TRES', 'NAA_TRES', 'NOTA_MULTIVARIADO', 'NOTA_TERMODINAMICA', 'NOTA_ECUACIONES', 'NOTA_ESTADISTICA_DOS', 'NOTA_FISICA_DOS', 'NOTA_MECANICA', 'NOTA_PROCESOSQ', 'RENDIMIENTO_CINCO', 'RENDIMIENTO_CINCO'],\n",
    "        '6': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_ADMINISTRACION', 'NOTA_LENGUA_UNO', 'NOTA_EI_UNO', 'NOTA_EI_DOS', 'RENDIMIENTO_SEIS'],\n",
    "        '7': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_LENGUA_UNO', 'NOTA_EI_DOS', 'PROMEDIO_SEIS', 'NCA_SEIS', 'NOTA_PLINEAL', 'NOTA_DISE O', 'NOTA_EI_TRES','RENDIMIENTO_SIETE'],\n",
    "        '8': ['PROMEDIO_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_LENGUA_UNO','PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'RENDIMIENTO_OCHO'],\n",
    "        '9': ['PROMEDIO_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'PROMEDIO_OCHO', 'NCC_OCHO', 'NOTA_LOG_UNO', 'NOTA_GOPERACIONES','NOTA_CALIDAD_DOS', 'NOTA_LENGUA_DOS', 'NOTA_CONTEXTO', 'RENDIMIENTO_NUEVE'],\n",
    "        '10': ['PROMEDIO_SEIS', 'PROMEDIO_SIETE', 'PROMEDIO_OCHO', 'NOTA_CALIDAD_DOS', 'PROMEDIO_NUEVE', 'NAA_NUEVE', 'NOTA_GRADO_UNO', 'NOTA_LOG_DOS', 'NOTA_FINANZAS', 'NOTA_HISTORIA', 'RENDIMIENTO_DIEZ']\n",
    "    },\n",
    "    'sistemas': {\n",
    "        '1': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'FISICA_ICFES', 'QUIMICA_ICFES', 'IDIOMA_ICFES', 'LOCALIDAD', 'RENDIMIENTO_UNO'],\n",
    "        '2': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'IDIOMA_ICFES', 'PROMEDIO_UNO', 'NOTA_DIFERENCIAL', 'NOTA_PROG_BASICA', 'NOTA_CATEDRA_FJC', 'NOTA_TEXTOS', 'NOTA_SEMINARIO', 'NOTA_CATEDRA_DEM', 'NOTA_CATEDRA_CON', 'NOTA_LOGICA', 'RENDIMIENTO_DOS'],\n",
    "        '3': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'IDIOMA_ICFES', 'PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_PROG_BASICA', 'NOTA_TEXTOS', 'NOTA_CATEDRA_DEM', 'NOTA_INTEGRAL', 'NOTA_PROG_ORIENTADA', 'NOTA_ETICA', 'RENDIMIENTO_TRES'],\n",
    "        '4': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'IDIOMA_ICFES', 'PROMEDIO_UNO', 'PROMEDIO_DOS', 'PROMEDIO_TRES', 'NOTA_PROG_BASICA', 'NOTA_TEXTOS', 'NOTA_CATEDRA_DEM', 'NOTA_INTEGRAL', 'NOTA_PROG_ORIENTADA', 'NOTA_ETICA', 'NOTA_FISICA_DOS', 'NOTA_TGS', 'NOTA_PROG_AVANZADA', 'RENDIMIENTO_CUATRO'],\n",
    "        '5': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NAA_TRES', 'NOTA_MULTIVARIADO', 'NOTA_TERMODINAMICA', 'NOTA_ECUACIONES', 'NOTA_ESTADISTICA_DOS', 'NOTA_FISICA_DOS', 'NOTA_MECANICA', 'NOTA_PROCESOSQ', 'RENDIMIENTO_CINCO'],\n",
    "        '6': ['PROMEDIO_UNO', 'NOTA_EE_UNO', 'PROMEDIO_DOS', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_ECONOMIA_UNO', 'NOTA_FISICA_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_ADMINISTRACION', 'NOTA_LENGUA_UNO', 'NOTA_EI_UNO', 'NOTA_EI_DOS', 'RENDIMIENTO_SEIS'],\n",
    "        '7': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_LENGUA_UNO', 'NOTA_EI_DOS', 'PROMEDIO_SEIS', 'NCA_SEIS', 'NOTA_PLINEAL', 'NOTA_DISE O', 'NOTA_EI_TRES', 'RENDIMIENTO_SIETE'],\n",
    "        '8': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_LENGUA_UNO', 'PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'RENDIMIENTO_OCHO'],\n",
    "        '9': ['PROMEDIO_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'PROMEDIO_OCHO', 'NCC_OCHO', 'NOTA_LOG_UNO', 'NOTA_GOPERACIONES', 'NOTA_CALIDAD_DOS', 'NOTA_LENGUA_DOS', 'NOTA_CONTEXTO', 'RENDIMIENTO_NUEVE'],\n",
    "        '10': ['PROMEDIO_SEIS', 'PROMEDIO_SIETE', 'PROMEDIO_OCHO', 'NOTA_CALIDAD_DOS', 'PROMEDIO_NUEVE', 'NAA_NUEVE', 'NOTA_GRADO_UNO', 'NOTA_LOG_DOS', 'NOTA_FINANZAS', 'NOTA_HISTORIA', 'RENDIMIENTO_DIEZ']\n",
    "    },\n",
    "    'catastral': {\n",
    "        '1': ['variable1_catastral', 'variable2_catastral', 'variable3_catastral'],\n",
    "        '2': ['variable4_catastral', 'variable5_catastral', 'variable6_catastral']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_datos(carrera, semestre):\n",
    "    \n",
    "    ruta_archivo = f'C:/Users/Intevo/Desktop/UNIVERSIDAD DISTRITAL PROYECTO FOLDER/UNIVERSIDAD-DISTRITAL-PROYECTO/MÓDULO ANALÍTICA PREDICTIVA/DATOS/{carrera}{semestre}.csv'\n",
    "    datos = pd.read_csv(ruta_archivo,sep=\";\")\n",
    "    \n",
    "    return datos\n",
    "carrera=\"industrial\"\n",
    "semestre=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame con columnas filtradas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PG_ICFES</th>\n",
       "      <th>CON_MAT_ICFES</th>\n",
       "      <th>FISICA_ICFES</th>\n",
       "      <th>QUIMICA_ICFES</th>\n",
       "      <th>IDIOMA_ICFES</th>\n",
       "      <th>LOCALIDAD</th>\n",
       "      <th>RENDIMIENTO_UNO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>474</td>\n",
       "      <td>65</td>\n",
       "      <td>73</td>\n",
       "      <td>75</td>\n",
       "      <td>79</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>523</td>\n",
       "      <td>99</td>\n",
       "      <td>69</td>\n",
       "      <td>78</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>483</td>\n",
       "      <td>63</td>\n",
       "      <td>76</td>\n",
       "      <td>82</td>\n",
       "      <td>77</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>528</td>\n",
       "      <td>88</td>\n",
       "      <td>69</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>478</td>\n",
       "      <td>78</td>\n",
       "      <td>69</td>\n",
       "      <td>66</td>\n",
       "      <td>69</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>342</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>347</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>348</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>340</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>351</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2008 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PG_ICFES  CON_MAT_ICFES  FISICA_ICFES  QUIMICA_ICFES  IDIOMA_ICFES  \\\n",
       "0          474             65            73             75            79   \n",
       "1          523             99            69             78            60   \n",
       "2          483             63            76             82            77   \n",
       "3          528             88            69             78            75   \n",
       "4          478             78            69             66            69   \n",
       "...        ...            ...           ...            ...           ...   \n",
       "2003       342             68             0              0            58   \n",
       "2004       347             69             0              0            71   \n",
       "2005       348             67             0              0            68   \n",
       "2006       340             70             0              0            63   \n",
       "2007       351             69             0              0            70   \n",
       "\n",
       "      LOCALIDAD  RENDIMIENTO_UNO  \n",
       "0            20                2  \n",
       "1             1                2  \n",
       "2            20                1  \n",
       "3            19                1  \n",
       "4             8                2  \n",
       "...         ...              ...  \n",
       "2003         11                2  \n",
       "2004         19                2  \n",
       "2005         11                1  \n",
       "2006         11                2  \n",
       "2007          7                3  \n",
       "\n",
       "[2008 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos = cargar_datos(carrera, semestre)\n",
    "columnas_filtradas = variables_por_carrera[carrera][semestre]\n",
    "df = datos[columnas_filtradas]\n",
    "print(\"DataFrame con columnas filtradas:\")\n",
    "df=df.astype(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uno\n"
     ]
    }
   ],
   "source": [
    "def numero_a_letras(numero):\n",
    "    numeros_letras = ['cero', 'uno', 'dos', 'tres', 'cuatro', 'cinco', 'seis', 'siete', 'ocho', 'nueve', 'diez']\n",
    "    return numeros_letras[int(numero)]\n",
    "\n",
    "semestre_en_letras = numero_a_letras(semestre)\n",
    "print(semestre_en_letras)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separación de datos usando Pandas\n",
      "(2008, 6) (2008, 1)\n"
     ]
    }
   ],
   "source": [
    "X = df.loc[:, ~df.columns.str.contains(f'RENDIMIENTO_{semestre_en_letras.upper()}')]\n",
    "Y = df.loc[:, df.columns.str.contains(f'RENDIMIENTO_{semestre_en_letras.upper()}')]                                                     \n",
    "print(\"Separación de datos usando Pandas\") \n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2008, 6) (2008,)\n"
     ]
    }
   ],
   "source": [
    "#X = X.astype('float32')                         \n",
    "Y = LabelEncoder().fit_transform(Y.astype('str'))                \n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor 1 aparece 1249 veces\n",
      "El valor 0 aparece 675 veces\n",
      "El valor 2 aparece 83 veces\n",
      "El valor 3 aparece 1 veces\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "frecuencias = Counter(Y)\n",
    "for valor, frecuencia in frecuencias.items():\n",
    "    print(f\"El valor {valor} aparece {frecuencia} veces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRANSFORMACIÓN DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.598 -0.897  1.005  1.046  1.268  1.353]\n",
      " [ 2.502  2.983  0.97   1.072 -0.304 -2.363]\n",
      " [ 1.767 -1.135  1.031  1.104  1.099  1.353]\n",
      " [ 2.592  1.758  0.97   1.072  0.931  1.202]\n",
      " [ 1.673  0.621  0.97   0.965  0.432 -0.682]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PG_ICFES</th>\n",
       "      <th>CON_MAT_ICFES</th>\n",
       "      <th>FISICA_ICFES</th>\n",
       "      <th>QUIMICA_ICFES</th>\n",
       "      <th>IDIOMA_ICFES</th>\n",
       "      <th>LOCALIDAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.597977</td>\n",
       "      <td>-0.896979</td>\n",
       "      <td>1.005474</td>\n",
       "      <td>1.046461</td>\n",
       "      <td>1.268136</td>\n",
       "      <td>1.353466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.501943</td>\n",
       "      <td>2.982940</td>\n",
       "      <td>0.970095</td>\n",
       "      <td>1.071635</td>\n",
       "      <td>-0.304403</td>\n",
       "      <td>-2.362712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PG_ICFES  CON_MAT_ICFES  FISICA_ICFES  QUIMICA_ICFES  IDIOMA_ICFES  \\\n",
       "0  1.597977      -0.896979      1.005474       1.046461      1.268136   \n",
       "1  2.501943       2.982940      0.970095       1.071635     -0.304403   \n",
       "\n",
       "   LOCALIDAD  \n",
       "0   1.353466  \n",
       "1  -2.362712  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_T_JOHNSON1 = X.copy(deep=True)\n",
    "def transformacion_johnson(X):\n",
    "    transformador_johnson = PowerTransformer(method='yeo-johnson', standardize=True).fit(X)\n",
    "    datos_transformados = transformador_johnson.transform(X)\n",
    "    set_printoptions(precision=3)\n",
    "    print(datos_transformados[:5, :])\n",
    "    datos_transformados_df = pd.DataFrame(data=datos_transformados, columns=X.columns)\n",
    "    return datos_transformados_df\n",
    "Xpandas_T_JOHNSON1 = transformacion_johnson(X_T_JOHNSON1)\n",
    "Xpandas_T_JOHNSON1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom imblearn.over_sampling import RandomOverSampler\\nfrom sklearn.model_selection import train_test_split\\n\\n# Crear una instancia de RandomOverSampler\\nros = RandomOverSampler(sampling_strategy=\\'auto\\', random_state=42)\\n\\n# Aplicar RandomOverSampler para generar muestras sintéticas de las clases minoritarias\\nXpandas_T_JOHNSON1, Y = ros.fit_resample(Xpandas_T_JOHNSON1, Y)\\n\\n# Imprimir la distribución de clases después del oversampling\\nprint(\"Distribución de clases después del oversampling:\", Counter(Y))\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Crear una instancia de RandomOverSampler\n",
    "ros = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "# Aplicar RandomOverSampler para generar muestras sintéticas de las clases minoritarias\n",
    "Xpandas_T_JOHNSON1, Y = ros.fit_resample(Xpandas_T_JOHNSON1, Y)\n",
    "\n",
    "# Imprimir la distribución de clases después del oversampling\n",
    "print(\"Distribución de clases después del oversampling:\", Counter(Y))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATOS: Son 1405 datos para entrenamiento y 603 datos para prueba\n"
     ]
    }
   ],
   "source": [
    "X_trn, X_tst, Y_trn, Y_tst = train_test_split(Xpandas_T_JOHNSON1, Y, test_size=0.3, random_state=2)\n",
    "print('DATOS: Son {} datos para entrenamiento y {} datos para prueba'.format(X_trn.shape[0], X_tst.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom imblearn.over_sampling import RandomOverSampler\\nfrom sklearn.model_selection import train_test_split\\n\\n# Crear una instancia de RandomOverSampler\\nros = RandomOverSampler(sampling_strategy=\\'auto\\', random_state=42)\\n\\n# Aplicar RandomOverSampler para generar muestras sintéticas de las clases minoritarias\\nX_trn,Y_trn = ros.fit_resample(X_trn, Y_trn)\\n\\n# Imprimir la distribución de clases después del oversampling\\nprint(\"Distribución de clases después del oversampling:\", Counter(Y_trn))\\n\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Crear una instancia de RandomOverSampler\n",
    "ros = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "# Aplicar RandomOverSampler para generar muestras sintéticas de las clases minoritarias\n",
    "X_trn,Y_trn = ros.fit_resample(X_trn, Y_trn)\n",
    "\n",
    "# Imprimir la distribución de clases después del oversampling\n",
    "print(\"Distribución de clases después del oversampling:\", Counter(Y_trn))\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor 1 aparece 861 veces\n",
      "El valor 0 aparece 477 veces\n",
      "El valor 2 aparece 66 veces\n",
      "El valor 3 aparece 1 veces\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "frecuencias = Counter(Y_trn)   \n",
    "for valor, frecuencia in frecuencias.items():\n",
    "    print(f\"El valor {valor} aparece {frecuencia} veces\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNEIGHBORSCLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 59.93161094224925\n",
      "Mejor valor PARAMETRO usando k-fold: {'algorithm': 'auto', 'metric': 'manhattan', 'n_neighbors': 16, 'p': 1, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_knn_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {\n",
    "        'n_neighbors': [i for i in range(14, 18, 1)],\n",
    "        'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "        'algorithm': ['auto'],\n",
    "        'p': [i for i in range(1, 6)],\n",
    "        'weights': ['uniform']\n",
    "    }\n",
    "    modelo = KNeighborsClassifier()\n",
    "    semilla = 5\n",
    "    num_folds = 10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn_transformado, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "\n",
    "    # Entrenar el modelo con los mejores hiperparámetros\n",
    "    mejor_modelo = KNeighborsClassifier(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_knn = entrenar_modelo_knn_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.50792994331564\n",
      "Exhaustividad (Recall):  0.5787728026533997\n",
      "Puntuación F1:  0.52877975562655\n",
      "Exactitud:  0.5787728026533997\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.16      0.21       198\n",
      "           1       0.64      0.82      0.72       388\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.58       603\n",
      "   macro avg       0.31      0.33      0.31       603\n",
      "weighted avg       0.51      0.58      0.53       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_knn.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 59.430597771023294\n",
      "Mejor valor PARAMETRO usando k-fold: {'C': 0.0008, 'gamma': 1.05, 'kernel': 'rbf', 'max_iter': 1, 'random_state': 1}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_svc_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = { 'kernel':  ['rbf'], \n",
    "            'C': [i/10000 for i in range(8,12,1)],\n",
    "            'max_iter':[i for i in range(1,3,1)],\n",
    "            'gamma' : [i/100 for i in range(90,110,5)],\n",
    "            'random_state':[i for i in range(1,5,1)]}\n",
    "    modelo = SVC()\n",
    "    semilla=5\n",
    "    num_folds=10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = SVC(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_svc = entrenar_modelo_svc_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5207791886339446\n",
      "Exhaustividad (Recall):  0.6069651741293532\n",
      "Puntuación F1:  0.5336250490854828\n",
      "Exactitud:  0.6069651741293532\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.11      0.17       198\n",
      "           1       0.64      0.89      0.74       388\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.61       603\n",
      "   macro avg       0.32      0.33      0.30       603\n",
      "weighted avg       0.52      0.61      0.53       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_svc.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 62.56433637284701\n",
      "Mejor valor PARAMETRO usando k-fold: {'criterion': 'entropy', 'max_depth': 4, 'max_features': 6, 'min_samples_leaf': 1, 'min_samples_split': 2, 'random_state': 1, 'splitter': 'random'}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_tree_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {          \n",
    "            'max_depth':[i for i in range(3,6,1)],\n",
    "            'min_samples_split' :  [i for i in range(1,3,1)],  \n",
    "            'min_samples_leaf' : [i for i in range(1,3,1)], \n",
    "            'max_features' : [i for i in range(5,7,1)], \n",
    "            'splitter': [\"best\", \"random\"],\n",
    "            'random_state': [i for i in range(1,4,1)],\n",
    "            'criterion': ['entropy']}\n",
    "    modelo = DecisionTreeClassifier()\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = DecisionTreeClassifier(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_tree = entrenar_modelo_tree_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5300855025473677\n",
      "Exhaustividad (Recall):  0.6235489220563848\n",
      "Puntuación F1:  0.5333105484805998\n",
      "Exactitud:  0.6235489220563848\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.08      0.13       198\n",
      "           1       0.65      0.93      0.76       388\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.62       603\n",
      "   macro avg       0.33      0.34      0.30       603\n",
      "weighted avg       0.53      0.62      0.53       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_tree.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 60.85916919959473\n",
      "Mejor valor PARAMETRO usando k-fold: {}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_gaussian_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {}\n",
    "    modelo = GaussianNB()\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = GaussianNB(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_gaussian = entrenar_modelo_gaussian_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5558536044814331\n",
      "Exhaustividad (Recall):  0.6401326699834162\n",
      "Puntuación F1:  0.5191201508406547\n",
      "Exactitud:  0.6401326699834162\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.03      0.06       198\n",
      "           1       0.65      0.98      0.78       388\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.64       603\n",
      "   macro avg       0.36      0.34      0.28       603\n",
      "weighted avg       0.56      0.64      0.52       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_gaussian.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 61.49848024316109\n",
      "Mejor valor PARAMETRO usando k-fold: {'n_components': 1, 'shrinkage': 1, 'solver': 'lsqr'}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_LDA_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = { 'solver':  ['svd','lsqr','eigen'],\n",
    "            'n_components':[1,2,3,4,5,None],\n",
    "            'shrinkage': ['auto',None, 0, 0.001, 0.01, 0.1, 0.5,1]}\n",
    "    modelo = LinearDiscriminantAnalysis()\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = LinearDiscriminantAnalysis(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_LDA = entrenar_modelo_LDA_con_transformacion(X_trn, Y_trn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5244075546333103\n",
      "Exhaustividad (Recall):  0.6417910447761194\n",
      "Puntuación F1:  0.5094394653585858\n",
      "Exactitud:  0.6417910447761194\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.01      0.02       198\n",
      "           1       0.64      0.99      0.78       388\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.64       603\n",
      "   macro avg       0.33      0.33      0.27       603\n",
      "weighted avg       0.52      0.64      0.51       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_LDA.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BAGGINGCLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'bootstrap_features': False,\n",
       " 'estimator': None,\n",
       " 'max_features': 1.0,\n",
       " 'max_samples': 1.0,\n",
       " 'n_estimators': 10,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "estimator = BaggingClassifier()\n",
    "estimator.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 61.142350557244185\n",
      "Mejor valor PARAMETRO usando k-fold: {'bootstrap': True, 'bootstrap_features': True, 'max_features': 0.6, 'max_samples': 0.45, 'n_estimators': 750}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_BG_con_transformacion(X_trn, Y_trn):\n",
    "    # Aplicar la transformación Yeo-Johnson\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {'n_estimators': [i for i in range(750,760,5)],\n",
    "            'max_samples' : [i/100.0 for i in range(40,50,5)],\n",
    "            'max_features': [i/100.0 for i in range(60,65,5)],\n",
    "            'bootstrap': [True], \n",
    "            'bootstrap_features': [True]}\n",
    "    \n",
    "    base_estimator= DecisionTreeClassifier(criterion= 'gini', \n",
    "                                max_depth=5, max_features= 3,min_samples_leaf= 4, \n",
    "                                min_samples_split = 8,random_state= 10, splitter= 'random')\n",
    "\n",
    "    modelo = BaggingClassifier(estimator=base_estimator, oob_score=True, random_state=1)\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = BaggingClassifier(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "modelo_BG = entrenar_modelo_BG_con_transformacion(X_trn, Y_trn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.584251557153769\n",
      "Exhaustividad (Recall):  0.6451077943615257\n",
      "Puntuación F1:  0.5605968772533045\n",
      "Exactitud:  0.6451077943615257\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.12      0.19       198\n",
      "           1       0.66      0.94      0.78       388\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.65       603\n",
      "   macro avg       0.38      0.35      0.32       603\n",
      "weighted avg       0.58      0.65      0.56       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_BG.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXTRA TREES CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 61.78216818642351\n",
      "Mejor valor PARAMETRO usando k-fold: {'min_samples_leaf': 1, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_extra_con_transformacion(X_trn, Y_trn):\n",
    "    # Aplicar la transformación Yeo-Johnson\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {'min_samples_split' : [i for i in range(1,3,1)], \n",
    "                'min_samples_leaf' : [i for i in range(0,2,1)] }\n",
    "    \n",
    "    semilla=7            \n",
    "    modelo = ExtraTreesClassifier(random_state=semilla, \n",
    "                                n_estimators=40, max_features=1,max_depth= 10,\n",
    "                                min_samples_leaf=1,  min_samples_split = 2,\n",
    "                                bootstrap=True,criterion='gini') \n",
    "    num_folds=10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = ExtraTreesClassifier(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_extra = entrenar_modelo_extra_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5422902391356268\n",
      "Exhaustividad (Recall):  0.5870646766169154\n",
      "Puntuación F1:  0.5574860136546097\n",
      "Exactitud:  0.5870646766169154\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.25      0.30       198\n",
      "           1       0.66      0.78      0.71       388\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.59       603\n",
      "   macro avg       0.34      0.35      0.34       603\n",
      "weighted avg       0.54      0.59      0.56       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_extra.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'SAMME.R',\n",
       " 'estimator': None,\n",
       " 'learning_rate': 1.0,\n",
       " 'n_estimators': 50,\n",
       " 'random_state': None}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier            \n",
    "estimator  = AdaBoostClassifier ()\n",
    "estimator.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 61.28368794326241\n",
      "Mejor valor PARAMETRO usando k-fold: {'learning_rate': 0.001}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_ADA_con_transformacion(X_trn, Y_trn):\n",
    "    # Aplicar la transformación Yeo-Johnson\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {'learning_rate' : [i/10000.0 for i in range(5,20,5)]}\n",
    "    semilla=7            \n",
    "    modelo = AdaBoostClassifier(estimator = None,  algorithm = 'SAMME.R', \n",
    "                                random_state= None, n_estimators =50) \n",
    "    num_folds=10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = AdaBoostClassifier(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_ADA = entrenar_modelo_ADA_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.41402715554345465\n",
      "Exhaustividad (Recall):  0.6434494195688225\n",
      "Puntuación F1:  0.5038514122960709\n",
      "Exactitud:  0.6434494195688225\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       198\n",
      "           1       0.64      1.00      0.78       388\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.64       603\n",
      "   macro avg       0.21      0.33      0.26       603\n",
      "weighted avg       0.41      0.64      0.50       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_ADA.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRADIENT BOOSTING MACHINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 61.63931104356638\n",
      "Mejor valor PARAMETRO usando k-fold: {'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_GD_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = { \n",
    "                'subsample' : [ 0.5,0.6,0.7 , 0.75 , 0.8 , 0.85 , 0.9 , 0.95 , 1 ]        \n",
    "              }\n",
    "    semilla=7\n",
    "    modelo = GradientBoostingClassifier(random_state=semilla,\n",
    "                                    n_estimators= 100,learning_rate= 0.1,max_depth= 2,\n",
    "                                    min_samples_split= 2, min_samples_leaf= 3,max_features= 2)\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = GradientBoostingClassifier(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_GD = entrenar_modelo_GD_con_transformacion(X_trn, Y_trn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5449469684544311\n",
      "Exhaustividad (Recall):  0.6135986733001658\n",
      "Puntuación F1:  0.5577029883263421\n",
      "Exactitud:  0.6135986733001658\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.17      0.24       198\n",
      "           1       0.66      0.87      0.75       388\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.61       603\n",
      "   macro avg       0.34      0.35      0.33       603\n",
      "weighted avg       0.54      0.61      0.56       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_GD.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 62.35258358662614\n",
      "Mejor valor PARAMETRO usando k-fold: {'reg_alpha': 0.3, 'reg_lambda': 1.4}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_XB_con_transformacion(X_trn, Y_trn):\n",
    "    # Aplicar la transformación Yeo-Johnson\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {'reg_alpha': [0,0.1,0.2,0.3,0.4,0.5],\n",
    "                'reg_lambda':  [i/100.0 for i in range(130,150,5)]}\n",
    "    semilla=7\n",
    "    modelo = XGBClassifier (random_state=semilla,                       \n",
    "                        n_estimators=40,colsample_bytree = 1, subsample =1,max_depth =2,\n",
    "                        min_child_weight =6,gamma = 0.05,learning_rate = 0.3)\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = XGBClassifier(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_XB = entrenar_modelo_XB_con_transformacion(X_trn, Y_trn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5229913217157277\n",
      "Exhaustividad (Recall):  0.5572139303482587\n",
      "Puntuación F1:  0.5378442260053621\n",
      "Exactitud:  0.5572139303482587\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.27      0.30       198\n",
      "           1       0.65      0.73      0.68       388\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.56       603\n",
      "   macro avg       0.32      0.33      0.33       603\n",
      "weighted avg       0.52      0.56      0.54       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_XB.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CATBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 60.78520770010132\n",
      "Mejor valor PARAMETRO usando k-fold: {'border_count': 53, 'l2_leaf_reg': 42}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_CB_con_transformacion(X_trn, Y_trn):\n",
    "    # Aplicar la transformación Yeo-Johnson\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {'border_count':[53],'l2_leaf_reg': [42]} \n",
    "    semilla=7\n",
    "    modelo = CatBoostClassifier(random_state=semilla, verbose =0)\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = CatBoostClassifier(verbose=0,**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_CB = entrenar_modelo_CB_con_transformacion(X_trn, Y_trn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5410368802256945\n",
      "Exhaustividad (Recall):  0.6218905472636815\n",
      "Puntuación F1:  0.5477270824633331\n",
      "Exactitud:  0.6218905472636815\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.12      0.18       198\n",
      "           1       0.65      0.90      0.76       388\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.62       603\n",
      "   macro avg       0.34      0.34      0.31       603\n",
      "weighted avg       0.54      0.62      0.55       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_CB.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIGHT GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 379\n",
      "[LightGBM] [Info] Number of data points in the train set: 1405, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -1.080276\n",
      "[LightGBM] [Info] Start training from score -0.489698\n",
      "[LightGBM] [Info] Start training from score -3.058138\n",
      "[LightGBM] [Info] Start training from score -7.247793\n",
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 62.06788247213779\n",
      "Mejor valor PARAMETRO usando k-fold: {'min_child_samples': 200}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_LIGHT_con_transformacion(X_trn, Y_trn):\n",
    "    # Aplicar la transformación Yeo-Johnson\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = { 'min_child_samples' : [i for i in range(200, 10000, 100)]}\n",
    "    semilla=7\n",
    "    modelo = LGBMClassifier (random_state=semilla,                           \n",
    "                        num_leaves =  10,max_depth = 1, n_estimators = 100,    \n",
    "                        learning_rate = 0.1 ,class_weight=  None, subsample = 1,\n",
    "                        colsample_bytree= 1, reg_alpha=  0, reg_lambda = 0,\n",
    "                        min_split_gain = 0, boosting_type = 'gbdt')\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = LGBMClassifier(verbose=-1,**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_LIGHT = entrenar_modelo_LIGHT_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5505247485201729\n",
      "Exhaustividad (Recall):  0.6285240464344942\n",
      "Puntuación F1:  0.5479421916800242\n",
      "Exactitud:  0.6285240464344942\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.11      0.17       198\n",
      "           1       0.65      0.92      0.76       388\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.63       603\n",
      "   macro avg       0.35      0.34      0.31       603\n",
      "weighted avg       0.55      0.63      0.55       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_LIGHT.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VOTING - VOTACIÓN DURA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento del modelo:\n",
      "Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold: 61.78216818642351  % \n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_voting_hard_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    semilla= 7 \n",
    "    kfold = KFold(n_splits=10, random_state=semilla, shuffle=True)\n",
    "    \n",
    "    modelo1 = GradientBoostingClassifier(random_state=semilla, n_estimators=800, \n",
    "                                    learning_rate = 0.01, max_depth = 2,\n",
    "                                    max_features =2, min_samples_leaf = 9, \n",
    "                                    min_samples_split = 2, subsample = 1 )\n",
    "    \n",
    "    base_estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, \n",
    "                                    criterion='gini',\n",
    "                                    max_depth=8, max_features=1, max_leaf_nodes=None,\n",
    "                                    min_impurity_decrease=0.0,\n",
    "                                    min_samples_leaf=1, min_samples_split=5,\n",
    "                                    min_weight_fraction_leaf=0.0,\n",
    "                                    random_state=5, splitter='random')\n",
    "\n",
    "    modelo2 = AdaBoostClassifier(estimator=base_estimator,n_estimators=1200, \n",
    "                                    algorithm ='SAMME.R', learning_rate = 0.001, \n",
    "                                    random_state=semilla)\n",
    "\n",
    "    modelo3 = ExtraTreesClassifier(n_estimators=300, max_features=None,\n",
    "                                    bootstrap = False, max_depth = 11,min_samples_split = 4, \n",
    "                                    min_samples_leaf = 1)\n",
    "\n",
    "    modelo4 = RandomForestClassifier (n_estimators=1100, max_features=None,\n",
    "                                    min_samples_split = 5, max_depth= 3, \n",
    "                                    min_samples_leaf= 1)\n",
    "\n",
    "    model = DecisionTreeClassifier(criterion= 'gini', \n",
    "                                    max_depth=6, \n",
    "                                    max_features= None, \n",
    "                                    min_samples_leaf= 9, \n",
    "                                    min_samples_split = 2, \n",
    "                                    random_state= 10, \n",
    "                                    splitter= 'random')\n",
    "\n",
    "    modelo5 = BaggingClassifier(estimator=model, n_estimators=50, \n",
    "                                    random_state=semilla,\n",
    "                                    bootstrap= True, bootstrap_features = False, \n",
    "                                    max_features = 0.9,\n",
    "                                    max_samples= 0.95)\n",
    "\n",
    "    modelo6 = DecisionTreeClassifier(criterion= 'gini', max_depth=6,max_features= None, \n",
    "                                    min_samples_leaf= 9, \n",
    "                                    min_samples_split = 2, random_state= 10, splitter= 'random')\n",
    "\n",
    "    modelo7 = XGBClassifier(n_estimators= 40, random_state=semilla,colsample_bytree = 1, \n",
    "                                    subsample =1, reg_alpha = 0.2, reg_lambda= 1.35,\n",
    "                                    learning_rate= 0.3,max_depth =2, min_child_weight =6,\n",
    "                                    gamma = 0.05)\n",
    "    metrica = 'accuracy'\n",
    "    mejor_modelo = VotingClassifier(\n",
    "    estimators=[('Gradient', modelo1), ('Adaboost', modelo2), \n",
    "                                    ('Extratrees', modelo3),('Random Forest',modelo4),\n",
    "                                    ('Bagging',modelo5),('Decision tree',modelo6),\n",
    "                                    ('XGB',modelo7)],voting='hard') \n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    resultados = cross_val_score(mejor_modelo, X_trn_transformado, Y_trn, \n",
    "                                    cv=kfold,scoring = metrica)\n",
    "    print(\"Rendimiento del modelo:\") \n",
    "    print (\"Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold:\", resultados.mean()*100,\" % \") \n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_voting_hard = entrenar_modelo_voting_hard_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5598971658449382\n",
      "Exhaustividad (Recall):  0.6401326699834162\n",
      "Puntuación F1:  0.5295854720389799\n",
      "Exactitud:  0.6401326699834162\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.05      0.09       198\n",
      "           1       0.65      0.97      0.78       388\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.64       603\n",
      "   macro avg       0.36      0.34      0.29       603\n",
      "weighted avg       0.56      0.64      0.53       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_voting_hard.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VOTING - VOTACIÓN SUAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento del modelo:\n",
      "Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold: 62.208206686930076  % \n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_voting_soft_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    semilla= 7 \n",
    "    kfold = KFold(n_splits=10, random_state=semilla, shuffle=True)\n",
    "    modelo1 = GradientBoostingClassifier(random_state=semilla, n_estimators=800, \n",
    "                                    learning_rate = 0.01, max_depth = 2,\n",
    "                                    max_features =2, min_samples_leaf = 9, \n",
    "                                    min_samples_split = 2, subsample = 1 )\n",
    "    \n",
    "    base_estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "                                    max_depth=8, max_features=1, max_leaf_nodes=None,\n",
    "                                    min_impurity_decrease=0.0,\n",
    "                                    min_samples_leaf=1, min_samples_split=5,\n",
    "                                    min_weight_fraction_leaf=0.0,\n",
    "                                    random_state=5, splitter='random')\n",
    "\n",
    "    modelo2 = AdaBoostClassifier(estimator=base_estimator,n_estimators=1200, \n",
    "                                    algorithm ='SAMME.R', learning_rate = 0.001, \n",
    "                                    random_state=semilla)\n",
    "\n",
    "    modelo3 = ExtraTreesClassifier(n_estimators=300, max_features=None,bootstrap = False, \n",
    "                                    max_depth = 11,min_samples_split = 4, \n",
    "                                    min_samples_leaf = 1)\n",
    "\n",
    "    modelo4 = RandomForestClassifier (n_estimators=1100, max_features=None,\n",
    "                                    min_samples_split = 5, max_depth= 3, min_samples_leaf= 1)\n",
    "\n",
    "    model = DecisionTreeClassifier(criterion= 'gini', \n",
    "                                    max_depth=6, \n",
    "                                    max_features= None, \n",
    "                                    min_samples_leaf= 9, \n",
    "                                    min_samples_split = 2, \n",
    "                                    random_state= 10, \n",
    "                                    splitter= 'random')\n",
    "\n",
    "    modelo5 = BaggingClassifier(estimator=model, n_estimators=50, random_state=semilla,\n",
    "                                    bootstrap= True, bootstrap_features = False, \n",
    "                                    max_features = 0.9, max_samples= 0.95)\n",
    "\n",
    "    modelo6 = DecisionTreeClassifier(criterion= 'gini', max_depth=6,max_features= None, \n",
    "                                    min_samples_leaf= 9, min_samples_split = 2, \n",
    "                                    random_state= 10, splitter= 'random')\n",
    "    metrica = 'accuracy'\n",
    "    mejor_modelo = VotingClassifier(\n",
    "    estimators=[('Gradient', modelo1), ('Adaboost', modelo2), ('Extratrees', modelo3),\n",
    "                                    ('Random Forest',modelo4),\n",
    "                                    ('Bagging',modelo5),('Decision tree',modelo6)],\n",
    "    voting='soft',weights=[0.9,0.7,0.9,0.9,0.9,0.9]) \n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    resultados = cross_val_score(mejor_modelo, X_trn_transformado, Y_trn, cv=kfold,scoring = metrica)\n",
    "    print(\"Rendimiento del modelo:\") \n",
    "    print (\"Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold:\", resultados.mean()*100,\" % \") \n",
    "    return mejor_modelo\n",
    "\n",
    "# Cargar los datos\n",
    "#datos = cargar_datos(carrera, semestre)\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "# Entrenar el modelo KNN con transformación Yeo-Johnson\n",
    "modelo_voting_soft = entrenar_modelo_voting_soft_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5915488302432474\n",
      "Exhaustividad (Recall):  0.648424543946932\n",
      "Puntuación F1:  0.5418530277060787\n",
      "Exactitud:  0.648424543946932\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.07      0.12       198\n",
      "           1       0.65      0.97      0.78       388\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.65       603\n",
      "   macro avg       0.39      0.35      0.30       603\n",
      "weighted avg       0.59      0.65      0.54       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_voting_soft.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STACKING ( METAMODELO LINEAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento del modelo:\n",
      "Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold: 62.34802431610943  % \n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_stacking_lineal_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    semilla= 7 \n",
    "    kfold = KFold(n_splits=10, random_state=semilla, shuffle=True)\n",
    "    base_estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "                                    max_depth=8, max_features=1, max_leaf_nodes=None,\n",
    "                                    min_impurity_decrease=0.0,\n",
    "                                    min_samples_leaf=1, min_samples_split=5,\n",
    "                                    min_weight_fraction_leaf=0.0,\n",
    "                                    random_state=5, splitter='random')\n",
    "    modelo2 = AdaBoostClassifier(estimator=base_estimator,n_estimators=500, \n",
    "                                    algorithm ='SAMME.R', learning_rate = 0.001, \n",
    "                                    random_state=semilla)\n",
    "\n",
    "    modelo3 = ExtraTreesClassifier(n_estimators=300, max_features=None,bootstrap = False, \n",
    "                                    max_depth = 11,min_samples_split = 4, \n",
    "                                    min_samples_leaf = 1)\n",
    "\n",
    "    modelo4 = RandomForestClassifier (n_estimators=300, max_features=None,\n",
    "                                    min_samples_split = 5, max_depth= 3, min_samples_leaf= 1)\n",
    "    model = DecisionTreeClassifier(criterion= 'gini', \n",
    "                                    max_depth=6, \n",
    "                                    max_features= None, \n",
    "                                    min_samples_leaf= 9, \n",
    "                                    min_samples_split = 2, \n",
    "                                    random_state= 10, \n",
    "                                    splitter= 'random')\n",
    "\n",
    "    modelo5 = BaggingClassifier(estimator=model, n_estimators=50, random_state=semilla,\n",
    "                                    bootstrap= True, bootstrap_features = False, \n",
    "                                    max_features = 0.9,\n",
    "                                    max_samples= 0.95)\n",
    "\n",
    "    modelo6 = DecisionTreeClassifier(criterion= 'gini', max_depth=6,max_features= None, \n",
    "                                    min_samples_leaf= 9, \n",
    "                                    min_samples_split = 2, random_state= 10, splitter= 'random')\n",
    "    estimador_final = LogisticRegression()\n",
    "    metrica = 'accuracy'\n",
    "    mejor_modelo = StackingClassifier(\n",
    "    estimators=[ ('Adaboost', modelo2), ('Extratrees', modelo3),('Random Forest',modelo4),\n",
    "                                    ('Bagging',modelo5),('Decision tree',modelo6)], \n",
    "                                    final_estimator=estimador_final) \n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    resultados = cross_val_score(mejor_modelo, X_trn_transformado, Y_trn, cv=kfold,scoring = metrica)\n",
    "    print(\"Rendimiento del modelo:\") \n",
    "    print (\"Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold:\", resultados.mean()*100,\" % \") \n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_stacking_lineal = entrenar_modelo_stacking_lineal_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.6030641560807631\n",
      "Exhaustividad (Recall):  0.6533996683250415\n",
      "Puntuación F1:  0.558350167384565\n",
      "Exactitud:  0.6533996683250415\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.10      0.16       198\n",
      "           1       0.66      0.97      0.78       388\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.65       603\n",
      "   macro avg       0.40      0.35      0.32       603\n",
      "weighted avg       0.60      0.65      0.56       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_stacking_lineal.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STACKING (METAMODELO NO LINEAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento del modelo:\n",
      "Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold: 60.57446808510638  % \n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_stacking_nolineal_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    semilla= 7 \n",
    "    kfold = KFold(n_splits=10, random_state=semilla, shuffle=True)\n",
    "    modelo3 = ExtraTreesClassifier(n_estimators=400, max_features=None,bootstrap = False, \n",
    "                                    max_depth = 11,min_samples_split = 4, \n",
    "                                    min_samples_leaf = 1)\n",
    "\n",
    "    modelo4 = RandomForestClassifier (n_estimators=500, max_features=None,\n",
    "                                    min_samples_split = 5, max_depth= 3, min_samples_leaf= 1)\n",
    "    model = DecisionTreeClassifier(criterion= 'gini', \n",
    "                                    max_depth=6, max_features= None,  min_samples_leaf= 9, \n",
    "                                    min_samples_split = 2, \n",
    "                                    random_state= 10, splitter= 'random')\n",
    "\n",
    "    modelo5 = BaggingClassifier(estimator=model, n_estimators=50, random_state=semilla,\n",
    "                                    bootstrap= True, bootstrap_features = False, \n",
    "                                    max_features = 0.9, max_samples= 0.95)\n",
    "\n",
    "    modelo6 = DecisionTreeClassifier(criterion= 'gini', max_depth=6,max_features= None, \n",
    "                                    min_samples_leaf= 9, min_samples_split = 2, \n",
    "                                    random_state= 10, splitter= 'random')\n",
    "    estimador_final = ExtraTreesClassifier(n_estimators=100, max_features=None,\n",
    "                                    bootstrap = False, max_depth = 11,min_samples_split = 4, \n",
    "                                    min_samples_leaf = 1)\n",
    "    metrica = 'accuracy'\n",
    "    mejor_modelo = StackingClassifier(\n",
    "    estimators=[  ('Extratrees', modelo3),('Random Forest',modelo4),('Bagging',modelo5),\n",
    "                                    ('Decision tree',modelo6)], \n",
    "                                    final_estimator=estimador_final) \n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    resultados = cross_val_score(mejor_modelo, X_trn_transformado, Y_trn, cv=kfold,scoring = metrica)\n",
    "    print(\"Rendimiento del modelo:\") \n",
    "    print (\"Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold:\", resultados.mean()*100,\" % \") \n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_stacking_nolineal = entrenar_modelo_stacking_nolineal_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5560129163786072\n",
      "Exhaustividad (Recall):  0.6334991708126037\n",
      "Puntuación F1:  0.5496096378740324\n",
      "Exactitud:  0.6334991708126037\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.11      0.17       198\n",
      "           1       0.65      0.93      0.77       388\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.63       603\n",
      "   macro avg       0.36      0.35      0.31       603\n",
      "weighted avg       0.56      0.63      0.55       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_stacking_nolineal.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VOTING WEIGHTED VOTING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.6401326699834162\n",
      "Exhaustividad (Recall):  0.6401326699834162\n",
      "Puntuación F1:  0.5295854720389799\n",
      "Exactitud:  0.6401326699834162\n",
      "Precisión del modelo (Ensamblaje con voto ponderado): 64.01%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier, RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def weighted_voting_ensemble(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    modelos = [\n",
    "        GradientBoostingClassifier(random_state=7, n_estimators=800, learning_rate=0.01, max_depth=2, max_features=2, min_samples_leaf=9, min_samples_split=2, subsample=1),\n",
    "        AdaBoostClassifier(estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini', max_depth=8, max_features=1, max_leaf_nodes=None, min_impurity_decrease=0.0, min_samples_leaf=1, min_samples_split=5, min_weight_fraction_leaf=0.0, random_state=5, splitter='random'), n_estimators=1200, algorithm='SAMME.R', learning_rate=0.001, random_state=7),\n",
    "        ExtraTreesClassifier(n_estimators=300, max_features=None, bootstrap=False, max_depth=11, min_samples_split=4, min_samples_leaf=1),\n",
    "        RandomForestClassifier(n_estimators=300, max_features=None, min_samples_split=5, max_depth=3, min_samples_leaf=1),\n",
    "        BaggingClassifier(estimator=DecisionTreeClassifier(criterion='gini', max_depth=6, max_features=None, min_samples_leaf=9, min_samples_split=2, random_state=10, splitter='random'), n_estimators=50, random_state=7, bootstrap=True, bootstrap_features=False, max_features=0.9, max_samples=0.95),\n",
    "        DecisionTreeClassifier(criterion='gini', max_depth=6, max_features=None, min_samples_leaf=9, min_samples_split=2, random_state=10, splitter='random'),\n",
    "        XGBClassifier(n_estimators=40, random_state=7, colsample_bytree=1, subsample=1, reg_alpha=0.2, reg_lambda=1.35, learning_rate=0.3, max_depth=2, min_child_weight=6, gamma=0.05)\n",
    "    ]\n",
    "    \n",
    "    # Inicializar pesos para el voto ponderado\n",
    "    pesos = np.ones(len(modelos))\n",
    "    \n",
    "    # Entrenar cada modelo y obtener su precisión\n",
    "    precisión_modelos = []\n",
    "    for modelo in modelos:\n",
    "        modelo.fit(X_trn_transformado, Y_trn)  # <-- Ajustar el modelo\n",
    "        precisión = np.mean(cross_val_score(modelo, X_trn_transformado, Y_trn, cv=KFold(n_splits=10, random_state=7, shuffle=True), scoring='accuracy'))\n",
    "        precisión_modelos.append(precisión)\n",
    "    \n",
    "    # Calcular los pesos como inversa de la precisión de cada modelo\n",
    "    suma_precisión = sum(precisión_modelos)\n",
    "    for i in range(len(precisión_modelos)):\n",
    "        pesos[i] = suma_precisión / (precisión_modelos[i] * len(modelos))\n",
    "    \n",
    "    # Devolver modelos y pesos\n",
    "    return modelos, pesos\n",
    "\n",
    "def weighted_voting_predict(modelos, pesos, X_test):\n",
    "    # Obtener las predicciones de cada modelo\n",
    "    predicciones_modelos = [modelo.predict(X_test) for modelo in modelos]\n",
    "    \n",
    "    # Convertir los pesos a float64\n",
    "    pesos_float64 = np.array(pesos, dtype=np.float64)\n",
    "    \n",
    "    # Calcular las predicciones ponderadas\n",
    "    predicciones_ponderadas = np.zeros_like(predicciones_modelos[0], dtype=np.float64)\n",
    "    for i, predicciones_modelo in enumerate(predicciones_modelos):\n",
    "        predicciones_ponderadas += predicciones_modelo * pesos_float64[i]\n",
    "    \n",
    "    # Normalizar las predicciones ponderadas\n",
    "    predicciones_ponderadas /= len(modelos)\n",
    "    predicciones_ponderadas = np.round(predicciones_ponderadas).astype(int)\n",
    "    \n",
    "    return predicciones_ponderadas\n",
    "\n",
    "# Utilizar la función\n",
    "modelos, pesos = weighted_voting_ensemble(X_trn, Y_trn)\n",
    "\n",
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = weighted_voting_predict(modelos, pesos, X_tst)\n",
    "\n",
    "# Calcular la precisión de las predicciones\n",
    "precision = accuracy_score(Y_tst, Y_pred)\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "print(\"Precisión del modelo (Ensamblaje con voto ponderado): {:.2f}%\".format(precision * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUPER APRENDIZ MLENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 't' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mt\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 't' is not defined"
     ]
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             "
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 50\u001b[0m\n\u001b[0;32m     47\u001b[0m X_trn \u001b[38;5;241m=\u001b[39m X_trn\n\u001b[0;32m     48\u001b[0m Y_trn \u001b[38;5;241m=\u001b[39m Y_trn \n\u001b[1;32m---> 50\u001b[0m modelo_superaprendiz \u001b[38;5;241m=\u001b[39m \u001b[43mentrenar_modelo_super_aprendiz\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_trn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_trn\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[57], line 37\u001b[0m, in \u001b[0;36mentrenar_modelo_super_aprendiz\u001b[1;34m(X_trn, Y_trn)\u001b[0m\n\u001b[0;32m     31\u001b[0m estimador_final \u001b[38;5;241m=\u001b[39m ExtraTreesClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     32\u001b[0m                                        bootstrap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m11\u001b[39m, min_samples_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, \n\u001b[0;32m     33\u001b[0m                                        min_samples_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     35\u001b[0m super_learner\u001b[38;5;241m.\u001b[39madd_meta(estimador_final)\n\u001b[1;32m---> 37\u001b[0m \u001b[43msuper_learner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_trn_transformado\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_trn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m resultados \u001b[38;5;241m=\u001b[39m cross_val_score(super_learner, X_trn_transformado, Y_trn, cv\u001b[38;5;241m=\u001b[39mkfold, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRendimiento del modelo:\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\mlens\\ensemble\\base.py:514\u001b[0m, in \u001b[0;36mBaseEnsemble.fit\u001b[1;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_selection:\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id_train\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[1;32m--> 514\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend:\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;66;03m# fit_transform\u001b[39;00m\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\mlens\\ensemble\\base.py:158\u001b[0m, in \u001b[0;36mSequential.fit\u001b[1;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m f, t0 \u001b[38;5;241m=\u001b[39m print_job(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ParallelProcessing(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[0;32m    157\u001b[0m                         \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m0\u001b[39m)) \u001b[38;5;28;01mas\u001b[39;00m manager:\n\u001b[1;32m--> 158\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmanager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[0;32m    161\u001b[0m     print_time(t0, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:<35}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFit complete\u001b[39m\u001b[38;5;124m\"\u001b[39m), file\u001b[38;5;241m=\u001b[39mf)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\mlens\\parallel\\backend.py:673\u001b[0m, in \u001b[0;36mParallelProcessing.stack\u001b[1;34m(self, caller, job, X, y, path, return_preds, warm_start, split, **kwargs)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Stacked parallel task mapping.\u001b[39;00m\n\u001b[0;32m    613\u001b[0m \n\u001b[0;32m    614\u001b[0m \u001b[38;5;124;03mRun stacked tasks in caller in parallel.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;124;03m    Prediction array(s).\u001b[39;00m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    670\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize(\n\u001b[0;32m    671\u001b[0m     job\u001b[38;5;241m=\u001b[39mjob, X\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my, path\u001b[38;5;241m=\u001b[39mpath, warm_start\u001b[38;5;241m=\u001b[39mwarm_start,\n\u001b[0;32m    672\u001b[0m     return_preds\u001b[38;5;241m=\u001b[39mreturn_preds, split\u001b[38;5;241m=\u001b[39msplit, stack\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 673\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcaller\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcaller\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\mlens\\parallel\\backend.py:718\u001b[0m, in \u001b[0;36mParallelProcessing.process\u001b[1;34m(self, caller, out, **kwargs)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m caller:\n\u001b[0;32m    716\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m--> 718\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_partial_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    720\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m task\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m return_names:\n\u001b[0;32m    721\u001b[0m         out\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_preds(dtype\u001b[38;5;241m=\u001b[39m_dtype(task)))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\mlens\\parallel\\backend.py:739\u001b[0m, in \u001b[0;36mParallelProcessing._partial_process\u001b[1;34m(self, task, parallel, **kwargs)\u001b[0m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39m__no_output__:\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gen_prediction_array(task, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob\u001b[38;5;241m.\u001b[39mjob, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__threading__)\n\u001b[1;32m--> 739\u001b[0m \u001b[43mtask\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39m__no_output__ \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(task, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_feature_prop\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_propagate_features(task)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\mlens\\parallel\\layer.py:151\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, args, parallel)\u001b[0m\n\u001b[0;32m    148\u001b[0m     safe_print(msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLearners ...\u001b[39m\u001b[38;5;124m'\u001b[39m), file\u001b[38;5;241m=\u001b[39mf, end\u001b[38;5;241m=\u001b[39me2)\n\u001b[0;32m    149\u001b[0m     t1 \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m--> 151\u001b[0m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43msublearner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_threading\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlearner\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearners\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msublearner\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlearner\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    156\u001b[0m     print_time(t1, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m'\u001b[39m, file\u001b[38;5;241m=\u001b[39mf)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\mlens\\externals\\joblib\\parallel.py:783\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# case of Parallel used with an exhausted iterator.\u001b[39;00m\n\u001b[1;32m--> 783\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\mlens\\externals\\joblib\\parallel.py:624\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    621\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m--> 624\u001b[0m     tasks \u001b[38;5;241m=\u001b[39m \u001b[43mBatchedCalls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    625\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tasks) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    626\u001b[0m         \u001b[38;5;66;03m# No more tasks available in the iterator: tell caller to stop.\u001b[39;00m\n\u001b[0;32m    627\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\mlens\\externals\\joblib\\parallel.py:131\u001b[0m, in \u001b[0;36mBatchedCalls.__init__\u001b[1;34m(self, iterator_slice)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, iterator_slice):\n\u001b[1;32m--> 131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterator_slice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\mlens\\parallel\\layer.py:151\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    148\u001b[0m     safe_print(msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLearners ...\u001b[39m\u001b[38;5;124m'\u001b[39m), file\u001b[38;5;241m=\u001b[39mf, end\u001b[38;5;241m=\u001b[39me2)\n\u001b[0;32m    149\u001b[0m     t1 \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m--> 151\u001b[0m parallel\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43msublearner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_threading\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlearner\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearners\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msublearner\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlearner\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    156\u001b[0m     print_time(t1, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m'\u001b[39m, file\u001b[38;5;241m=\u001b[39mf)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\mlens\\parallel\\learner.py:583\u001b[0m, in \u001b[0;36mBaseNode.gen_fit\u001b[1;34m(self, X, y, P)\u001b[0m\n\u001b[0;32m    579\u001b[0m         i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    581\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__only_all__:\n\u001b[0;32m    582\u001b[0m     \u001b[38;5;66;03m# Fit sub-learners on cv folds\u001b[39;00m\n\u001b[1;32m--> 583\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    584\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note that we bump index[1] by 1 to have index[1] start at 1\u001b[39;49;00m\n\u001b[0;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_partitions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\mlens\\index\\base.py:253\u001b[0m, in \u001b[0;36mBaseIndex.generate\u001b[1;34m(self, X, as_array)\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;66;03m# Need to call fit to continue\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[1;32m--> 253\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtei\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gen_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mas_array\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtri\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_range\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtri\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\mlens\\index\\base.py:184\u001b[0m, in \u001b[0;36mBaseIndex._gen_indices\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m ((\u001b[38;5;241m0\u001b[39m, n_samples),), (\u001b[38;5;241m0\u001b[39m, n_samples)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# Get the length of the test sets\u001b[39;00m\n\u001b[1;32m--> 184\u001b[0m     tei_len \u001b[38;5;241m=\u001b[39m \u001b[43mpartition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m     last \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m size \u001b[38;5;129;01min\u001b[39;00m tei_len:\n\u001b[0;32m    188\u001b[0m \n\u001b[0;32m    189\u001b[0m         \u001b[38;5;66;03m# Test set\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\mlens\\index\\base.py:83\u001b[0m, in \u001b[0;36mpartition\u001b[1;34m(n, p)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpartition\u001b[39m(n, p):\n\u001b[0;32m     54\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get partition sizes for a given number of samples and partitions.\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m    This method will give an array containing the sizes of ``p`` partitions\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;124;03m    array([3, 3, 2])\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m     sizes \u001b[38;5;241m=\u001b[39m (n \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m p) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mones(p, dtype\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint\u001b[49m)\n\u001b[0;32m     84\u001b[0m     sizes[:n \u001b[38;5;241m%\u001b[39m p] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sizes\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\__init__.py:338\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    333\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    334\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    335\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[1;32m--> 338\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtesting\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "from mlens.ensemble import SuperLearner\n",
    "Y_trn = Y_trn.astype(int)\n",
    "def entrenar_modelo_super_aprendiz(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    semilla = 7 \n",
    "    kfold = KFold(n_splits=10, random_state=semilla, shuffle=True)\n",
    "    modelo3 = ExtraTreesClassifier(n_estimators=400, max_features=None, bootstrap=False, \n",
    "                                   max_depth=11, min_samples_split=4, min_samples_leaf=1)\n",
    "\n",
    "    modelo4 = RandomForestClassifier(n_estimators=500, max_features=None,\n",
    "                                     min_samples_split=5, max_depth=3, min_samples_leaf=1)\n",
    "    model = DecisionTreeClassifier(criterion='gini', \n",
    "                                   max_depth=6, max_features=None,  min_samples_leaf=9, \n",
    "                                   min_samples_split=2, \n",
    "                                   random_state=10, splitter='random')\n",
    "\n",
    "    modelo5 = BaggingClassifier(estimator=model, n_estimators=50, random_state=semilla,\n",
    "                                bootstrap=True, bootstrap_features=False, \n",
    "                                max_features=0.9, max_samples=0.95)\n",
    "\n",
    "    modelo6 = DecisionTreeClassifier(criterion='gini', max_depth=6, max_features=None, \n",
    "                                     min_samples_leaf=9, min_samples_split=2, \n",
    "                                     random_state=10, splitter='random')\n",
    "    \n",
    "    estimadores = [('Extratrees', modelo3), ('Random Forest', modelo4), \n",
    "                   ('Bagging', modelo5), ('Decision tree', modelo6)]\n",
    "    \n",
    "    super_learner = SuperLearner(folds=10, random_state=semilla, verbose=2)\n",
    "    super_learner.add(estimadores)\n",
    "    \n",
    "    estimador_final = ExtraTreesClassifier(n_estimators=100, max_features=None,\n",
    "                                           bootstrap=False, max_depth=11, min_samples_split=4, \n",
    "                                           min_samples_leaf=1)\n",
    "    \n",
    "    super_learner.add_meta(estimador_final)\n",
    "    \n",
    "    super_learner.fit(X_trn_transformado, Y_trn)\n",
    "    resultados = cross_val_score(super_learner, X_trn_transformado, Y_trn, cv=kfold, scoring='accuracy')\n",
    "    \n",
    "    print(\"Rendimiento del modelo:\") \n",
    "    print(\"Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold:\", resultados.mean() * 100, \"%\") \n",
    "    return super_learner\n",
    "\n",
    "Y_trn = Y_trn.astype(int)\n",
    "X_trn = X_trn.astype(int)\n",
    "X_trn_transformado = X_trn.astype(int)\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_superaprendiz = entrenar_modelo_super_aprendiz(X_trn, Y_trn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy\n",
    "print(numpy.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RED NEURONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 1.0184\n",
      "Epoch [20/100], Loss: 0.7499\n",
      "Epoch [30/100], Loss: 0.6183\n",
      "Epoch [40/100], Loss: 0.5524\n",
      "Epoch [50/100], Loss: 0.5122\n",
      "Epoch [60/100], Loss: 0.4840\n",
      "Epoch [70/100], Loss: 0.4635\n",
      "Epoch [80/100], Loss: 0.4482\n",
      "Epoch [90/100], Loss: 0.4362\n",
      "Epoch [100/100], Loss: 0.4264\n",
      "Accuracy: 81.94%\n",
      "Precisión:  0.7912353035379575\n",
      "Exhaustividad (Recall):  0.8194444444444444\n",
      "Puntuación F1:  0.8031387356218563\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "def train_neural_network(X_train, y_train, input_size, hidden_size, num_classes, num_epochs=100, learning_rate=0.001):\n",
    "    # Convertir datos de entrenamiento a tensores de PyTorch\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "    \n",
    "    # Inicializar modelo y función de pérdida\n",
    "    model = NeuralNetwork(input_size, hidden_size, num_classes)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Entrenamiento del modelo\n",
    "    for epoch in range(num_epochs):\n",
    "        # Forward pass y pérdida\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        \n",
    "        # Backward pass y optimización\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    # Convertir datos de prueba a tensores de PyTorch\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "    # Obtener las predicciones del modelo\n",
    "    outputs = model(X_test_tensor)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # Calcular las métricas del modelo\n",
    "    accuracy = accuracy_score(y_test_tensor.numpy(), predicted.numpy())\n",
    "    precision = precision_score(y_test, predicted.numpy(), average='weighted')\n",
    "    recall = recall_score(y_test, predicted.numpy(), average='weighted')\n",
    "    f1 = f1_score(y_test, predicted.numpy(), average='weighted')\n",
    "\n",
    "    print('Accuracy: {:.2f}%'.format(accuracy * 100))\n",
    "    print(\"Precisión: \", precision)\n",
    "    print(\"Exhaustividad (Recall): \", recall)\n",
    "    print(\"Puntuación F1: \", f1)\n",
    "\n",
    "X_train_array = X_trn.values\n",
    "X_test_array = X_tst.values\n",
    "Y_trn = Y_trn \n",
    "input_size = X_trn.shape[1]\n",
    "num_classes = 4\n",
    "hidden_size = 170\n",
    "\n",
    "# Supongamos que X_train, y_train, X_test, y_test son tus datos de entrenamiento y prueba\n",
    "modelo_red_reuronal = train_neural_network(X_train_array , Y_trn, input_size, hidden_size, num_classes)\n",
    "evaluate_model(modelo_red_reuronal, X_test_array , Y_tst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MLENS] backend: threading\n"
     ]
    }
   ],
   "source": [
    "from mlens.ensemble import SuperLearner"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
