{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from numpy import set_printoptions\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "pd.options.display.max_columns=None\n",
    "import seaborn as sns \n",
    "from pandas import read_csv\n",
    "import io\n",
    "import base64\n",
    "import json\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.drawing.image import Image as XLImage\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "#from mlens.ensemble import SuperLearner\n",
    "\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CARGUE DE DATOS Y CONEXIÓN A DRIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=899973764197-biu188dkvsgi2al0fh29udm7keak0lh0.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A57561%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.readonly&state=1cNYig9AdB9beqckwKXXDxbUOwZplV&access_type=offline\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando industrial10.csv: 100%\n",
      "Descargando industrial9.csv: 100%\n",
      "Descargando industrial8.csv: 100%\n",
      "Descargando industrial7.csv: 100%\n",
      "Descargando industrial6.csv: 100%\n",
      "Descargando industrial5.csv: 100%\n",
      "Descargando industrial3.csv: 100%\n",
      "Descargando industrial4.csv: 100%\n",
      "Descargando industrial2.csv: 100%\n",
      "Descargando industrial1.csv: 100%\n",
      "Descarga completa\n",
      "Archivos descargados:\n",
      "industrial1.csv\n",
      "industrial10.csv\n",
      "industrial2.csv\n",
      "industrial3.csv\n",
      "industrial4.csv\n",
      "industrial5.csv\n",
      "industrial6.csv\n",
      "industrial7.csv\n",
      "industrial8.csv\n",
      "industrial9.csv\n"
     ]
    }
   ],
   "source": [
    "SCOPES = ['https://www.googleapis.com/auth/drive.readonly']\n",
    "\n",
    "creds = None\n",
    "if os.path.exists('token.json'):\n",
    "    creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "if not creds or not creds.valid:\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "        creds.refresh(Request())\n",
    "    else:\n",
    "        flow = InstalledAppFlow.from_client_secrets_file('C:/Users/Intevo/Desktop/UNIVERSIDAD DISTRITAL PROYECTO FOLDER/credentials.json', SCOPES) # Reemplazar con la ruta correcta\n",
    "        creds = flow.run_local_server(port=0)\n",
    "    with open('C:/Users/Intevo/Desktop/UNIVERSIDAD DISTRITAL PROYECTO FOLDER/token.json', 'w') as token:\n",
    "        token.write(creds.to_json())\n",
    "        \n",
    "# Crear una instancia de la API de Drive\n",
    "drive_service = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "# ID de la carpeta de Google Drive\n",
    "folder_id = '1hQeetmO4XIObUefS_nzePqKqq3VksUEC'\n",
    "\n",
    "# Ruta de destino para guardar los archivos descargados\n",
    "save_path = 'C:/Users/Intevo/Desktop/UNIVERSIDAD DISTRITAL PROYECTO FOLDER/UNIVERSIDAD-DISTRITAL-PROYECTO/MÓDULO ANALÍTICA PREDICTIVA/DATOS'  # Reemplazar con la ruta deseada\n",
    "\n",
    "# Función para descargar archivos de la carpeta de Drive\n",
    "def download_folder(folder_id, save_path):\n",
    "    results = drive_service.files().list(\n",
    "        q=f\"'{folder_id}' in parents and trashed=false\",\n",
    "        fields='files(id, name)').execute()\n",
    "    items = results.get('files', [])\n",
    "    for item in items:\n",
    "        file_id = item['id']\n",
    "        file_name = item['name']\n",
    "        request = drive_service.files().get_media(fileId=file_id)\n",
    "        fh = io.FileIO(os.path.join(save_path, file_name), 'wb')\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "        done = False\n",
    "        while done is False:\n",
    "            status, done = downloader.next_chunk()\n",
    "            print(f\"Descargando {file_name}: {int(status.progress() * 100)}%\")\n",
    "    print(\"Descarga completa\")\n",
    "\n",
    "# Descargar archivos de la carpeta\n",
    "download_folder(folder_id, save_path)\n",
    "\n",
    "# Listar archivos descargados\n",
    "files = os.listdir(save_path)\n",
    "print(\"Archivos descargados:\")\n",
    "for file in files:\n",
    "    print(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nvariables_por_carrera = {\\n    'industrial': {\\n        '1': ['PG_ICFES', 'CON_MAT_ICFES', 'FISICA_ICFES','QUIMICA_ICFES','IDIOMA_ICFES','LOCALIDAD','RENDIMIENTO_UNO', 'PROMEDIO_UNO'],\\n        '2': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'FISICA_ICFES', 'BIOLOGIA_ICFES', 'IDIOMA_ICFES', 'LOCALIDAD', 'PROMEDIO_UNO', 'CAR_UNO', 'NCC_UNO', 'NAA_UNO', 'NOTA_DIFERENCIAL', 'NOTA_DIBUJO', 'NOTA_QUIMICA', 'NOTA_CFJC', 'NOTA_TEXTOS', 'NOTA_SEMINARIO', 'NOTA_EE_UNO','RENDIMIENTO_DOS', 'PROMEDIO_DOS'],\\n        '3': ['PROMEDIO_UNO', 'NAA_UNO', 'NOTA_DIFERENCIAL', 'NOTA_DIBUJO', 'NOTA_TEXTOS', 'NOTA_EE_UNO', 'PROMEDIO_DOS', 'NCC_DOS', 'NCA_DOS', 'NAA_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_PBASICA', 'NOTA_EE_DOS', 'RENDIMIENTO_TRES', 'PROMEDIO_TRES'],\\n        '4': ['PROMEDIO_UNO', 'NOTA_EE_UNO', 'PROMEDIO_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'NAA_TRES', 'NOTA_MULTIVARIADO', 'NOTA_ESTADISTICA_UNO', 'NOTA_TERMODINAMICA', 'NOTA_TGS', 'NOTA_EE_TRES','RENDIMIENTO_CUATRO', 'PROMEDIO_CUATRO'],\\n        '5': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_EE_DOS','PROMEDIO_TRES', 'NAA_TRES', 'NOTA_MULTIVARIADO', 'NOTA_TERMODINAMICA', 'NOTA_ECUACIONES', 'NOTA_ESTADISTICA_DOS', 'NOTA_FISICA_DOS', 'NOTA_MECANICA', 'NOTA_PROCESOSQ', 'RENDIMIENTO_CINCO', 'RENDIMIENTO_CINCO'],\\n        '6': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_ADMINISTRACION', 'NOTA_LENGUA_UNO', 'NOTA_EI_UNO', 'NOTA_EI_DOS', 'RENDIMIENTO_SEIS', 'PROMEDIO_SEIS'],\\n        '7': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_LENGUA_UNO', 'NOTA_EI_DOS', 'PROMEDIO_SEIS', 'NCA_SEIS', 'NOTA_PLINEAL', 'NOTA_DISE O', 'NOTA_EI_TRES','RENDIMIENTO_SIETE', 'PROMEDIO_SIETE'],\\n        '8': ['PROMEDIO_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_LENGUA_UNO','PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'RENDIMIENTO_OCHO', 'PROMEDIO_OCHO'],\\n        '9': ['PROMEDIO_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'PROMEDIO_OCHO', 'NCC_OCHO', 'NOTA_LOG_UNO', 'NOTA_GOPERACIONES','NOTA_CALIDAD_DOS', 'NOTA_LENGUA_DOS', 'NOTA_CONTEXTO', 'RENDIMIENTO_NUEVE', 'PROMEDIO_NUEVE'],\\n        '10': ['PROMEDIO_SEIS', 'PROMEDIO_SIETE', 'PROMEDIO_OCHO', 'NOTA_CALIDAD_DOS', 'PROMEDIO_NUEVE', 'NAA_NUEVE', 'NOTA_GRADO_UNO', 'NOTA_LOG_DOS', 'NOTA_FINANZAS', 'NOTA_HISTORIA', 'RENDIMIENTO_DIEZ', 'PROMEDIO_DIEZ']\\n    },\\n    'sistemas': {\\n        '1': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'FISICA_ICFES', 'QUIMICA_ICFES', 'IDIOMA_ICFES', 'LOCALIDAD', 'RENDIMIENTO_UNO', 'PROMEDIO_UNO'],\\n        '2': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'IDIOMA_ICFES', 'PROMEDIO_UNO', 'NOTA_DIFERENCIAL', 'NOTA_PROG_BASICA', 'NOTA_CATEDRA_FJC', 'NOTA_TEXTOS', 'NOTA_SEMINARIO', 'NOTA_CATEDRA_DEM', 'NOTA_CATEDRA_CON', 'NOTA_LOGICA', 'RENDIMIENTO_DOS', 'PROMEDIO_DOS'],\\n        '3': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'IDIOMA_ICFES', 'PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_PROG_BASICA', 'NOTA_TEXTOS', 'NOTA_CATEDRA_DEM', 'NOTA_INTEGRAL', 'NOTA_PROG_ORIENTADA', 'NOTA_ETICA', 'RENDIMIENTO_TRES', 'PROMEDIO_TRES'],\\n        '4': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'IDIOMA_ICFES', 'PROMEDIO_UNO', 'PROMEDIO_DOS', 'PROMEDIO_TRES', 'NOTA_PROG_BASICA', 'NOTA_TEXTOS', 'NOTA_CATEDRA_DEM', 'NOTA_INTEGRAL', 'NOTA_PROG_ORIENTADA', 'NOTA_ETICA', 'NOTA_FISICA_DOS', 'NOTA_TGS', 'NOTA_PROG_AVANZADA', 'RENDIMIENTO_CUATRO', 'PROMEDIO_CUATRO'],\\n        '5': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NAA_TRES', 'NOTA_MULTIVARIADO', 'NOTA_TERMODINAMICA', 'NOTA_ECUACIONES', 'NOTA_ESTADISTICA_DOS', 'NOTA_FISICA_DOS', 'NOTA_MECANICA', 'NOTA_PROCESOSQ', 'RENDIMIENTO_CINCO', 'PROMEDIO_CINCO'],\\n        '6': ['PROMEDIO_UNO', 'NOTA_EE_UNO', 'PROMEDIO_DOS', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_ECONOMIA_UNO', 'NOTA_FISICA_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_ADMINISTRACION', 'NOTA_LENGUA_UNO', 'NOTA_EI_UNO', 'NOTA_EI_DOS', 'RENDIMIENTO_SEIS', 'PROMEDIO_SEIS'],\\n        '7': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_LENGUA_UNO', 'NOTA_EI_DOS', 'PROMEDIO_SEIS', 'NCA_SEIS', 'NOTA_PLINEAL', 'NOTA_DISE O', 'NOTA_EI_TRES', 'RENDIMIENTO_SIETE', 'PROMEDIO_SIETE'],\\n        '8': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_LENGUA_UNO', 'PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'RENDIMIENTO_OCHO', 'PROMEDIO_OCHO'],\\n        '9': ['PROMEDIO_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'PROMEDIO_OCHO', 'NCC_OCHO', 'NOTA_LOG_UNO', 'NOTA_GOPERACIONES', 'NOTA_CALIDAD_DOS', 'NOTA_LENGUA_DOS', 'NOTA_CONTEXTO', 'RENDIMIENTO_NUEVE', 'PROMEDIO_NUEVE'],\\n        '10': ['PROMEDIO_SEIS', 'PROMEDIO_SIETE', 'PROMEDIO_OCHO', 'NOTA_CALIDAD_DOS', 'PROMEDIO_NUEVE', 'NAA_NUEVE', 'NOTA_GRADO_UNO', 'NOTA_LOG_DOS', 'NOTA_FINANZAS', 'NOTA_HISTORIA', 'RENDIMIENTO_DIEZ', 'PROMEDIO_DIEZ']\\n    },\\n    'catastral': {\\n        '1': ['variable1_catastral', 'variable2_catastral', 'variable3_catastral'],\\n        '2': ['variable4_catastral', 'variable5_catastral', 'variable6_catastral']\\n    }\\n}\\n\""
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "variables_por_carrera = {\n",
    "    'industrial': {\n",
    "        '1': ['PG_ICFES', 'CON_MAT_ICFES', 'FISICA_ICFES','QUIMICA_ICFES','IDIOMA_ICFES','LOCALIDAD','RENDIMIENTO_UNO', 'PROMEDIO_UNO'],\n",
    "        '2': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'FISICA_ICFES', 'BIOLOGIA_ICFES', 'IDIOMA_ICFES', 'LOCALIDAD', 'PROMEDIO_UNO', 'CAR_UNO', 'NCC_UNO', 'NAA_UNO', 'NOTA_DIFERENCIAL', 'NOTA_DIBUJO', 'NOTA_QUIMICA', 'NOTA_CFJC', 'NOTA_TEXTOS', 'NOTA_SEMINARIO', 'NOTA_EE_UNO','RENDIMIENTO_DOS', 'PROMEDIO_DOS'],\n",
    "        '3': ['PROMEDIO_UNO', 'NAA_UNO', 'NOTA_DIFERENCIAL', 'NOTA_DIBUJO', 'NOTA_TEXTOS', 'NOTA_EE_UNO', 'PROMEDIO_DOS', 'NCC_DOS', 'NCA_DOS', 'NAA_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_PBASICA', 'NOTA_EE_DOS', 'RENDIMIENTO_TRES', 'PROMEDIO_TRES'],\n",
    "        '4': ['PROMEDIO_UNO', 'NOTA_EE_UNO', 'PROMEDIO_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'NAA_TRES', 'NOTA_MULTIVARIADO', 'NOTA_ESTADISTICA_UNO', 'NOTA_TERMODINAMICA', 'NOTA_TGS', 'NOTA_EE_TRES','RENDIMIENTO_CUATRO', 'PROMEDIO_CUATRO'],\n",
    "        '5': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_EE_DOS','PROMEDIO_TRES', 'NAA_TRES', 'NOTA_MULTIVARIADO', 'NOTA_TERMODINAMICA', 'NOTA_ECUACIONES', 'NOTA_ESTADISTICA_DOS', 'NOTA_FISICA_DOS', 'NOTA_MECANICA', 'NOTA_PROCESOSQ', 'RENDIMIENTO_CINCO', 'RENDIMIENTO_CINCO'],\n",
    "        '6': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_ADMINISTRACION', 'NOTA_LENGUA_UNO', 'NOTA_EI_UNO', 'NOTA_EI_DOS', 'RENDIMIENTO_SEIS', 'PROMEDIO_SEIS'],\n",
    "        '7': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_LENGUA_UNO', 'NOTA_EI_DOS', 'PROMEDIO_SEIS', 'NCA_SEIS', 'NOTA_PLINEAL', 'NOTA_DISE O', 'NOTA_EI_TRES','RENDIMIENTO_SIETE', 'PROMEDIO_SIETE'],\n",
    "        '8': ['PROMEDIO_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_LENGUA_UNO','PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'RENDIMIENTO_OCHO', 'PROMEDIO_OCHO'],\n",
    "        '9': ['PROMEDIO_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'PROMEDIO_OCHO', 'NCC_OCHO', 'NOTA_LOG_UNO', 'NOTA_GOPERACIONES','NOTA_CALIDAD_DOS', 'NOTA_LENGUA_DOS', 'NOTA_CONTEXTO', 'RENDIMIENTO_NUEVE', 'PROMEDIO_NUEVE'],\n",
    "        '10': ['PROMEDIO_SEIS', 'PROMEDIO_SIETE', 'PROMEDIO_OCHO', 'NOTA_CALIDAD_DOS', 'PROMEDIO_NUEVE', 'NAA_NUEVE', 'NOTA_GRADO_UNO', 'NOTA_LOG_DOS', 'NOTA_FINANZAS', 'NOTA_HISTORIA', 'RENDIMIENTO_DIEZ', 'PROMEDIO_DIEZ']\n",
    "    },\n",
    "    'sistemas': {\n",
    "        '1': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'FISICA_ICFES', 'QUIMICA_ICFES', 'IDIOMA_ICFES', 'LOCALIDAD', 'RENDIMIENTO_UNO', 'PROMEDIO_UNO'],\n",
    "        '2': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'IDIOMA_ICFES', 'PROMEDIO_UNO', 'NOTA_DIFERENCIAL', 'NOTA_PROG_BASICA', 'NOTA_CATEDRA_FJC', 'NOTA_TEXTOS', 'NOTA_SEMINARIO', 'NOTA_CATEDRA_DEM', 'NOTA_CATEDRA_CON', 'NOTA_LOGICA', 'RENDIMIENTO_DOS', 'PROMEDIO_DOS'],\n",
    "        '3': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'IDIOMA_ICFES', 'PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_PROG_BASICA', 'NOTA_TEXTOS', 'NOTA_CATEDRA_DEM', 'NOTA_INTEGRAL', 'NOTA_PROG_ORIENTADA', 'NOTA_ETICA', 'RENDIMIENTO_TRES', 'PROMEDIO_TRES'],\n",
    "        '4': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'IDIOMA_ICFES', 'PROMEDIO_UNO', 'PROMEDIO_DOS', 'PROMEDIO_TRES', 'NOTA_PROG_BASICA', 'NOTA_TEXTOS', 'NOTA_CATEDRA_DEM', 'NOTA_INTEGRAL', 'NOTA_PROG_ORIENTADA', 'NOTA_ETICA', 'NOTA_FISICA_DOS', 'NOTA_TGS', 'NOTA_PROG_AVANZADA', 'RENDIMIENTO_CUATRO', 'PROMEDIO_CUATRO'],\n",
    "        '5': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NAA_TRES', 'NOTA_MULTIVARIADO', 'NOTA_TERMODINAMICA', 'NOTA_ECUACIONES', 'NOTA_ESTADISTICA_DOS', 'NOTA_FISICA_DOS', 'NOTA_MECANICA', 'NOTA_PROCESOSQ', 'RENDIMIENTO_CINCO', 'PROMEDIO_CINCO'],\n",
    "        '6': ['PROMEDIO_UNO', 'NOTA_EE_UNO', 'PROMEDIO_DOS', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_ECONOMIA_UNO', 'NOTA_FISICA_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_ADMINISTRACION', 'NOTA_LENGUA_UNO', 'NOTA_EI_UNO', 'NOTA_EI_DOS', 'RENDIMIENTO_SEIS', 'PROMEDIO_SEIS'],\n",
    "        '7': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_LENGUA_UNO', 'NOTA_EI_DOS', 'PROMEDIO_SEIS', 'NCA_SEIS', 'NOTA_PLINEAL', 'NOTA_DISE O', 'NOTA_EI_TRES', 'RENDIMIENTO_SIETE', 'PROMEDIO_SIETE'],\n",
    "        '8': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_LENGUA_UNO', 'PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'RENDIMIENTO_OCHO', 'PROMEDIO_OCHO'],\n",
    "        '9': ['PROMEDIO_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'PROMEDIO_OCHO', 'NCC_OCHO', 'NOTA_LOG_UNO', 'NOTA_GOPERACIONES', 'NOTA_CALIDAD_DOS', 'NOTA_LENGUA_DOS', 'NOTA_CONTEXTO', 'RENDIMIENTO_NUEVE', 'PROMEDIO_NUEVE'],\n",
    "        '10': ['PROMEDIO_SEIS', 'PROMEDIO_SIETE', 'PROMEDIO_OCHO', 'NOTA_CALIDAD_DOS', 'PROMEDIO_NUEVE', 'NAA_NUEVE', 'NOTA_GRADO_UNO', 'NOTA_LOG_DOS', 'NOTA_FINANZAS', 'NOTA_HISTORIA', 'RENDIMIENTO_DIEZ', 'PROMEDIO_DIEZ']\n",
    "    },\n",
    "    'catastral': {\n",
    "        '1': ['variable1_catastral', 'variable2_catastral', 'variable3_catastral'],\n",
    "        '2': ['variable4_catastral', 'variable5_catastral', 'variable6_catastral']\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_por_carrera = {\n",
    "    'industrial': {\n",
    "        '1': ['PG_ICFES', 'CON_MAT_ICFES', 'FISICA_ICFES','QUIMICA_ICFES','IDIOMA_ICFES','LOCALIDAD','RENDIMIENTO_UNO'],\n",
    "        '2': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'FISICA_ICFES', 'BIOLOGIA_ICFES', 'IDIOMA_ICFES', 'LOCALIDAD', 'PROMEDIO_UNO', 'CAR_UNO', 'NCC_UNO', 'NAA_UNO', 'NOTA_DIFERENCIAL', 'NOTA_DIBUJO', 'NOTA_QUIMICA', 'NOTA_CFJC', 'NOTA_TEXTOS', 'NOTA_SEMINARIO', 'NOTA_EE_UNO','RENDIMIENTO_DOS'],\n",
    "        '3': ['PROMEDIO_UNO', 'NAA_UNO', 'NOTA_DIFERENCIAL', 'NOTA_DIBUJO', 'NOTA_TEXTOS', 'NOTA_EE_UNO', 'PROMEDIO_DOS', 'NCC_DOS', 'NCA_DOS', 'NAA_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_PBASICA', 'NOTA_EE_DOS', 'RENDIMIENTO_TRES'],\n",
    "        '4': ['PROMEDIO_UNO', 'NOTA_EE_UNO', 'PROMEDIO_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'NAA_TRES', 'NOTA_MULTIVARIADO', 'NOTA_ESTADISTICA_UNO', 'NOTA_TERMODINAMICA', 'NOTA_TGS', 'NOTA_EE_TRES','RENDIMIENTO_CUATRO'],\n",
    "        '5': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_EE_DOS','PROMEDIO_TRES', 'NAA_TRES', 'NOTA_MULTIVARIADO', 'NOTA_TERMODINAMICA', 'NOTA_ECUACIONES', 'NOTA_ESTADISTICA_DOS', 'NOTA_FISICA_DOS', 'NOTA_MECANICA', 'NOTA_PROCESOSQ', 'RENDIMIENTO_CINCO', 'RENDIMIENTO_CINCO'],\n",
    "        '6': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_ADMINISTRACION', 'NOTA_LENGUA_UNO', 'NOTA_EI_UNO', 'NOTA_EI_DOS', 'RENDIMIENTO_SEIS'],\n",
    "        '7': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_LENGUA_UNO', 'NOTA_EI_DOS', 'PROMEDIO_SEIS', 'NCA_SEIS', 'NOTA_PLINEAL', 'NOTA_DISE O', 'NOTA_EI_TRES','RENDIMIENTO_SIETE'],\n",
    "        '8': ['PROMEDIO_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_LENGUA_UNO','PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'RENDIMIENTO_OCHO'],\n",
    "        '9': ['PROMEDIO_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'PROMEDIO_OCHO', 'NCC_OCHO', 'NOTA_LOG_UNO', 'NOTA_GOPERACIONES','NOTA_CALIDAD_DOS', 'NOTA_LENGUA_DOS', 'NOTA_CONTEXTO', 'RENDIMIENTO_NUEVE'],\n",
    "        '10': ['PROMEDIO_SEIS', 'PROMEDIO_SIETE', 'PROMEDIO_OCHO', 'NOTA_CALIDAD_DOS', 'PROMEDIO_NUEVE', 'NAA_NUEVE', 'NOTA_GRADO_UNO', 'NOTA_LOG_DOS', 'NOTA_FINANZAS', 'NOTA_HISTORIA', 'RENDIMIENTO_DIEZ']\n",
    "    },\n",
    "    'sistemas': {\n",
    "        '1': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'FISICA_ICFES', 'QUIMICA_ICFES', 'IDIOMA_ICFES', 'LOCALIDAD', 'RENDIMIENTO_UNO'],\n",
    "        '2': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'IDIOMA_ICFES', 'PROMEDIO_UNO', 'NOTA_DIFERENCIAL', 'NOTA_PROG_BASICA', 'NOTA_CATEDRA_FJC', 'NOTA_TEXTOS', 'NOTA_SEMINARIO', 'NOTA_CATEDRA_DEM', 'NOTA_CATEDRA_CON', 'NOTA_LOGICA', 'RENDIMIENTO_DOS'],\n",
    "        '3': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'IDIOMA_ICFES', 'PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_PROG_BASICA', 'NOTA_TEXTOS', 'NOTA_CATEDRA_DEM', 'NOTA_INTEGRAL', 'NOTA_PROG_ORIENTADA', 'NOTA_ETICA', 'RENDIMIENTO_TRES'],\n",
    "        '4': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'IDIOMA_ICFES', 'PROMEDIO_UNO', 'PROMEDIO_DOS', 'PROMEDIO_TRES', 'NOTA_PROG_BASICA', 'NOTA_TEXTOS', 'NOTA_CATEDRA_DEM', 'NOTA_INTEGRAL', 'NOTA_PROG_ORIENTADA', 'NOTA_ETICA', 'NOTA_FISICA_DOS', 'NOTA_TGS', 'NOTA_PROG_AVANZADA', 'RENDIMIENTO_CUATRO'],\n",
    "        '5': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NAA_TRES', 'NOTA_MULTIVARIADO', 'NOTA_TERMODINAMICA', 'NOTA_ECUACIONES', 'NOTA_ESTADISTICA_DOS', 'NOTA_FISICA_DOS', 'NOTA_MECANICA', 'NOTA_PROCESOSQ', 'RENDIMIENTO_CINCO'],\n",
    "        '6': ['PROMEDIO_UNO', 'NOTA_EE_UNO', 'PROMEDIO_DOS', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_ECONOMIA_UNO', 'NOTA_FISICA_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_ADMINISTRACION', 'NOTA_LENGUA_UNO', 'NOTA_EI_UNO', 'NOTA_EI_DOS', 'RENDIMIENTO_SEIS'],\n",
    "        '7': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_LENGUA_UNO', 'NOTA_EI_DOS', 'PROMEDIO_SEIS', 'NCA_SEIS', 'NOTA_PLINEAL', 'NOTA_DISE O', 'NOTA_EI_TRES', 'RENDIMIENTO_SIETE'],\n",
    "        '8': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_LENGUA_UNO', 'PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'RENDIMIENTO_OCHO'],\n",
    "        '9': ['PROMEDIO_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'PROMEDIO_OCHO', 'NCC_OCHO', 'NOTA_LOG_UNO', 'NOTA_GOPERACIONES', 'NOTA_CALIDAD_DOS', 'NOTA_LENGUA_DOS', 'NOTA_CONTEXTO', 'RENDIMIENTO_NUEVE'],\n",
    "        '10': ['PROMEDIO_SEIS', 'PROMEDIO_SIETE', 'PROMEDIO_OCHO', 'NOTA_CALIDAD_DOS', 'PROMEDIO_NUEVE', 'NAA_NUEVE', 'NOTA_GRADO_UNO', 'NOTA_LOG_DOS', 'NOTA_FINANZAS', 'NOTA_HISTORIA', 'RENDIMIENTO_DIEZ']\n",
    "    },\n",
    "    'catastral': {\n",
    "        '1': ['variable1_catastral', 'variable2_catastral', 'variable3_catastral'],\n",
    "        '2': ['variable4_catastral', 'variable5_catastral', 'variable6_catastral']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_datos(carrera, semestre):\n",
    "    \n",
    "    ruta_archivo = f'C:/Users/Intevo/Desktop/UNIVERSIDAD DISTRITAL PROYECTO FOLDER/UNIVERSIDAD-DISTRITAL-PROYECTO/MÓDULO ANALÍTICA PREDICTIVA/DATOS/{carrera}{semestre}.csv'\n",
    "    datos = pd.read_csv(ruta_archivo,sep=\";\")\n",
    "    \n",
    "    return datos\n",
    "carrera=\"industrial\"\n",
    "semestre=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame con columnas filtradas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCALIDAD_COLEGIO</th>\n",
       "      <th>PG_ICFES</th>\n",
       "      <th>CON_MAT_ICFES</th>\n",
       "      <th>FISICA_ICFES</th>\n",
       "      <th>BIOLOGIA_ICFES</th>\n",
       "      <th>IDIOMA_ICFES</th>\n",
       "      <th>LOCALIDAD</th>\n",
       "      <th>PROMEDIO_UNO</th>\n",
       "      <th>CAR_UNO</th>\n",
       "      <th>NCC_UNO</th>\n",
       "      <th>NAA_UNO</th>\n",
       "      <th>NOTA_DIFERENCIAL</th>\n",
       "      <th>NOTA_DIBUJO</th>\n",
       "      <th>NOTA_QUIMICA</th>\n",
       "      <th>NOTA_CFJC</th>\n",
       "      <th>NOTA_TEXTOS</th>\n",
       "      <th>NOTA_SEMINARIO</th>\n",
       "      <th>NOTA_EE_UNO</th>\n",
       "      <th>RENDIMIENTO_DOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>472</td>\n",
       "      <td>65</td>\n",
       "      <td>63</td>\n",
       "      <td>59</td>\n",
       "      <td>62</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>478</td>\n",
       "      <td>62</td>\n",
       "      <td>58</td>\n",
       "      <td>59</td>\n",
       "      <td>53</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>465</td>\n",
       "      <td>78</td>\n",
       "      <td>66</td>\n",
       "      <td>49</td>\n",
       "      <td>88</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>15</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>491</td>\n",
       "      <td>72</td>\n",
       "      <td>56</td>\n",
       "      <td>65</td>\n",
       "      <td>53</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>464</td>\n",
       "      <td>67</td>\n",
       "      <td>64</td>\n",
       "      <td>62</td>\n",
       "      <td>53</td>\n",
       "      <td>20</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2634</th>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>58</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2635</th>\n",
       "      <td>0</td>\n",
       "      <td>347</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>19</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>48</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2636</th>\n",
       "      <td>0</td>\n",
       "      <td>348</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>68</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2637</th>\n",
       "      <td>0</td>\n",
       "      <td>340</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>63</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>0</td>\n",
       "      <td>351</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>70</td>\n",
       "      <td>7</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>46</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2639 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LOCALIDAD_COLEGIO  PG_ICFES  CON_MAT_ICFES  FISICA_ICFES  \\\n",
       "0                    20       472             65            63   \n",
       "1                     0       478             62            58   \n",
       "2                    20       465             78            66   \n",
       "3                    10       491             72            56   \n",
       "4                    20       464             67            64   \n",
       "...                 ...       ...            ...           ...   \n",
       "2634                  0       342             68             0   \n",
       "2635                  0       347             69             0   \n",
       "2636                  0       348             67             0   \n",
       "2637                  0       340             70             0   \n",
       "2638                  0       351             69             0   \n",
       "\n",
       "      BIOLOGIA_ICFES  IDIOMA_ICFES  LOCALIDAD  PROMEDIO_UNO  CAR_UNO  NCC_UNO  \\\n",
       "0                 59            62          8            39        0        9   \n",
       "1                 59            53          8            31        1       19   \n",
       "2                 49            88         19            30        1       21   \n",
       "3                 65            53         10            31        1       21   \n",
       "4                 62            53         20            36        0       15   \n",
       "...              ...           ...        ...           ...      ...      ...   \n",
       "2634              68            58         11            31        0       10   \n",
       "2635              71            71         19            36        0       15   \n",
       "2636              67            68         11            29        0       13   \n",
       "2637              67            63         11            31        0       10   \n",
       "2638              63            70          7            41        0        8   \n",
       "\n",
       "      NAA_UNO  NOTA_DIFERENCIAL  NOTA_DIBUJO  NOTA_QUIMICA  NOTA_CFJC  \\\n",
       "0           4                35            0            45         40   \n",
       "1           6                22           30            40         35   \n",
       "2           5                30           23            35         40   \n",
       "3           5                20           40            35         40   \n",
       "4           7                30           35            40         40   \n",
       "...       ...               ...          ...           ...        ...   \n",
       "2634        4                24           33             0         35   \n",
       "2635        6                41           28            30         38   \n",
       "2636        4                25           36            30         30   \n",
       "2637        4                28           33             0         34   \n",
       "2638        5                 0           31             0         34   \n",
       "\n",
       "      NOTA_TEXTOS  NOTA_SEMINARIO  NOTA_EE_UNO  RENDIMIENTO_DOS  \n",
       "0               0              40            0                1  \n",
       "1              30              40           36                2  \n",
       "2              15              40           40                1  \n",
       "3              30              40            0                2  \n",
       "4              35              35           45                2  \n",
       "...           ...             ...          ...              ...  \n",
       "2634           37              43            0                1  \n",
       "2635           39              48           38                1  \n",
       "2636           27              37            0                1  \n",
       "2637           30              39            0                1  \n",
       "2638           45              46           50                1  \n",
       "\n",
       "[2639 rows x 19 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos = cargar_datos(carrera, semestre)\n",
    "columnas_filtradas = variables_por_carrera[carrera][semestre]\n",
    "df = datos[columnas_filtradas]\n",
    "print(\"DataFrame con columnas filtradas:\")\n",
    "df=df.astype(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separación de datos usando Pandas\n",
      "(2639, 18) (2639, 1)\n"
     ]
    }
   ],
   "source": [
    "X=df.loc[:, ~df.columns.str.contains('RENDIMIENTO')]\n",
    "Y = df.loc[:, df.columns.str.contains('RENDIMIENTO')]                                                      \n",
    "print(\"Separación de datos usando Pandas\") \n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2639, 18) (2639,)\n"
     ]
    }
   ],
   "source": [
    "X = X.astype('float32')                         \n",
    "Y = LabelEncoder().fit_transform(Y.astype('str'))                \n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor 0 aparece 1121 veces\n",
      "El valor 1 aparece 1412 veces\n",
      "El valor 2 aparece 103 veces\n",
      "El valor 3 aparece 3 veces\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "frecuencias = Counter(Y)\n",
    "for valor, frecuencia in frecuencias.items():\n",
    "    print(f\"El valor {valor} aparece {frecuencia} veces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRANSFORMACIÓN DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.220e+00  1.211e+00 -6.616e-01  7.632e-01 -3.457e-01 -1.739e-03\n",
      "  -6.865e-01  1.419e+00 -1.149e+00 -2.320e+00 -5.930e-01  9.885e-01\n",
      "  -2.310e+00  2.012e+00  4.505e-01 -2.261e+00  4.796e-01 -1.137e+00]\n",
      " [-1.675e+00  1.339e+00 -9.879e-01  6.658e-01 -3.457e-01 -7.067e-01\n",
      "  -6.865e-01 -1.514e-01  1.495e-01  2.141e-01  5.492e-01 -5.261e-01\n",
      "  -2.822e-01  1.378e+00 -3.776e-01 -4.596e-01  4.796e-01  7.941e-01]\n",
      " [ 1.220e+00  1.062e+00  7.691e-01  8.197e-01 -1.556e+00  2.110e+00\n",
      "   1.199e+00 -3.103e-01  1.495e-01  5.505e-01 -5.578e-02  3.773e-01\n",
      "  -9.902e-01  7.732e-01  4.505e-01 -1.622e+00  4.796e-01  8.704e-01]\n",
      " [-2.308e-02  1.622e+00  1.055e-01  6.257e-01  3.518e-01 -7.067e-01\n",
      "  -3.061e-01 -1.514e-01  1.495e-01  5.505e-01 -5.578e-02 -7.358e-01\n",
      "   9.297e-01  7.732e-01  4.505e-01 -4.596e-01  4.796e-01 -1.137e+00]\n",
      " [ 1.220e+00  1.041e+00 -4.432e-01  7.822e-01  5.507e-03 -7.067e-01\n",
      "   1.352e+00  7.658e-01 -1.149e+00 -5.846e-01  1.219e+00  3.773e-01\n",
      "   2.954e-01  1.378e+00  4.505e-01  1.414e-02 -1.780e-01  9.576e-01]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCALIDAD_COLEGIO</th>\n",
       "      <th>PG_ICFES</th>\n",
       "      <th>CON_MAT_ICFES</th>\n",
       "      <th>FISICA_ICFES</th>\n",
       "      <th>BIOLOGIA_ICFES</th>\n",
       "      <th>IDIOMA_ICFES</th>\n",
       "      <th>LOCALIDAD</th>\n",
       "      <th>PROMEDIO_UNO</th>\n",
       "      <th>CAR_UNO</th>\n",
       "      <th>NCC_UNO</th>\n",
       "      <th>NAA_UNO</th>\n",
       "      <th>NOTA_DIFERENCIAL</th>\n",
       "      <th>NOTA_DIBUJO</th>\n",
       "      <th>NOTA_QUIMICA</th>\n",
       "      <th>NOTA_CFJC</th>\n",
       "      <th>NOTA_TEXTOS</th>\n",
       "      <th>NOTA_SEMINARIO</th>\n",
       "      <th>NOTA_EE_UNO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.219727</td>\n",
       "      <td>1.210544</td>\n",
       "      <td>-0.661599</td>\n",
       "      <td>0.763178</td>\n",
       "      <td>-0.345683</td>\n",
       "      <td>-0.001739</td>\n",
       "      <td>-0.686483</td>\n",
       "      <td>1.419251</td>\n",
       "      <td>-1.148729</td>\n",
       "      <td>-2.319642</td>\n",
       "      <td>-0.592996</td>\n",
       "      <td>0.988491</td>\n",
       "      <td>-2.309741</td>\n",
       "      <td>2.011675</td>\n",
       "      <td>0.450522</td>\n",
       "      <td>-2.261243</td>\n",
       "      <td>0.479632</td>\n",
       "      <td>-1.136821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.674688</td>\n",
       "      <td>1.339302</td>\n",
       "      <td>-0.987923</td>\n",
       "      <td>0.665835</td>\n",
       "      <td>-0.345683</td>\n",
       "      <td>-0.706695</td>\n",
       "      <td>-0.686483</td>\n",
       "      <td>-0.151395</td>\n",
       "      <td>0.149489</td>\n",
       "      <td>0.214130</td>\n",
       "      <td>0.549188</td>\n",
       "      <td>-0.526053</td>\n",
       "      <td>-0.282213</td>\n",
       "      <td>1.377705</td>\n",
       "      <td>-0.377645</td>\n",
       "      <td>-0.459550</td>\n",
       "      <td>0.479632</td>\n",
       "      <td>0.794119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LOCALIDAD_COLEGIO  PG_ICFES  CON_MAT_ICFES  FISICA_ICFES  BIOLOGIA_ICFES  \\\n",
       "0           1.219727  1.210544      -0.661599      0.763178       -0.345683   \n",
       "1          -1.674688  1.339302      -0.987923      0.665835       -0.345683   \n",
       "\n",
       "   IDIOMA_ICFES  LOCALIDAD  PROMEDIO_UNO   CAR_UNO   NCC_UNO   NAA_UNO  \\\n",
       "0     -0.001739  -0.686483      1.419251 -1.148729 -2.319642 -0.592996   \n",
       "1     -0.706695  -0.686483     -0.151395  0.149489  0.214130  0.549188   \n",
       "\n",
       "   NOTA_DIFERENCIAL  NOTA_DIBUJO  NOTA_QUIMICA  NOTA_CFJC  NOTA_TEXTOS  \\\n",
       "0          0.988491    -2.309741      2.011675   0.450522    -2.261243   \n",
       "1         -0.526053    -0.282213      1.377705  -0.377645    -0.459550   \n",
       "\n",
       "   NOTA_SEMINARIO  NOTA_EE_UNO  \n",
       "0        0.479632    -1.136821  \n",
       "1        0.479632     0.794119  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_T_JOHNSON1 = X.copy(deep=True)\n",
    "def transformacion_johnson(X):\n",
    "    transformador_johnson = PowerTransformer(method='yeo-johnson', standardize=True).fit(X)\n",
    "    datos_transformados = transformador_johnson.transform(X)\n",
    "    set_printoptions(precision=3)\n",
    "    print(datos_transformados[:5, :])\n",
    "    datos_transformados_df = pd.DataFrame(data=datos_transformados, columns=X.columns)\n",
    "    return datos_transformados_df\n",
    "Xpandas_T_JOHNSON1 = transformacion_johnson(X_T_JOHNSON1)\n",
    "Xpandas_T_JOHNSON1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom imblearn.over_sampling import RandomOverSampler\\nfrom sklearn.model_selection import train_test_split\\n\\n# Crear una instancia de RandomOverSampler\\nros = RandomOverSampler(sampling_strategy=\\'auto\\', random_state=42)\\n\\n# Aplicar RandomOverSampler para generar muestras sintéticas de las clases minoritarias\\nXpandas_T_JOHNSON1, Y = ros.fit_resample(Xpandas_T_JOHNSON1, Y)\\n\\n# Imprimir la distribución de clases después del oversampling\\nprint(\"Distribución de clases después del oversampling:\", Counter(Y))\\n'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Crear una instancia de RandomOverSampler\n",
    "ros = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "# Aplicar RandomOverSampler para generar muestras sintéticas de las clases minoritarias\n",
    "Xpandas_T_JOHNSON1, Y = ros.fit_resample(Xpandas_T_JOHNSON1, Y)\n",
    "\n",
    "# Imprimir la distribución de clases después del oversampling\n",
    "print(\"Distribución de clases después del oversampling:\", Counter(Y))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATOS: Son 1847 datos para entrenamiento y 792 datos para prueba\n"
     ]
    }
   ],
   "source": [
    "X_trn, X_tst, Y_trn, Y_tst = train_test_split(Xpandas_T_JOHNSON1, Y, test_size=0.3, random_state=2)\n",
    "print('DATOS: Son {} datos para entrenamiento y {} datos para prueba'.format(X_trn.shape[0], X_tst.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom imblearn.over_sampling import RandomOverSampler\\nfrom sklearn.model_selection import train_test_split\\n\\n# Crear una instancia de RandomOverSampler\\nros = RandomOverSampler(sampling_strategy=\\'auto\\', random_state=42)\\n\\n# Aplicar RandomOverSampler para generar muestras sintéticas de las clases minoritarias\\nX_trn,Y_trn = ros.fit_resample(X_trn, Y_trn)\\n\\n# Imprimir la distribución de clases después del oversampling\\nprint(\"Distribución de clases después del oversampling:\", Counter(Y_trn))\\n'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Crear una instancia de RandomOverSampler\n",
    "ros = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "# Aplicar RandomOverSampler para generar muestras sintéticas de las clases minoritarias\n",
    "X_trn,Y_trn = ros.fit_resample(X_trn, Y_trn)\n",
    "\n",
    "# Imprimir la distribución de clases después del oversampling\n",
    "print(\"Distribución de clases después del oversampling:\", Counter(Y_trn))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor 1 aparece 988 veces\n",
      "El valor 0 aparece 783 veces\n",
      "El valor 2 aparece 73 veces\n",
      "El valor 3 aparece 3 veces\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "frecuencias = Counter(Y_trn)\n",
    "for valor, frecuencia in frecuencias.items():\n",
    "    print(f\"El valor {valor} aparece {frecuencia} veces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNEIGHBORSCLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 82.88807285546416\n",
      "Mejor valor PARAMETRO usando k-fold: {'algorithm': 'auto', 'metric': 'minkowski', 'n_neighbors': 14, 'p': 3, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_knn_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {\n",
    "        'n_neighbors': [i for i in range(14, 18, 1)],\n",
    "        'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "        'algorithm': ['auto'],\n",
    "        'p': [i for i in range(1, 6)],\n",
    "        'weights': ['uniform']\n",
    "    }\n",
    "    modelo = KNeighborsClassifier()\n",
    "    semilla = 5\n",
    "    num_folds = 10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn_transformado, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "\n",
    "    # Entrenar el modelo con los mejores hiperparámetros\n",
    "    mejor_modelo = KNeighborsClassifier(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_knn = entrenar_modelo_knn_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.7817212529333741\n",
      "Exhaustividad (Recall):  0.8068181818181818\n",
      "Puntuación F1:  0.7901484059966835\n",
      "Exactitud:  0.8068181818181818\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.75      0.80       338\n",
      "           1       0.78      0.91      0.84       424\n",
      "           2       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           0.81       792\n",
      "   macro avg       0.54      0.55      0.55       792\n",
      "weighted avg       0.78      0.81      0.79       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_knn.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 42.662162162162176\n",
      "Mejor valor PARAMETRO usando k-fold: {'C': 0.0008, 'gamma': 0.9, 'kernel': 'rbf', 'max_iter': 2, 'random_state': 1}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_svc_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = { 'kernel':  ['rbf'], \n",
    "            'C': [i/10000 for i in range(8,12,1)],\n",
    "            'max_iter':[i for i in range(1,3,1)],\n",
    "            'gamma' : [i/100 for i in range(90,110,5)],\n",
    "            'random_state':[i for i in range(1,5,1)]}\n",
    "    modelo = SVC()\n",
    "    semilla=5\n",
    "    num_folds=10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = SVC(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_svc = entrenar_modelo_svc_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.3160416105142916\n",
      "Exhaustividad (Recall):  0.4255050505050505\n",
      "Puntuación F1:  0.25742421095692125\n",
      "Exactitud:  0.4255050505050505\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.99      0.60       338\n",
      "           1       0.25      0.00      0.00       424\n",
      "           2       0.00      0.00      0.00        30\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.43       792\n",
      "   macro avg       0.17      0.25      0.15       792\n",
      "weighted avg       0.32      0.43      0.26       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_svc.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 81.15775558166864\n",
      "Mejor valor PARAMETRO usando k-fold: {'criterion': 'entropy', 'max_depth': 5, 'max_features': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'random_state': 3, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_tree_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {          \n",
    "            'max_depth':[i for i in range(3,6,1)],\n",
    "            'min_samples_split' :  [i for i in range(1,3,1)],  \n",
    "            'min_samples_leaf' : [i for i in range(1,3,1)], \n",
    "            'max_features' : [i for i in range(5,7,1)], \n",
    "            'splitter': [\"best\", \"random\"],\n",
    "            'random_state': [i for i in range(1,4,1)],\n",
    "            'criterion': ['entropy']}\n",
    "    modelo = DecisionTreeClassifier()\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = DecisionTreeClassifier(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_tree = entrenar_modelo_tree_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.782423377867914\n",
      "Exhaustividad (Recall):  0.8080808080808081\n",
      "Puntuación F1:  0.7950327225197928\n",
      "Exactitud:  0.8080808080808081\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82       338\n",
      "           1       0.81      0.84      0.83       424\n",
      "           2       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           0.81       792\n",
      "   macro avg       0.54      0.56      0.55       792\n",
      "weighted avg       0.78      0.81      0.80       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_tree.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 73.19917743830787\n",
      "Mejor valor PARAMETRO usando k-fold: {}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_gaussian_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {}\n",
    "    modelo = GaussianNB()\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = GaussianNB(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_gaussian = entrenar_modelo_gaussian_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.7991216361113912\n",
      "Exhaustividad (Recall):  0.7373737373737373\n",
      "Puntuación F1:  0.7621966222256437\n",
      "Exactitud:  0.7373737373737373\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.78      0.82       338\n",
      "           1       0.80      0.71      0.75       424\n",
      "           2       0.17      0.57      0.26        30\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.74       792\n",
      "   macro avg       0.46      0.52      0.46       792\n",
      "weighted avg       0.80      0.74      0.76       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_gaussian.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 80.07667450058754\n",
      "Mejor valor PARAMETRO usando k-fold: {'n_components': 1, 'shrinkage': 0.1, 'solver': 'lsqr'}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_LDA_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = { 'solver':  ['svd','lsqr','eigen'],\n",
    "            'n_components':[1,2,3,4,5,None],\n",
    "            'shrinkage': ['auto',None, 0, 0.001, 0.01, 0.1, 0.5,1]}\n",
    "    modelo = LinearDiscriminantAnalysis()\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = LinearDiscriminantAnalysis(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_LDA = entrenar_modelo_LDA_con_transformacion(X_trn, Y_trn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.8085191506634195\n",
      "Exhaustividad (Recall):  0.797979797979798\n",
      "Puntuación F1:  0.7835125160518082\n",
      "Exactitud:  0.797979797979798\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.76      0.80       338\n",
      "           1       0.77      0.88      0.82       424\n",
      "           2       1.00      0.03      0.06        30\n",
      "\n",
      "    accuracy                           0.80       792\n",
      "   macro avg       0.87      0.56      0.56       792\n",
      "weighted avg       0.81      0.80      0.78       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_LDA.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BAGGINGCLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'bootstrap_features': False,\n",
       " 'estimator': None,\n",
       " 'max_features': 1.0,\n",
       " 'max_samples': 1.0,\n",
       " 'n_estimators': 10,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "estimator = BaggingClassifier()\n",
    "estimator.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 82.62103407755582\n",
      "Mejor valor PARAMETRO usando k-fold: {'bootstrap': True, 'bootstrap_features': True, 'max_features': 0.6, 'max_samples': 0.45, 'n_estimators': 750}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_BG_con_transformacion(X_trn, Y_trn):\n",
    "    # Aplicar la transformación Yeo-Johnson\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {'n_estimators': [i for i in range(750,760,5)],\n",
    "            'max_samples' : [i/100.0 for i in range(40,50,5)],\n",
    "            'max_features': [i/100.0 for i in range(60,65,5)],\n",
    "            'bootstrap': [True], \n",
    "            'bootstrap_features': [True]}\n",
    "    \n",
    "    base_estimator= DecisionTreeClassifier(criterion= 'gini', \n",
    "                                max_depth=5, max_features= 3,min_samples_leaf= 4, \n",
    "                                min_samples_split = 8,random_state= 10, splitter= 'random')\n",
    "\n",
    "    modelo = BaggingClassifier(estimator=base_estimator, oob_score=True, random_state=1)\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = BaggingClassifier(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "modelo_BG = entrenar_modelo_BG_con_transformacion(X_trn, Y_trn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.8381068760618884\n",
      "Exhaustividad (Recall):  0.8308080808080808\n",
      "Puntuación F1:  0.8163681677580162\n",
      "Exactitud:  0.8308080808080808\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       338\n",
      "           1       0.81      0.89      0.85       424\n",
      "           2       1.00      0.03      0.06        30\n",
      "\n",
      "    accuracy                           0.83       792\n",
      "   macro avg       0.89      0.58      0.59       792\n",
      "weighted avg       0.84      0.83      0.82       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_BG.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXTRA TREES CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 83.21709753231494\n",
      "Mejor valor PARAMETRO usando k-fold: {'min_samples_leaf': 1, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_extra_con_transformacion(X_trn, Y_trn):\n",
    "    # Aplicar la transformación Yeo-Johnson\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {'min_samples_split' : [i for i in range(1,3,1)], \n",
    "                'min_samples_leaf' : [i for i in range(0,2,1)] }\n",
    "    \n",
    "    semilla=7            \n",
    "    modelo = ExtraTreesClassifier(random_state=semilla, \n",
    "                                n_estimators=40, max_features=1,max_depth= 10,\n",
    "                                min_samples_leaf=1,  min_samples_split = 2,\n",
    "                                bootstrap=True,criterion='gini') \n",
    "    num_folds=10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = ExtraTreesClassifier(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_extra = entrenar_modelo_extra_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.8441779313974173\n",
      "Exhaustividad (Recall):  0.8371212121212122\n",
      "Puntuación F1:  0.8225526686813371\n",
      "Exactitud:  0.8371212121212122\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.85       338\n",
      "           1       0.82      0.90      0.86       424\n",
      "           2       1.00      0.03      0.06        30\n",
      "\n",
      "    accuracy                           0.84       792\n",
      "   macro avg       0.89      0.59      0.59       792\n",
      "weighted avg       0.84      0.84      0.82       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_extra.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'SAMME.R',\n",
       " 'estimator': None,\n",
       " 'learning_rate': 1.0,\n",
       " 'n_estimators': 50,\n",
       " 'random_state': None}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier            \n",
    "estimator  = AdaBoostClassifier ()\n",
    "estimator.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 76.17596944770858\n",
      "Mejor valor PARAMETRO usando k-fold: {'learning_rate': 0.0005}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_ADA_con_transformacion(X_trn, Y_trn):\n",
    "    # Aplicar la transformación Yeo-Johnson\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {'learning_rate' : [i/10000.0 for i in range(5,20,5)]}\n",
    "    semilla=7            \n",
    "    modelo = AdaBoostClassifier(estimator = None,  algorithm = 'SAMME.R', \n",
    "                                random_state= None, n_estimators =50) \n",
    "    num_folds=10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = AdaBoostClassifier(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_ADA = entrenar_modelo_ADA_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.7639212703081316\n",
      "Exhaustividad (Recall):  0.7828282828282829\n",
      "Puntuación F1:  0.7653496267365383\n",
      "Exactitud:  0.7828282828282829\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.70      0.77       338\n",
      "           1       0.74      0.91      0.82       424\n",
      "           2       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           0.78       792\n",
      "   macro avg       0.53      0.53      0.53       792\n",
      "weighted avg       0.76      0.78      0.77       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_ADA.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRADIENT BOOSTING MACHINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 83.75851938895418\n",
      "Mejor valor PARAMETRO usando k-fold: {'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_GD_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = { \n",
    "                'subsample' : [ 0.5,0.6,0.7 , 0.75 , 0.8 , 0.85 , 0.9 , 0.95 , 1 ]        \n",
    "              }\n",
    "    semilla=7\n",
    "    modelo = GradientBoostingClassifier(random_state=semilla,\n",
    "                                    n_estimators= 100,learning_rate= 0.1,max_depth= 2,\n",
    "                                    min_samples_split= 2, min_samples_leaf= 3,max_features= 2)\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = GradientBoostingClassifier(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_GD = entrenar_modelo_GD_con_transformacion(X_trn, Y_trn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.8019252051756732\n",
      "Exhaustividad (Recall):  0.8017676767676768\n",
      "Puntuación F1:  0.8004320960725225\n",
      "Exactitud:  0.8017676767676768\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83       338\n",
      "           1       0.81      0.84      0.83       424\n",
      "           2       0.20      0.07      0.10        30\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.80       792\n",
      "   macro avg       0.46      0.43      0.44       792\n",
      "weighted avg       0.80      0.80      0.80       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_GD.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 83.81257344300825\n",
      "Mejor valor PARAMETRO usando k-fold: {'reg_alpha': 0.4, 'reg_lambda': 1.4}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_XB_con_transformacion(X_trn, Y_trn):\n",
    "    # Aplicar la transformación Yeo-Johnson\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {'reg_alpha': [0,0.1,0.2,0.3,0.4,0.5],\n",
    "                'reg_lambda':  [i/100.0 for i in range(130,150,5)]}\n",
    "    semilla=7\n",
    "    modelo = XGBClassifier (random_state=semilla,                       \n",
    "                        n_estimators=40,colsample_bytree = 1, subsample =1,max_depth =2,\n",
    "                        min_child_weight =6,gamma = 0.05,learning_rate = 0.3)\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = XGBClassifier(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_XB = entrenar_modelo_XB_con_transformacion(X_trn, Y_trn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.8237242861966924\n",
      "Exhaustividad (Recall):  0.8282828282828283\n",
      "Puntuación F1:  0.818752624485996\n",
      "Exactitud:  0.8282828282828283\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.83       338\n",
      "           1       0.82      0.88      0.85       424\n",
      "           2       0.67      0.13      0.22        30\n",
      "\n",
      "    accuracy                           0.83       792\n",
      "   macro avg       0.78      0.61      0.64       792\n",
      "weighted avg       0.82      0.83      0.82       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_XB.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CATBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 84.24706227967098\n",
      "Mejor valor PARAMETRO usando k-fold: {'border_count': 53, 'l2_leaf_reg': 42}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_CB_con_transformacion(X_trn, Y_trn):\n",
    "    # Aplicar la transformación Yeo-Johnson\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {'border_count':[53],'l2_leaf_reg': [42]} \n",
    "    semilla=7\n",
    "    modelo = CatBoostClassifier(random_state=semilla, verbose =0)\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = CatBoostClassifier(verbose=0,**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_CB = entrenar_modelo_CB_con_transformacion(X_trn, Y_trn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.8364691187009873\n",
      "Exhaustividad (Recall):  0.8295454545454546\n",
      "Puntuación F1:  0.8151361137893514\n",
      "Exactitud:  0.8295454545454546\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       338\n",
      "           1       0.82      0.88      0.85       424\n",
      "           2       1.00      0.03      0.06        30\n",
      "\n",
      "    accuracy                           0.83       792\n",
      "   macro avg       0.89      0.58      0.58       792\n",
      "weighted avg       0.84      0.83      0.82       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_CB.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIGHT GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 859\n",
      "[LightGBM] [Info] Number of data points in the train set: 1847, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score -0.858185\n",
      "[LightGBM] [Info] Start training from score -0.625635\n",
      "[LightGBM] [Info] Start training from score -3.230859\n",
      "[LightGBM] [Info] Start training from score -6.422706\n",
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 82.83754406580493\n",
      "Mejor valor PARAMETRO usando k-fold: {'min_child_samples': 300}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_LIGHT_con_transformacion(X_trn, Y_trn):\n",
    "    # Aplicar la transformación Yeo-Johnson\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = { 'min_child_samples' : [i for i in range(200, 10000, 100)]}\n",
    "    semilla=7\n",
    "    modelo = LGBMClassifier (random_state=semilla,                           \n",
    "                        num_leaves =  10,max_depth = 1, n_estimators = 100,    \n",
    "                        learning_rate = 0.1 ,class_weight=  None, subsample = 1,\n",
    "                        colsample_bytree= 1, reg_alpha=  0, reg_lambda = 0,\n",
    "                        min_split_gain = 0, boosting_type = 'gbdt')\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = LGBMClassifier(verbose=-1,**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_LIGHT = entrenar_modelo_LIGHT_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.8210502957306025\n",
      "Exhaustividad (Recall):  0.8282828282828283\n",
      "Puntuación F1:  0.817669232318636\n",
      "Exactitud:  0.8282828282828283\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       338\n",
      "           1       0.83      0.86      0.85       424\n",
      "           2       0.60      0.10      0.17        30\n",
      "\n",
      "    accuracy                           0.83       792\n",
      "   macro avg       0.75      0.60      0.62       792\n",
      "weighted avg       0.82      0.83      0.82       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_LIGHT.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VOTING - VOTACIÓN DURA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento del modelo:\n",
      "Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold: 83.05611045828438  % \n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_voting_hard_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    semilla= 7 \n",
    "    kfold = KFold(n_splits=10, random_state=semilla, shuffle=True)\n",
    "    \n",
    "    modelo1 = GradientBoostingClassifier(random_state=semilla, n_estimators=800, \n",
    "                                    learning_rate = 0.01, max_depth = 2,\n",
    "                                    max_features =2, min_samples_leaf = 9, \n",
    "                                    min_samples_split = 2, subsample = 1 )\n",
    "    \n",
    "    base_estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, \n",
    "                                    criterion='gini',\n",
    "                                    max_depth=8, max_features=1, max_leaf_nodes=None,\n",
    "                                    min_impurity_decrease=0.0,\n",
    "                                    min_samples_leaf=1, min_samples_split=5,\n",
    "                                    min_weight_fraction_leaf=0.0,\n",
    "                                    random_state=5, splitter='random')\n",
    "\n",
    "    modelo2 = AdaBoostClassifier(estimator=base_estimator,n_estimators=1200, \n",
    "                                    algorithm ='SAMME.R', learning_rate = 0.001, \n",
    "                                    random_state=semilla)\n",
    "\n",
    "    modelo3 = ExtraTreesClassifier(n_estimators=300, max_features=None,\n",
    "                                    bootstrap = False, max_depth = 11,min_samples_split = 4, \n",
    "                                    min_samples_leaf = 1)\n",
    "\n",
    "    modelo4 = RandomForestClassifier (n_estimators=1100, max_features=None,\n",
    "                                    min_samples_split = 5, max_depth= 3, \n",
    "                                    min_samples_leaf= 1)\n",
    "\n",
    "    model = DecisionTreeClassifier(criterion= 'gini', \n",
    "                                    max_depth=6, \n",
    "                                    max_features= None, \n",
    "                                    min_samples_leaf= 9, \n",
    "                                    min_samples_split = 2, \n",
    "                                    random_state= 10, \n",
    "                                    splitter= 'random')\n",
    "\n",
    "    modelo5 = BaggingClassifier(estimator=model, n_estimators=50, \n",
    "                                    random_state=semilla,\n",
    "                                    bootstrap= True, bootstrap_features = False, \n",
    "                                    max_features = 0.9,\n",
    "                                    max_samples= 0.95)\n",
    "\n",
    "    modelo6 = DecisionTreeClassifier(criterion= 'gini', max_depth=6,max_features= None, \n",
    "                                    min_samples_leaf= 9, \n",
    "                                    min_samples_split = 2, random_state= 10, splitter= 'random')\n",
    "\n",
    "    modelo7 = XGBClassifier(n_estimators= 40, random_state=semilla,colsample_bytree = 1, \n",
    "                                    subsample =1, reg_alpha = 0.2, reg_lambda= 1.35,\n",
    "                                    learning_rate= 0.3,max_depth =2, min_child_weight =6,\n",
    "                                    gamma = 0.05)\n",
    "    metrica = 'accuracy'\n",
    "    mejor_modelo = VotingClassifier(\n",
    "    estimators=[('Gradient', modelo1), ('Adaboost', modelo2), \n",
    "                                    ('Extratrees', modelo3),('Random Forest',modelo4),\n",
    "                                    ('Bagging',modelo5),('Decision tree',modelo6),\n",
    "                                    ('XGB',modelo7)],voting='hard') \n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    resultados = cross_val_score(mejor_modelo, X_trn_transformado, Y_trn, \n",
    "                                    cv=kfold,scoring = metrica)\n",
    "    print(\"Rendimiento del modelo:\") \n",
    "    print (\"Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold:\", resultados.mean()*100,\" % \") \n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_voting_hard = entrenar_modelo_voting_hard_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.8002605702722346\n",
      "Exhaustividad (Recall):  0.8295454545454546\n",
      "Puntuación F1:  0.8132392427607834\n",
      "Exactitud:  0.8295454545454546\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.81      0.84       338\n",
      "           1       0.81      0.90      0.85       424\n",
      "           2       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           0.83       792\n",
      "   macro avg       0.56      0.57      0.56       792\n",
      "weighted avg       0.80      0.83      0.81       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_voting_hard.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VOTING - VOTACIÓN SUAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento del modelo:\n",
      "Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold: 83.21886016451234  % \n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_voting_soft_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    semilla= 7 \n",
    "    kfold = KFold(n_splits=10, random_state=semilla, shuffle=True)\n",
    "    modelo1 = GradientBoostingClassifier(random_state=semilla, n_estimators=800, \n",
    "                                    learning_rate = 0.01, max_depth = 2,\n",
    "                                    max_features =2, min_samples_leaf = 9, \n",
    "                                    min_samples_split = 2, subsample = 1 )\n",
    "    \n",
    "    base_estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "                                    max_depth=8, max_features=1, max_leaf_nodes=None,\n",
    "                                    min_impurity_decrease=0.0,\n",
    "                                    min_samples_leaf=1, min_samples_split=5,\n",
    "                                    min_weight_fraction_leaf=0.0,\n",
    "                                    random_state=5, splitter='random')\n",
    "\n",
    "    modelo2 = AdaBoostClassifier(estimator=base_estimator,n_estimators=1200, \n",
    "                                    algorithm ='SAMME.R', learning_rate = 0.001, \n",
    "                                    random_state=semilla)\n",
    "\n",
    "    modelo3 = ExtraTreesClassifier(n_estimators=300, max_features=None,bootstrap = False, \n",
    "                                    max_depth = 11,min_samples_split = 4, \n",
    "                                    min_samples_leaf = 1)\n",
    "\n",
    "    modelo4 = RandomForestClassifier (n_estimators=1100, max_features=None,\n",
    "                                    min_samples_split = 5, max_depth= 3, min_samples_leaf= 1)\n",
    "\n",
    "    model = DecisionTreeClassifier(criterion= 'gini', \n",
    "                                    max_depth=6, \n",
    "                                    max_features= None, \n",
    "                                    min_samples_leaf= 9, \n",
    "                                    min_samples_split = 2, \n",
    "                                    random_state= 10, \n",
    "                                    splitter= 'random')\n",
    "\n",
    "    modelo5 = BaggingClassifier(estimator=model, n_estimators=50, random_state=semilla,\n",
    "                                    bootstrap= True, bootstrap_features = False, \n",
    "                                    max_features = 0.9, max_samples= 0.95)\n",
    "\n",
    "    modelo6 = DecisionTreeClassifier(criterion= 'gini', max_depth=6,max_features= None, \n",
    "                                    min_samples_leaf= 9, min_samples_split = 2, \n",
    "                                    random_state= 10, splitter= 'random')\n",
    "    metrica = 'accuracy'\n",
    "    mejor_modelo = VotingClassifier(\n",
    "    estimators=[('Gradient', modelo1), ('Adaboost', modelo2), ('Extratrees', modelo3),\n",
    "                                    ('Random Forest',modelo4),\n",
    "                                    ('Bagging',modelo5),('Decision tree',modelo6)],\n",
    "    voting='soft',weights=[0.9,0.7,0.9,0.9,0.9,0.9]) \n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    resultados = cross_val_score(mejor_modelo, X_trn_transformado, Y_trn, cv=kfold,scoring = metrica)\n",
    "    print(\"Rendimiento del modelo:\") \n",
    "    print (\"Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold:\", resultados.mean()*100,\" % \") \n",
    "    return mejor_modelo\n",
    "\n",
    "# Cargar los datos\n",
    "#datos = cargar_datos(carrera, semestre)\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "# Entrenar el modelo KNN con transformación Yeo-Johnson\n",
    "modelo_voting_soft = entrenar_modelo_voting_soft_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.7977909149083605\n",
      "Exhaustividad (Recall):  0.827020202020202\n",
      "Puntuación F1:  0.81074644882467\n",
      "Exactitud:  0.827020202020202\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.81      0.83       338\n",
      "           1       0.81      0.90      0.85       424\n",
      "           2       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           0.83       792\n",
      "   macro avg       0.55      0.57      0.56       792\n",
      "weighted avg       0.80      0.83      0.81       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_voting_soft.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STACKING ( METAMODELO LINEAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento del modelo:\n",
      "Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold: 83.27203290246767  % \n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_stacking_lineal_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    semilla= 7 \n",
    "    kfold = KFold(n_splits=10, random_state=semilla, shuffle=True)\n",
    "    base_estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "                                    max_depth=8, max_features=1, max_leaf_nodes=None,\n",
    "                                    min_impurity_decrease=0.0,\n",
    "                                    min_samples_leaf=1, min_samples_split=5,\n",
    "                                    min_weight_fraction_leaf=0.0,\n",
    "                                    random_state=5, splitter='random')\n",
    "    modelo2 = AdaBoostClassifier(estimator=base_estimator,n_estimators=500, \n",
    "                                    algorithm ='SAMME.R', learning_rate = 0.001, \n",
    "                                    random_state=semilla)\n",
    "\n",
    "    modelo3 = ExtraTreesClassifier(n_estimators=300, max_features=None,bootstrap = False, \n",
    "                                    max_depth = 11,min_samples_split = 4, \n",
    "                                    min_samples_leaf = 1)\n",
    "\n",
    "    modelo4 = RandomForestClassifier (n_estimators=300, max_features=None,\n",
    "                                    min_samples_split = 5, max_depth= 3, min_samples_leaf= 1)\n",
    "    model = DecisionTreeClassifier(criterion= 'gini', \n",
    "                                    max_depth=6, \n",
    "                                    max_features= None, \n",
    "                                    min_samples_leaf= 9, \n",
    "                                    min_samples_split = 2, \n",
    "                                    random_state= 10, \n",
    "                                    splitter= 'random')\n",
    "\n",
    "    modelo5 = BaggingClassifier(estimator=model, n_estimators=50, random_state=semilla,\n",
    "                                    bootstrap= True, bootstrap_features = False, \n",
    "                                    max_features = 0.9,\n",
    "                                    max_samples= 0.95)\n",
    "\n",
    "    modelo6 = DecisionTreeClassifier(criterion= 'gini', max_depth=6,max_features= None, \n",
    "                                    min_samples_leaf= 9, \n",
    "                                    min_samples_split = 2, random_state= 10, splitter= 'random')\n",
    "    estimador_final = LogisticRegression()\n",
    "    metrica = 'accuracy'\n",
    "    mejor_modelo = StackingClassifier(\n",
    "    estimators=[ ('Adaboost', modelo2), ('Extratrees', modelo3),('Random Forest',modelo4),\n",
    "                                    ('Bagging',modelo5),('Decision tree',modelo6)], \n",
    "                                    final_estimator=estimador_final) \n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    resultados = cross_val_score(mejor_modelo, X_trn_transformado, Y_trn, cv=kfold,scoring = metrica)\n",
    "    print(\"Rendimiento del modelo:\") \n",
    "    print (\"Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold:\", resultados.mean()*100,\" % \") \n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_stacking_lineal = entrenar_modelo_stacking_lineal_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.8256587443504463\n",
      "Exhaustividad (Recall):  0.8358585858585859\n",
      "Puntuación F1:  0.8217699541539778\n",
      "Exactitud:  0.8358585858585859\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.83      0.85       338\n",
      "           1       0.82      0.90      0.86       424\n",
      "           2       0.50      0.03      0.06        30\n",
      "\n",
      "    accuracy                           0.84       792\n",
      "   macro avg       0.73      0.59      0.59       792\n",
      "weighted avg       0.83      0.84      0.82       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_stacking_lineal.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STACKING (METAMODELO NO LINEAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento del modelo:\n",
      "Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold: 83.05376028202114  % \n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_stacking_nolineal_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    semilla= 7 \n",
    "    kfold = KFold(n_splits=10, random_state=semilla, shuffle=True)\n",
    "    modelo3 = ExtraTreesClassifier(n_estimators=400, max_features=None,bootstrap = False, \n",
    "                                    max_depth = 11,min_samples_split = 4, \n",
    "                                    min_samples_leaf = 1)\n",
    "\n",
    "    modelo4 = RandomForestClassifier (n_estimators=500, max_features=None,\n",
    "                                    min_samples_split = 5, max_depth= 3, min_samples_leaf= 1)\n",
    "    model = DecisionTreeClassifier(criterion= 'gini', \n",
    "                                    max_depth=6, max_features= None,  min_samples_leaf= 9, \n",
    "                                    min_samples_split = 2, \n",
    "                                    random_state= 10, splitter= 'random')\n",
    "\n",
    "    modelo5 = BaggingClassifier(estimator=model, n_estimators=50, random_state=semilla,\n",
    "                                    bootstrap= True, bootstrap_features = False, \n",
    "                                    max_features = 0.9, max_samples= 0.95)\n",
    "\n",
    "    modelo6 = DecisionTreeClassifier(criterion= 'gini', max_depth=6,max_features= None, \n",
    "                                    min_samples_leaf= 9, min_samples_split = 2, \n",
    "                                    random_state= 10, splitter= 'random')\n",
    "    estimador_final = ExtraTreesClassifier(n_estimators=100, max_features=None,\n",
    "                                    bootstrap = False, max_depth = 11,min_samples_split = 4, \n",
    "                                    min_samples_leaf = 1)\n",
    "    metrica = 'accuracy'\n",
    "    mejor_modelo = StackingClassifier(\n",
    "    estimators=[  ('Extratrees', modelo3),('Random Forest',modelo4),('Bagging',modelo5),\n",
    "                                    ('Decision tree',modelo6)], \n",
    "                                    final_estimator=estimador_final) \n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    resultados = cross_val_score(mejor_modelo, X_trn_transformado, Y_trn, cv=kfold,scoring = metrica)\n",
    "    print(\"Rendimiento del modelo:\") \n",
    "    print (\"Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold:\", resultados.mean()*100,\" % \") \n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_stacking_nolineal = entrenar_modelo_stacking_nolineal_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.7950265069703514\n",
      "Exhaustividad (Recall):  0.8207070707070707\n",
      "Puntuación F1:  0.8068575089266116\n",
      "Exactitud:  0.8207070707070707\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.82      0.84       338\n",
      "           1       0.81      0.88      0.84       424\n",
      "           2       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           0.82       792\n",
      "   macro avg       0.55      0.57      0.56       792\n",
      "weighted avg       0.80      0.82      0.81       792\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_stacking_nolineal.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUPER APRENDIZ CON ML ESEMBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo (Ensamblaje con voto ponderado): 87.38%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier, RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "def weighted_voting_ensemble(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    modelos = [\n",
    "        GradientBoostingClassifier(random_state=7, n_estimators=800, learning_rate=0.01, max_depth=2, max_features=2, min_samples_leaf=9, min_samples_split=2, subsample=1),\n",
    "        AdaBoostClassifier(estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini', max_depth=8, max_features=1, max_leaf_nodes=None, min_impurity_decrease=0.0, min_samples_leaf=1, min_samples_split=5, min_weight_fraction_leaf=0.0, random_state=5, splitter='random'), n_estimators=1200, algorithm='SAMME.R', learning_rate=0.001, random_state=7),\n",
    "        ExtraTreesClassifier(n_estimators=300, max_features=None, bootstrap=False, max_depth=11, min_samples_split=4, min_samples_leaf=1),\n",
    "        RandomForestClassifier(n_estimators=300, max_features=None, min_samples_split=5, max_depth=3, min_samples_leaf=1),\n",
    "        BaggingClassifier(estimator=DecisionTreeClassifier(criterion='gini', max_depth=6, max_features=None, min_samples_leaf=9, min_samples_split=2, random_state=10, splitter='random'), n_estimators=50, random_state=7, bootstrap=True, bootstrap_features=False, max_features=0.9, max_samples=0.95),\n",
    "        DecisionTreeClassifier(criterion='gini', max_depth=6, max_features=None, min_samples_leaf=9, min_samples_split=2, random_state=10, splitter='random'),\n",
    "        XGBClassifier(n_estimators=40, random_state=7, colsample_bytree=1, subsample=1, reg_alpha=0.2, reg_lambda=1.35, learning_rate=0.3, max_depth=2, min_child_weight=6, gamma=0.05)\n",
    "    ]\n",
    "    \n",
    "    # Inicializar pesos para el voto ponderado\n",
    "    pesos = np.ones(len(modelos))\n",
    "    \n",
    "    # Entrenar cada modelo y obtener su precisión\n",
    "    precisión_modelos = []\n",
    "    for modelo in modelos:\n",
    "        precisión = np.mean(cross_val_score(modelo, X_trn_transformado, Y_trn, cv=KFold(n_splits=10, random_state=7, shuffle=True), scoring='accuracy'))\n",
    "        precisión_modelos.append(precisión)\n",
    "    \n",
    "    # Calcular los pesos como inversa de la precisión de cada modelo\n",
    "    suma_precisión = sum(precisión_modelos)\n",
    "    for i in range(len(precisión_modelos)):\n",
    "        pesos[i] = suma_precisión / (precisión_modelos[i] * len(modelos))\n",
    "    \n",
    "    # Calcular las predicciones ponderadas\n",
    "    predicciones_ponderadas = np.zeros(len(X_trn_transformado))\n",
    "    for i, modelo in enumerate(modelos):\n",
    "        modelo.fit(X_trn_transformado, Y_trn)\n",
    "        predicciones = modelo.predict(X_trn_transformado)\n",
    "        predicciones_ponderadas += predicciones * pesos[i]\n",
    "    \n",
    "    # Normalizar las predicciones ponderadas\n",
    "    predicciones_ponderadas /= len(modelos)\n",
    "    predicciones_ponderadas = np.round(predicciones_ponderadas).astype(int)\n",
    "    \n",
    "    # Calcular la precisión del ensamblaje\n",
    "    precisión_ensamblaje = accuracy_score(Y_trn, predicciones_ponderadas)\n",
    "    \n",
    "    print(\"Precisión del modelo (Ensamblaje con voto ponderado): {:.2f}%\".format(precisión_ensamblaje * 100))\n",
    "    \n",
    "    return modelos\n",
    "\n",
    "# Utilizar la función\n",
    "X_trn =X_trn # Aquí debes proporcionar tus datos de entrenamiento transformados\n",
    "Y_trn =Y_trn # Aquí debes proporcionar tus etiquetas de entrenamiento\n",
    "modelo_weighted_voting= weighted_voting_ensemble(X_trn, Y_trn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_weighted_voting.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUPER APRENDIZ CON ML ESEMBLE - DOS CAPAS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 1.0184\n",
      "Epoch [20/100], Loss: 0.7499\n",
      "Epoch [30/100], Loss: 0.6183\n",
      "Epoch [40/100], Loss: 0.5524\n",
      "Epoch [50/100], Loss: 0.5122\n",
      "Epoch [60/100], Loss: 0.4840\n",
      "Epoch [70/100], Loss: 0.4635\n",
      "Epoch [80/100], Loss: 0.4482\n",
      "Epoch [90/100], Loss: 0.4362\n",
      "Epoch [100/100], Loss: 0.4264\n",
      "Accuracy: 81.94%\n",
      "Precisión:  0.7912353035379575\n",
      "Exhaustividad (Recall):  0.8194444444444444\n",
      "Puntuación F1:  0.8031387356218563\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "def train_neural_network(X_train, y_train, input_size, hidden_size, num_classes, num_epochs=100, learning_rate=0.001):\n",
    "    # Convertir datos de entrenamiento a tensores de PyTorch\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "    \n",
    "    # Inicializar modelo y función de pérdida\n",
    "    model = NeuralNetwork(input_size, hidden_size, num_classes)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Entrenamiento del modelo\n",
    "    for epoch in range(num_epochs):\n",
    "        # Forward pass y pérdida\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        \n",
    "        # Backward pass y optimización\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    # Convertir datos de prueba a tensores de PyTorch\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "    # Obtener las predicciones del modelo\n",
    "    outputs = model(X_test_tensor)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # Calcular las métricas del modelo\n",
    "    accuracy = accuracy_score(y_test_tensor.numpy(), predicted.numpy())\n",
    "    precision = precision_score(y_test, predicted.numpy(), average='weighted')\n",
    "    recall = recall_score(y_test, predicted.numpy(), average='weighted')\n",
    "    f1 = f1_score(y_test, predicted.numpy(), average='weighted')\n",
    "\n",
    "    print('Accuracy: {:.2f}%'.format(accuracy * 100))\n",
    "    print(\"Precisión: \", precision)\n",
    "    print(\"Exhaustividad (Recall): \", recall)\n",
    "    print(\"Puntuación F1: \", f1)\n",
    "\n",
    "X_train_array = X_trn.values\n",
    "X_test_array = X_tst.values\n",
    "Y_trn = Y_trn \n",
    "input_size = X_trn.shape[1]\n",
    "num_classes = 4\n",
    "hidden_size = 170\n",
    "\n",
    "# Supongamos que X_train, y_train, X_test, y_test son tus datos de entrenamiento y prueba\n",
    "modelo_red_reuronal = train_neural_network(X_train_array , Y_trn, input_size, hidden_size, num_classes)\n",
    "evaluate_model(modelo_red_reuronal, X_test_array , Y_tst)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
