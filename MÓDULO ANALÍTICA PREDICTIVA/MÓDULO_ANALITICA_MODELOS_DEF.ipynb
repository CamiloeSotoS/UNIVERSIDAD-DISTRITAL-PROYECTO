{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from numpy import set_printoptions\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "pd.options.display.max_columns=None\n",
    "import seaborn as sns \n",
    "from pandas import read_csv\n",
    "import io\n",
    "import base64\n",
    "import json\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.drawing.image import Image as XLImage\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CARGUE DE DATOS Y CONEXIÓN A DRIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=899973764197-biu188dkvsgi2al0fh29udm7keak0lh0.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A61844%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.readonly&state=l0B0271GA0f478OzZXw1g7vrlEl81d&access_type=offline\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando industrial10.csv: 100%\n",
      "Descargando industrial9.csv: 100%\n",
      "Descargando industrial8.csv: 100%\n",
      "Descargando industrial7.csv: 100%\n",
      "Descargando industrial6.csv: 100%\n",
      "Descargando industrial5.csv: 100%\n",
      "Descargando industrial3.csv: 100%\n",
      "Descargando industrial4.csv: 100%\n",
      "Descargando industrial2.csv: 100%\n",
      "Descargando industrial1.csv: 100%\n",
      "Descarga completa\n",
      "Archivos descargados:\n",
      "industrial1.csv\n",
      "industrial10.csv\n",
      "industrial2.csv\n",
      "industrial3.csv\n",
      "industrial4.csv\n",
      "industrial5.csv\n",
      "industrial6.csv\n",
      "industrial7.csv\n",
      "industrial8.csv\n",
      "industrial9.csv\n"
     ]
    }
   ],
   "source": [
    "SCOPES = ['https://www.googleapis.com/auth/drive.readonly']\n",
    "\n",
    "creds = None\n",
    "if os.path.exists('token.json'):\n",
    "    creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "if not creds or not creds.valid:\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "        creds.refresh(Request())\n",
    "    else:\n",
    "        flow = InstalledAppFlow.from_client_secrets_file('C:/Users/Intevo/Desktop/UNIVERSIDAD DISTRITAL PROYECTO FOLDER/credentials.json', SCOPES) # Reemplazar con la ruta correcta\n",
    "        creds = flow.run_local_server(port=0)\n",
    "    with open('C:/Users/Intevo/Desktop/UNIVERSIDAD DISTRITAL PROYECTO FOLDER/token.json', 'w') as token:\n",
    "        token.write(creds.to_json())\n",
    "        \n",
    "# Crear una instancia de la API de Drive\n",
    "drive_service = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "# ID de la carpeta de Google Drive\n",
    "folder_id = '1hQeetmO4XIObUefS_nzePqKqq3VksUEC'\n",
    "\n",
    "# Ruta de destino para guardar los archivos descargados\n",
    "save_path = 'C:/Users/Intevo/Desktop/UNIVERSIDAD DISTRITAL PROYECTO FOLDER/UNIVERSIDAD-DISTRITAL-PROYECTO/MÓDULO ANALÍTICA PREDICTIVA/DATOS'  # Reemplazar con la ruta deseada\n",
    "\n",
    "# Función para descargar archivos de la carpeta de Drive\n",
    "def download_folder(folder_id, save_path):\n",
    "    results = drive_service.files().list(\n",
    "        q=f\"'{folder_id}' in parents and trashed=false\",\n",
    "        fields='files(id, name)').execute()\n",
    "    items = results.get('files', [])\n",
    "    for item in items:\n",
    "        file_id = item['id']\n",
    "        file_name = item['name']\n",
    "        request = drive_service.files().get_media(fileId=file_id)\n",
    "        fh = io.FileIO(os.path.join(save_path, file_name), 'wb')\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "        done = False\n",
    "        while done is False:\n",
    "            status, done = downloader.next_chunk()\n",
    "            print(f\"Descargando {file_name}: {int(status.progress() * 100)}%\")\n",
    "    print(\"Descarga completa\")\n",
    "\n",
    "# Descargar archivos de la carpeta\n",
    "download_folder(folder_id, save_path)\n",
    "\n",
    "# Listar archivos descargados\n",
    "files = os.listdir(save_path)\n",
    "print(\"Archivos descargados:\")\n",
    "for file in files:\n",
    "    print(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_por_carrera = {\n",
    "    'industrial': {\n",
    "        '1': ['PG_ICFES', 'CON_MAT_ICFES', 'FISICA_ICFES','QUIMICA_ICFES','IDIOMA_ICFES','LOCALIDAD','RENDIMIENTO_UNO'],\n",
    "        '2': ['variable4_sistemas', 'variable5_sistemas', 'variable6_sistemas']\n",
    "    },\n",
    "    'sistemas': {\n",
    "        '1': ['variable1_industrial', 'variable2_industrial', 'variable3_industrial'],\n",
    "        '2': ['variable4_industrial', 'variable5_industrial', 'variable6_industrial']\n",
    "    },\n",
    "    'catastral': {\n",
    "        '1': ['variable1_catastral', 'variable2_catastral', 'variable3_catastral'],\n",
    "        '2': ['variable4_catastral', 'variable5_catastral', 'variable6_catastral']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_datos(carrera, semestre):\n",
    "    \n",
    "    ruta_archivo = f'C:/Users/Intevo/Desktop/UNIVERSIDAD DISTRITAL PROYECTO FOLDER/UNIVERSIDAD-DISTRITAL-PROYECTO/MÓDULO ANALÍTICA PREDICTIVA/DATOS/{carrera}{semestre}.csv'\n",
    "    datos = pd.read_csv(ruta_archivo,sep=\";\")\n",
    "    \n",
    "    return datos\n",
    "carrera=\"industrial\"\n",
    "semestre=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame con columnas filtradas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PG_ICFES</th>\n",
       "      <th>CON_MAT_ICFES</th>\n",
       "      <th>FISICA_ICFES</th>\n",
       "      <th>QUIMICA_ICFES</th>\n",
       "      <th>IDIOMA_ICFES</th>\n",
       "      <th>LOCALIDAD</th>\n",
       "      <th>RENDIMIENTO_UNO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>474</td>\n",
       "      <td>65</td>\n",
       "      <td>73</td>\n",
       "      <td>75</td>\n",
       "      <td>79</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>523</td>\n",
       "      <td>99</td>\n",
       "      <td>69</td>\n",
       "      <td>78</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>483</td>\n",
       "      <td>63</td>\n",
       "      <td>76</td>\n",
       "      <td>82</td>\n",
       "      <td>77</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>528</td>\n",
       "      <td>88</td>\n",
       "      <td>69</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>478</td>\n",
       "      <td>78</td>\n",
       "      <td>69</td>\n",
       "      <td>66</td>\n",
       "      <td>69</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>342</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>347</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>348</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>340</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>351</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2008 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PG_ICFES  CON_MAT_ICFES  FISICA_ICFES  QUIMICA_ICFES  IDIOMA_ICFES  \\\n",
       "0          474             65            73             75            79   \n",
       "1          523             99            69             78            60   \n",
       "2          483             63            76             82            77   \n",
       "3          528             88            69             78            75   \n",
       "4          478             78            69             66            69   \n",
       "...        ...            ...           ...            ...           ...   \n",
       "2003       342             68             0              0            58   \n",
       "2004       347             69             0              0            71   \n",
       "2005       348             67             0              0            68   \n",
       "2006       340             70             0              0            63   \n",
       "2007       351             69             0              0            70   \n",
       "\n",
       "      LOCALIDAD  RENDIMIENTO_UNO  \n",
       "0            20                2  \n",
       "1             1                2  \n",
       "2            20                1  \n",
       "3            19                1  \n",
       "4             8                2  \n",
       "...         ...              ...  \n",
       "2003         11                2  \n",
       "2004         19                2  \n",
       "2005         11                1  \n",
       "2006         11                2  \n",
       "2007          7                3  \n",
       "\n",
       "[2008 rows x 7 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos = cargar_datos(carrera, semestre)\n",
    "\n",
    "columnas_filtradas = variables_por_carrera[carrera][semestre]\n",
    "df = datos[columnas_filtradas]\n",
    "print(\"DataFrame con columnas filtradas:\")\n",
    "df=df.astype(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separación de datos usando Pandas\n",
      "(2008, 6) (2008, 1)\n"
     ]
    }
   ],
   "source": [
    "X=df.loc[:, ~df.columns.str.contains('RENDIMIENTO')]\n",
    "Y = df.loc[:, df.columns.str.contains('RENDIMIENTO')]                                                      \n",
    "print(\"Separación de datos usando Pandas\") \n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2008, 6) (2008,)\n"
     ]
    }
   ],
   "source": [
    "X = X.astype('float32')                         \n",
    "Y = LabelEncoder().fit_transform(Y.astype('str'))                \n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor 1 aparece 1249 veces\n",
      "El valor 0 aparece 675 veces\n",
      "El valor 2 aparece 83 veces\n",
      "El valor 3 aparece 1 veces\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "frecuencias = Counter(Y)\n",
    "for valor, frecuencia in frecuencias.items():\n",
    "    print(f\"El valor {valor} aparece {frecuencia} veces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRANSFORMACIÓN DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.598 -0.897  1.005  1.046  1.268  1.353]\n",
      " [ 2.502  2.983  0.97   1.072 -0.304 -2.363]\n",
      " [ 1.767 -1.135  1.031  1.104  1.099  1.353]\n",
      " [ 2.592  1.759  0.97   1.072  0.931  1.202]\n",
      " [ 1.673  0.621  0.97   0.965  0.432 -0.682]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PG_ICFES</th>\n",
       "      <th>CON_MAT_ICFES</th>\n",
       "      <th>FISICA_ICFES</th>\n",
       "      <th>QUIMICA_ICFES</th>\n",
       "      <th>IDIOMA_ICFES</th>\n",
       "      <th>LOCALIDAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.597922</td>\n",
       "      <td>-0.896989</td>\n",
       "      <td>1.005440</td>\n",
       "      <td>1.046458</td>\n",
       "      <td>1.268133</td>\n",
       "      <td>1.353436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.501767</td>\n",
       "      <td>2.983213</td>\n",
       "      <td>0.970075</td>\n",
       "      <td>1.071632</td>\n",
       "      <td>-0.304398</td>\n",
       "      <td>-2.362881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PG_ICFES  CON_MAT_ICFES  FISICA_ICFES  QUIMICA_ICFES  IDIOMA_ICFES  \\\n",
       "0  1.597922      -0.896989      1.005440       1.046458      1.268133   \n",
       "1  2.501767       2.983213      0.970075       1.071632     -0.304398   \n",
       "\n",
       "   LOCALIDAD  \n",
       "0   1.353436  \n",
       "1  -2.362881  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_T_JOHNSON1 = X.copy(deep=True)\n",
    "def transformacion_johnson(X):\n",
    "    transformador_johnson = PowerTransformer(method='yeo-johnson', standardize=True).fit(X)\n",
    "    datos_transformados = transformador_johnson.transform(X)\n",
    "    set_printoptions(precision=3)\n",
    "    print(datos_transformados[:5, :])\n",
    "    datos_transformados_df = pd.DataFrame(data=datos_transformados, columns=X.columns)\n",
    "    return datos_transformados_df\n",
    "Xpandas_T_JOHNSON1 = transformacion_johnson(X_T_JOHNSON1)\n",
    "Xpandas_T_JOHNSON1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom imblearn.over_sampling import RandomOverSampler\\nfrom sklearn.model_selection import train_test_split\\n\\n# Crear una instancia de RandomOverSampler\\nros = RandomOverSampler(sampling_strategy=\\'auto\\', random_state=42)\\n\\n# Aplicar RandomOverSampler para generar muestras sintéticas de las clases minoritarias\\nXpandas_T_JOHNSON1, Y = ros.fit_resample(Xpandas_T_JOHNSON1, Y)\\n\\n# Imprimir la distribución de clases después del oversampling\\nprint(\"Distribución de clases después del oversampling:\", Counter(Y))\\n'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Crear una instancia de RandomOverSampler\n",
    "ros = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "# Aplicar RandomOverSampler para generar muestras sintéticas de las clases minoritarias\n",
    "Xpandas_T_JOHNSON1, Y = ros.fit_resample(Xpandas_T_JOHNSON1, Y)\n",
    "\n",
    "# Imprimir la distribución de clases después del oversampling\n",
    "print(\"Distribución de clases después del oversampling:\", Counter(Y))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATOS: Son 1405 datos para entrenamiento y 603 datos para prueba\n"
     ]
    }
   ],
   "source": [
    "X_trn, X_tst, Y_trn, Y_tst = train_test_split(Xpandas_T_JOHNSON1, Y, test_size=0.3, random_state=2)\n",
    "print('DATOS: Son {} datos para entrenamiento y {} datos para prueba'.format(X_trn.shape[0], X_tst.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom imblearn.over_sampling import RandomOverSampler\\nfrom sklearn.model_selection import train_test_split\\n\\n# Crear una instancia de RandomOverSampler\\nros = RandomOverSampler(sampling_strategy=\\'auto\\', random_state=42)\\n\\n# Aplicar RandomOverSampler para generar muestras sintéticas de las clases minoritarias\\nX_trn,Y_trn = ros.fit_resample(X_trn, Y_trn)\\n\\n# Imprimir la distribución de clases después del oversampling\\nprint(\"Distribución de clases después del oversampling:\", Counter(Y_trn))\\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Crear una instancia de RandomOverSampler\n",
    "ros = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "# Aplicar RandomOverSampler para generar muestras sintéticas de las clases minoritarias\n",
    "X_trn,Y_trn = ros.fit_resample(X_trn, Y_trn)\n",
    "\n",
    "# Imprimir la distribución de clases después del oversampling\n",
    "print(\"Distribución de clases después del oversampling:\", Counter(Y_trn))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor 1 aparece 861 veces\n",
      "El valor 0 aparece 477 veces\n",
      "El valor 2 aparece 66 veces\n",
      "El valor 3 aparece 1 veces\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "frecuencias = Counter(Y_trn)\n",
    "for valor, frecuencia in frecuencias.items():\n",
    "    print(f\"El valor {valor} aparece {frecuencia} veces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNEIGHBORSCLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 59.93161094224925\n",
      "Mejor valor PARAMETRO usando k-fold: {'algorithm': 'auto', 'metric': 'manhattan', 'n_neighbors': 16, 'p': 1, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_knn_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {\n",
    "        'n_neighbors': [i for i in range(14, 18, 1)],\n",
    "        'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "        'algorithm': ['auto'],\n",
    "        'p': [i for i in range(1, 6)],\n",
    "        'weights': ['uniform']\n",
    "    }\n",
    "    modelo = KNeighborsClassifier()\n",
    "    semilla = 5\n",
    "    num_folds = 10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn_transformado, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "\n",
    "    # Entrenar el modelo con los mejores hiperparámetros\n",
    "    mejor_modelo = KNeighborsClassifier(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_knn = entrenar_modelo_knn_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.50792994331564\n",
      "Exhaustividad (Recall):  0.5787728026533997\n",
      "Puntuación F1:  0.52877975562655\n",
      "Exactitud:  0.5787728026533997\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.16      0.21       198\n",
      "           1       0.64      0.82      0.72       388\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.58       603\n",
      "   macro avg       0.31      0.33      0.31       603\n",
      "weighted avg       0.51      0.58      0.53       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_knn.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 59.430597771023294\n",
      "Mejor valor PARAMETRO usando k-fold: {'C': 0.0008, 'gamma': 1.05, 'kernel': 'rbf', 'max_iter': 1, 'random_state': 1}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_svc_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = { 'kernel':  ['rbf'], \n",
    "            'C': [i/10000 for i in range(8,12,1)],\n",
    "            'max_iter':[i for i in range(1,3,1)],\n",
    "            'gamma' : [i/100 for i in range(90,110,5)],\n",
    "            'random_state':[i for i in range(1,5,1)]}\n",
    "    modelo = SVC()\n",
    "    semilla=5\n",
    "    num_folds=10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = SVC(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_svc = entrenar_modelo_svc_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5207791886339446\n",
      "Exhaustividad (Recall):  0.6069651741293532\n",
      "Puntuación F1:  0.5336250490854828\n",
      "Exactitud:  0.6069651741293532\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.11      0.17       198\n",
      "           1       0.64      0.89      0.74       388\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.61       603\n",
      "   macro avg       0.32      0.33      0.30       603\n",
      "weighted avg       0.52      0.61      0.53       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_svc.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 62.56433637284701\n",
      "Mejor valor PARAMETRO usando k-fold: {'criterion': 'entropy', 'max_depth': 4, 'max_features': 6, 'min_samples_leaf': 1, 'min_samples_split': 2, 'random_state': 1, 'splitter': 'random'}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_tree_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {          \n",
    "            'max_depth':[i for i in range(3,6,1)],\n",
    "            'min_samples_split' :  [i for i in range(1,3,1)],  \n",
    "            'min_samples_leaf' : [i for i in range(1,3,1)], \n",
    "            'max_features' : [i for i in range(5,7,1)], \n",
    "            'splitter': [\"best\", \"random\"],\n",
    "            'random_state': [i for i in range(1,4,1)],\n",
    "            'criterion': ['entropy']}\n",
    "    modelo = DecisionTreeClassifier()\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = DecisionTreeClassifier(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_tree = entrenar_modelo_tree_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5300855025473677\n",
      "Exhaustividad (Recall):  0.6235489220563848\n",
      "Puntuación F1:  0.5333105484805998\n",
      "Exactitud:  0.6235489220563848\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.08      0.13       198\n",
      "           1       0.65      0.93      0.76       388\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.62       603\n",
      "   macro avg       0.33      0.34      0.30       603\n",
      "weighted avg       0.53      0.62      0.53       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_tree.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 60.85916919959473\n",
      "Mejor valor PARAMETRO usando k-fold: {}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_gaussian_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {}\n",
    "    modelo = GaussianNB()\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = GaussianNB(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_gaussian = entrenar_modelo_gaussian_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5558536044814331\n",
      "Exhaustividad (Recall):  0.6401326699834162\n",
      "Puntuación F1:  0.5191201508406547\n",
      "Exactitud:  0.6401326699834162\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.03      0.06       198\n",
      "           1       0.65      0.98      0.78       388\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.64       603\n",
      "   macro avg       0.36      0.34      0.28       603\n",
      "weighted avg       0.56      0.64      0.52       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_gaussian.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 61.49848024316109\n",
      "Mejor valor PARAMETRO usando k-fold: {'n_components': 1, 'shrinkage': 1, 'solver': 'lsqr'}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_LDA_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = { 'solver':  ['svd','lsqr','eigen'],\n",
    "            'n_components':[1,2,3,4,5,None],\n",
    "            'shrinkage': ['auto',None, 0, 0.001, 0.01, 0.1, 0.5,1]}\n",
    "    modelo = LinearDiscriminantAnalysis()\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = LinearDiscriminantAnalysis(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_LDA = entrenar_modelo_LDA_con_transformacion(X_trn, Y_trn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5244075546333103\n",
      "Exhaustividad (Recall):  0.6417910447761194\n",
      "Puntuación F1:  0.5094394653585858\n",
      "Exactitud:  0.6417910447761194\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.01      0.02       198\n",
      "           1       0.64      0.99      0.78       388\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.64       603\n",
      "   macro avg       0.33      0.33      0.27       603\n",
      "weighted avg       0.52      0.64      0.51       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_LDA.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BAGGINGCLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'bootstrap_features': False,\n",
       " 'estimator': None,\n",
       " 'max_features': 1.0,\n",
       " 'max_samples': 1.0,\n",
       " 'n_estimators': 10,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "estimator = BaggingClassifier()\n",
    "estimator.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 61.142350557244185\n",
      "Mejor valor PARAMETRO usando k-fold: {'bootstrap': True, 'bootstrap_features': True, 'max_features': 0.6, 'max_samples': 0.45, 'n_estimators': 750}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_BG_con_transformacion(X_trn, Y_trn):\n",
    "    # Aplicar la transformación Yeo-Johnson\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {'n_estimators': [i for i in range(750,760,5)],\n",
    "            'max_samples' : [i/100.0 for i in range(40,50,5)],\n",
    "            'max_features': [i/100.0 for i in range(60,65,5)],\n",
    "            'bootstrap': [True], \n",
    "            'bootstrap_features': [True]}\n",
    "    \n",
    "    base_estimator= DecisionTreeClassifier(criterion= 'gini', \n",
    "                                max_depth=5, max_features= 3,min_samples_leaf= 4, \n",
    "                                min_samples_split = 8,random_state= 10, splitter= 'random')\n",
    "\n",
    "    modelo = BaggingClassifier(estimator=base_estimator, oob_score=True, random_state=1)\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = BaggingClassifier(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "modelo_BG = entrenar_modelo_BG_con_transformacion(X_trn, Y_trn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.6046107532202811\n",
      "Exhaustividad (Recall):  0.6517412935323383\n",
      "Puntuación F1:  0.5627442788824598\n",
      "Exactitud:  0.6517412935323383\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.11      0.18       198\n",
      "           1       0.66      0.96      0.78       388\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.65       603\n",
      "   macro avg       0.40      0.36      0.32       603\n",
      "weighted avg       0.60      0.65      0.56       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_BG.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXTRA TREES CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 61.64032421479231\n",
      "Mejor valor PARAMETRO usando k-fold: {'min_samples_leaf': 1, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_extra_con_transformacion(X_trn, Y_trn):\n",
    "    # Aplicar la transformación Yeo-Johnson\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {'min_samples_split' : [i for i in range(1,3,1)], \n",
    "                'min_samples_leaf' : [i for i in range(0,2,1)] }\n",
    "    \n",
    "    semilla=7            \n",
    "    modelo = ExtraTreesClassifier(random_state=semilla, \n",
    "                                n_estimators=40, max_features=1,max_depth= 10,\n",
    "                                min_samples_leaf=1,  min_samples_split = 2,\n",
    "                                bootstrap=True,criterion='gini') \n",
    "    num_folds=10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = ExtraTreesClassifier(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_extra = entrenar_modelo_extra_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.571788606566432\n",
      "Exhaustividad (Recall):  0.6053067993366501\n",
      "Puntuación F1:  0.5742745143346262\n",
      "Exactitud:  0.6053067993366501\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.26      0.32       198\n",
      "           1       0.66      0.80      0.73       388\n",
      "           2       0.50      0.06      0.11        17\n",
      "\n",
      "    accuracy                           0.61       603\n",
      "   macro avg       0.52      0.38      0.38       603\n",
      "weighted avg       0.57      0.61      0.57       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_extra.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'SAMME.R',\n",
       " 'estimator': None,\n",
       " 'learning_rate': 1.0,\n",
       " 'n_estimators': 50,\n",
       " 'random_state': None}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier            \n",
    "estimator  = AdaBoostClassifier ()\n",
    "estimator.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 61.28368794326241\n",
      "Mejor valor PARAMETRO usando k-fold: {'learning_rate': 0.001}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_ADA_con_transformacion(X_trn, Y_trn):\n",
    "    # Aplicar la transformación Yeo-Johnson\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {'learning_rate' : [i/10000.0 for i in range(5,20,5)]}\n",
    "    semilla=7            \n",
    "    modelo = AdaBoostClassifier(estimator = None,  algorithm = 'SAMME.R', \n",
    "                                random_state= None, n_estimators =50) \n",
    "    num_folds=10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = AdaBoostClassifier(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_ADA = entrenar_modelo_ADA_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.41402715554345465\n",
      "Exhaustividad (Recall):  0.6434494195688225\n",
      "Puntuación F1:  0.5038514122960709\n",
      "Exactitud:  0.6434494195688225\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       198\n",
      "           1       0.64      1.00      0.78       388\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.64       603\n",
      "   macro avg       0.21      0.33      0.26       603\n",
      "weighted avg       0.41      0.64      0.50       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_ADA.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRADIENT BOOSTING MACHINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 61.63931104356638\n",
      "Mejor valor PARAMETRO usando k-fold: {'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_GD_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = { \n",
    "                'subsample' : [ 0.5,0.6,0.7 , 0.75 , 0.8 , 0.85 , 0.9 , 0.95 , 1 ]        \n",
    "              }\n",
    "    semilla=7\n",
    "    modelo = GradientBoostingClassifier(random_state=semilla,\n",
    "                                    n_estimators= 100,learning_rate= 0.1,max_depth= 2,\n",
    "                                    min_samples_split= 2, min_samples_leaf= 3,max_features= 2)\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = GradientBoostingClassifier(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_GD = entrenar_modelo_GD_con_transformacion(X_trn, Y_trn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5528933768459033\n",
      "Exhaustividad (Recall):  0.6185737976782753\n",
      "Puntuación F1:  0.5600654496079799\n",
      "Exactitud:  0.6185737976782753\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.17      0.23       198\n",
      "           1       0.66      0.88      0.75       388\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.62       603\n",
      "   macro avg       0.35      0.35      0.33       603\n",
      "weighted avg       0.55      0.62      0.56       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_GD.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 62.35258358662614\n",
      "Mejor valor PARAMETRO usando k-fold: {'reg_alpha': 0.3, 'reg_lambda': 1.4}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_XB_con_transformacion(X_trn, Y_trn):\n",
    "    # Aplicar la transformación Yeo-Johnson\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {'reg_alpha': [0,0.1,0.2,0.3,0.4,0.5],\n",
    "                'reg_lambda':  [i/100.0 for i in range(130,150,5)]}\n",
    "    semilla=7\n",
    "    modelo = XGBClassifier (random_state=semilla,                       \n",
    "                        n_estimators=40,colsample_bytree = 1, subsample =1,max_depth =2,\n",
    "                        min_child_weight =6,gamma = 0.05,learning_rate = 0.3)\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = XGBClassifier(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_XB = entrenar_modelo_XB_con_transformacion(X_trn, Y_trn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5229913217157277\n",
      "Exhaustividad (Recall):  0.5572139303482587\n",
      "Puntuación F1:  0.5378442260053621\n",
      "Exactitud:  0.5572139303482587\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.27      0.30       198\n",
      "           1       0.65      0.73      0.68       388\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.56       603\n",
      "   macro avg       0.32      0.33      0.33       603\n",
      "weighted avg       0.52      0.56      0.54       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_XB.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CATBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 60.78520770010132\n",
      "Mejor valor PARAMETRO usando k-fold: {'border_count': 53, 'l2_leaf_reg': 42}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_CB_con_transformacion(X_trn, Y_trn):\n",
    "    # Aplicar la transformación Yeo-Johnson\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {'border_count':[53],'l2_leaf_reg': [42]} \n",
    "    semilla=7\n",
    "    modelo = CatBoostClassifier(random_state=semilla, verbose =0)\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = CatBoostClassifier(verbose=0,**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_CB = entrenar_modelo_CB_con_transformacion(X_trn, Y_trn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5410368802256945\n",
      "Exhaustividad (Recall):  0.6218905472636815\n",
      "Puntuación F1:  0.5477270824633331\n",
      "Exactitud:  0.6218905472636815\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.12      0.18       198\n",
      "           1       0.65      0.90      0.76       388\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.62       603\n",
      "   macro avg       0.34      0.34      0.31       603\n",
      "weighted avg       0.54      0.62      0.55       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_CB.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIGHT GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 379\n",
      "[LightGBM] [Info] Number of data points in the train set: 1405, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score -1.080276\n",
      "[LightGBM] [Info] Start training from score -0.489698\n",
      "[LightGBM] [Info] Start training from score -3.058138\n",
      "[LightGBM] [Info] Start training from score -7.247793\n",
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 62.06788247213779\n",
      "Mejor valor PARAMETRO usando k-fold: {'min_child_samples': 200}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_LIGHT_con_transformacion(X_trn, Y_trn):\n",
    "    # Aplicar la transformación Yeo-Johnson\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = { 'min_child_samples' : [i for i in range(200, 10000, 100)]}\n",
    "    semilla=7\n",
    "    modelo = LGBMClassifier (random_state=semilla,                           \n",
    "                        num_leaves =  10,max_depth = 1, n_estimators = 100,    \n",
    "                        learning_rate = 0.1 ,class_weight=  None, subsample = 1,\n",
    "                        colsample_bytree= 1, reg_alpha=  0, reg_lambda = 0,\n",
    "                        min_split_gain = 0, boosting_type = 'gbdt')\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = KFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = LGBMClassifier(verbose=-1,**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_LIGHT = entrenar_modelo_LIGHT_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5505247485201729\n",
      "Exhaustividad (Recall):  0.6285240464344942\n",
      "Puntuación F1:  0.5479421916800242\n",
      "Exactitud:  0.6285240464344942\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.11      0.17       198\n",
      "           1       0.65      0.92      0.76       388\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.63       603\n",
      "   macro avg       0.35      0.34      0.31       603\n",
      "weighted avg       0.55      0.63      0.55       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_LIGHT.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VOTING - VOTACIÓN DURA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento del modelo:\n",
      "Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold: 61.92401215805472  % \n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_voting_hard_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    semilla= 7 \n",
    "    kfold = KFold(n_splits=10, random_state=semilla, shuffle=True)\n",
    "    \n",
    "    modelo1 = GradientBoostingClassifier(random_state=semilla, n_estimators=800, \n",
    "                                    learning_rate = 0.01, max_depth = 2,\n",
    "                                    max_features =2, min_samples_leaf = 9, \n",
    "                                    min_samples_split = 2, subsample = 1 )\n",
    "    \n",
    "    base_estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, \n",
    "                                    criterion='gini',\n",
    "                                    max_depth=8, max_features=1, max_leaf_nodes=None,\n",
    "                                    min_impurity_decrease=0.0,\n",
    "                                    min_samples_leaf=1, min_samples_split=5,\n",
    "                                    min_weight_fraction_leaf=0.0,\n",
    "                                    random_state=5, splitter='random')\n",
    "\n",
    "    modelo2 = AdaBoostClassifier(estimator=base_estimator,n_estimators=1200, \n",
    "                                    algorithm ='SAMME.R', learning_rate = 0.001, \n",
    "                                    random_state=semilla)\n",
    "\n",
    "    modelo3 = ExtraTreesClassifier(n_estimators=300, max_features=None,\n",
    "                                    bootstrap = False, max_depth = 11,min_samples_split = 4, \n",
    "                                    min_samples_leaf = 1)\n",
    "\n",
    "    modelo4 = RandomForestClassifier (n_estimators=1100, max_features=None,\n",
    "                                    min_samples_split = 5, max_depth= 3, \n",
    "                                    min_samples_leaf= 1)\n",
    "\n",
    "    model = DecisionTreeClassifier(criterion= 'gini', \n",
    "                                    max_depth=6, \n",
    "                                    max_features= None, \n",
    "                                    min_samples_leaf= 9, \n",
    "                                    min_samples_split = 2, \n",
    "                                    random_state= 10, \n",
    "                                    splitter= 'random')\n",
    "\n",
    "    modelo5 = BaggingClassifier(estimator=model, n_estimators=50, \n",
    "                                    random_state=semilla,\n",
    "                                    bootstrap= True, bootstrap_features = False, \n",
    "                                    max_features = 0.9,\n",
    "                                    max_samples= 0.95)\n",
    "\n",
    "    modelo6 = DecisionTreeClassifier(criterion= 'gini', max_depth=6,max_features= None, \n",
    "                                    min_samples_leaf= 9, \n",
    "                                    min_samples_split = 2, random_state= 10, splitter= 'random')\n",
    "\n",
    "    modelo7 = XGBClassifier(n_estimators= 40, random_state=semilla,colsample_bytree = 1, \n",
    "                                    subsample =1, reg_alpha = 0.2, reg_lambda= 1.35,\n",
    "                                    learning_rate= 0.3,max_depth =2, min_child_weight =6,\n",
    "                                    gamma = 0.05)\n",
    "    metrica = 'accuracy'\n",
    "    mejor_modelo = VotingClassifier(\n",
    "    estimators=[('Gradient', modelo1), ('Adaboost', modelo2), \n",
    "                                    ('Extratrees', modelo3),('Random Forest',modelo4),\n",
    "                                    ('Bagging',modelo5),('Decision tree',modelo6),\n",
    "                                    ('XGB',modelo7)],voting='hard') \n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    resultados = cross_val_score(mejor_modelo, X_trn_transformado, Y_trn, \n",
    "                                    cv=kfold,scoring = metrica)\n",
    "    print(\"Rendimiento del modelo:\") \n",
    "    print (\"Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold:\", resultados.mean()*100,\" % \") \n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_voting_hard = entrenar_modelo_voting_hard_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.5598971658449382\n",
      "Exhaustividad (Recall):  0.6401326699834162\n",
      "Puntuación F1:  0.5295854720389799\n",
      "Exactitud:  0.6401326699834162\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.05      0.09       198\n",
      "           1       0.65      0.97      0.78       388\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.64       603\n",
      "   macro avg       0.36      0.34      0.29       603\n",
      "weighted avg       0.56      0.64      0.53       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_voting_hard.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VOTING - VOTACIÓN SUAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento del modelo:\n",
      "Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold: 62.279128672745685  % \n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_voting_soft_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    semilla= 7 \n",
    "    kfold = KFold(n_splits=10, random_state=semilla, shuffle=True)\n",
    "    modelo1 = GradientBoostingClassifier(random_state=semilla, n_estimators=800, \n",
    "                                    learning_rate = 0.01, max_depth = 2,\n",
    "                                    max_features =2, min_samples_leaf = 9, \n",
    "                                    min_samples_split = 2, subsample = 1 )\n",
    "    \n",
    "    base_estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "                                    max_depth=8, max_features=1, max_leaf_nodes=None,\n",
    "                                    min_impurity_decrease=0.0,\n",
    "                                    min_samples_leaf=1, min_samples_split=5,\n",
    "                                    min_weight_fraction_leaf=0.0,\n",
    "                                    random_state=5, splitter='random')\n",
    "\n",
    "    modelo2 = AdaBoostClassifier(estimator=base_estimator,n_estimators=1200, \n",
    "                                    algorithm ='SAMME.R', learning_rate = 0.001, \n",
    "                                    random_state=semilla)\n",
    "\n",
    "    modelo3 = ExtraTreesClassifier(n_estimators=300, max_features=None,bootstrap = False, \n",
    "                                    max_depth = 11,min_samples_split = 4, \n",
    "                                    min_samples_leaf = 1)\n",
    "\n",
    "    modelo4 = RandomForestClassifier (n_estimators=1100, max_features=None,\n",
    "                                    min_samples_split = 5, max_depth= 3, min_samples_leaf= 1)\n",
    "\n",
    "    model = DecisionTreeClassifier(criterion= 'gini', \n",
    "                                    max_depth=6, \n",
    "                                    max_features= None, \n",
    "                                    min_samples_leaf= 9, \n",
    "                                    min_samples_split = 2, \n",
    "                                    random_state= 10, \n",
    "                                    splitter= 'random')\n",
    "\n",
    "    modelo5 = BaggingClassifier(estimator=model, n_estimators=50, random_state=semilla,\n",
    "                                    bootstrap= True, bootstrap_features = False, \n",
    "                                    max_features = 0.9, max_samples= 0.95)\n",
    "\n",
    "    modelo6 = DecisionTreeClassifier(criterion= 'gini', max_depth=6,max_features= None, \n",
    "                                    min_samples_leaf= 9, min_samples_split = 2, \n",
    "                                    random_state= 10, splitter= 'random')\n",
    "    metrica = 'accuracy'\n",
    "    mejor_modelo = VotingClassifier(\n",
    "    estimators=[('Gradient', modelo1), ('Adaboost', modelo2), ('Extratrees', modelo3),\n",
    "                                    ('Random Forest',modelo4),\n",
    "                                    ('Bagging',modelo5),('Decision tree',modelo6)],\n",
    "    voting='soft',weights=[0.9,0.7,0.9,0.9,0.9,0.9]) \n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    resultados = cross_val_score(mejor_modelo, X_trn_transformado, Y_trn, cv=kfold,scoring = metrica)\n",
    "    print(\"Rendimiento del modelo:\") \n",
    "    print (\"Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold:\", resultados.mean()*100,\" % \") \n",
    "    return mejor_modelo\n",
    "\n",
    "# Cargar los datos\n",
    "#datos = cargar_datos(carrera, semestre)\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "# Entrenar el modelo KNN con transformación Yeo-Johnson\n",
    "modelo_voting_soft = entrenar_modelo_voting_soft_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.578127879122904\n",
      "Exhaustividad (Recall):  0.6451077943615257\n",
      "Puntuación F1:  0.5398875608128101\n",
      "Exactitud:  0.6451077943615257\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.07      0.12       198\n",
      "           1       0.65      0.97      0.78       388\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.65       603\n",
      "   macro avg       0.38      0.34      0.30       603\n",
      "weighted avg       0.58      0.65      0.54       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_voting_soft.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLENDING ( METAMODELO LINEAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento del modelo:\n",
      "Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold: 62.34802431610943  % \n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_stacking_lineal_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    semilla= 7 \n",
    "    kfold = KFold(n_splits=10, random_state=semilla, shuffle=True)\n",
    "    base_estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "                                    max_depth=8, max_features=1, max_leaf_nodes=None,\n",
    "                                    min_impurity_decrease=0.0,\n",
    "                                    min_samples_leaf=1, min_samples_split=5,\n",
    "                                    min_weight_fraction_leaf=0.0,\n",
    "                                    random_state=5, splitter='random')\n",
    "    modelo2 = AdaBoostClassifier(estimator=base_estimator,n_estimators=500, \n",
    "                                    algorithm ='SAMME.R', learning_rate = 0.001, \n",
    "                                    random_state=semilla)\n",
    "\n",
    "    modelo3 = ExtraTreesClassifier(n_estimators=300, max_features=None,bootstrap = False, \n",
    "                                    max_depth = 11,min_samples_split = 4, \n",
    "                                    min_samples_leaf = 1)\n",
    "\n",
    "    modelo4 = RandomForestClassifier (n_estimators=300, max_features=None,\n",
    "                                    min_samples_split = 5, max_depth= 3, min_samples_leaf= 1)\n",
    "    model = DecisionTreeClassifier(criterion= 'gini', \n",
    "                                    max_depth=6, \n",
    "                                    max_features= None, \n",
    "                                    min_samples_leaf= 9, \n",
    "                                    min_samples_split = 2, \n",
    "                                    random_state= 10, \n",
    "                                    splitter= 'random')\n",
    "\n",
    "    modelo5 = BaggingClassifier(estimator=model, n_estimators=50, random_state=semilla,\n",
    "                                    bootstrap= True, bootstrap_features = False, \n",
    "                                    max_features = 0.9,\n",
    "                                    max_samples= 0.95)\n",
    "\n",
    "    modelo6 = DecisionTreeClassifier(criterion= 'gini', max_depth=6,max_features= None, \n",
    "                                    min_samples_leaf= 9, \n",
    "                                    min_samples_split = 2, random_state= 10, splitter= 'random')\n",
    "    estimador_final = LogisticRegression()\n",
    "    metrica = 'accuracy'\n",
    "    mejor_modelo = StackingClassifier(\n",
    "    estimators=[ ('Adaboost', modelo2), ('Extratrees', modelo3),('Random Forest',modelo4),\n",
    "                                    ('Bagging',modelo5),('Decision tree',modelo6)], \n",
    "                                    final_estimator=estimador_final) \n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    resultados = cross_val_score(mejor_modelo, X_trn_transformado, Y_trn, cv=kfold,scoring = metrica)\n",
    "    print(\"Rendimiento del modelo:\") \n",
    "    print (\"Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold:\", resultados.mean()*100,\" % \") \n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_stacking_lineal = entrenar_modelo_stacking_lineal_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión:  0.6171040739863294\n",
      "Exhaustividad (Recall):  0.6567164179104478\n",
      "Puntuación F1:  0.5642628580817219\n",
      "Exactitud:  0.6567164179104478\n",
      "\n",
      "Informe de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.11      0.18       198\n",
      "           1       0.66      0.97      0.79       388\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.66       603\n",
      "   macro avg       0.41      0.36      0.32       603\n",
      "weighted avg       0.62      0.66      0.56       603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_stacking_lineal.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STACKING (METAMODELO NO LINEAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento del modelo:\n",
      "Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold: 61.142350557244185  % \n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_stacking_nolineal_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    semilla= 7 \n",
    "    kfold = KFold(n_splits=10, random_state=semilla, shuffle=True)\n",
    "    modelo3 = ExtraTreesClassifier(n_estimators=400, max_features=None,bootstrap = False, \n",
    "                                    max_depth = 11,min_samples_split = 4, \n",
    "                                    min_samples_leaf = 1)\n",
    "\n",
    "    modelo4 = RandomForestClassifier (n_estimators=500, max_features=None,\n",
    "                                    min_samples_split = 5, max_depth= 3, min_samples_leaf= 1)\n",
    "    model = DecisionTreeClassifier(criterion= 'gini', \n",
    "                                    max_depth=6, max_features= None,  min_samples_leaf= 9, \n",
    "                                    min_samples_split = 2, \n",
    "                                    random_state= 10, splitter= 'random')\n",
    "\n",
    "    modelo5 = BaggingClassifier(estimator=model, n_estimators=50, random_state=semilla,\n",
    "                                    bootstrap= True, bootstrap_features = False, \n",
    "                                    max_features = 0.9, max_samples= 0.95)\n",
    "\n",
    "    modelo6 = DecisionTreeClassifier(criterion= 'gini', max_depth=6,max_features= None, \n",
    "                                    min_samples_leaf= 9, min_samples_split = 2, \n",
    "                                    random_state= 10, splitter= 'random')\n",
    "    estimador_final = ExtraTreesClassifier(n_estimators=100, max_features=None,\n",
    "                                    bootstrap = False, max_depth = 11,min_samples_split = 4, \n",
    "                                    min_samples_leaf = 1)\n",
    "    metrica = 'accuracy'\n",
    "    mejor_modelo = StackingClassifier(\n",
    "    estimators=[  ('Extratrees', modelo3),('Random Forest',modelo4),('Bagging',modelo5),\n",
    "                                    ('Decision tree',modelo6)], \n",
    "                                    final_estimator=estimador_final) \n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    resultados = cross_val_score(mejor_modelo, X_trn_transformado, Y_trn, cv=kfold,scoring = metrica)\n",
    "    print(\"Rendimiento del modelo:\") \n",
    "    print (\"Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold:\", resultados.mean()*100,\" % \") \n",
    "    return mejor_modelo\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_stacking_nolineal = entrenar_modelo_stacking_nolineal_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir las etiquetas para los datos de prueba\n",
    "Y_pred = modelo_stacking_nolineal.predict(X_tst)\n",
    "\n",
    "precision = precision_score(Y_tst, Y_pred, average='weighted')\n",
    "recall = recall_score(Y_tst, Y_pred, average='weighted')\n",
    "f1 = f1_score(Y_tst, Y_pred, average='weighted')\n",
    "accuracy = accuracy_score(Y_tst, Y_pred)\n",
    "print(\"Precisión: \", precision)\n",
    "print(\"Exhaustividad (Recall): \", recall)\n",
    "print(\"Puntuación F1: \", f1)\n",
    "print(\"Exactitud: \", accuracy)\n",
    "\n",
    "# Informe de clasificación detallado\n",
    "print(\"\\nInforme de clasificación:\")\n",
    "print(classification_report(Y_tst, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUPER APRENDIZ CON ML ESEMBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUPER APRENDIZ CON ML ESEMBLE - DOS CAPAS "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
