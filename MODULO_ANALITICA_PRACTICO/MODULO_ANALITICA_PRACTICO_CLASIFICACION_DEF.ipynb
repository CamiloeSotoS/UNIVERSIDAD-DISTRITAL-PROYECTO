{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MLENS] backend: threading\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from numpy import set_printoptions\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "pd.options.display.max_columns=None\n",
    "import seaborn as sns \n",
    "from pandas import read_csv\n",
    "import io\n",
    "import base64\n",
    "import json\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.drawing.image import Image as XLImage\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "from unidecode import unidecode\n",
    "\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from mlens.ensemble import SuperLearner\n",
    "\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CARGUE DE DATOS Y CONEXIÓN A DRIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=899973764197-biu188dkvsgi2al0fh29udm7keak0lh0.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A57444%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.readonly&state=4LUz39Scu5u45hZGugazwoF7ZhNTNY&access_type=offline\n",
      "Descargando industrial9.csv: 100%\n",
      "Descargando industrial4.csv: 100%\n",
      "Descargando industrial3.csv: 100%\n",
      "Descargando industrial10.csv: 100%\n",
      "Descargando industrial6.csv: 100%\n",
      "Descargando industrial5.csv: 100%\n",
      "Descargando industrial2.csv: 100%\n",
      "Descargando industrial8.csv: 100%\n",
      "Descargando industrial7.csv: 100%\n",
      "Descargando industrial1.csv: 100%\n",
      "Descargando Limpieza de datos 1 UD.ipynb: 100%\n",
      "Descargando sistemas10.csv: 100%\n",
      "Descargando sistemas6.csv: 100%\n",
      "Descargando sistemas2.csv: 100%\n",
      "Descargando sistemas7.csv: 100%\n",
      "Descargando sistemas4.csv: 100%\n",
      "Descargando sistemas9.csv: 100%\n",
      "Descargando sistemas5.csv: 100%\n",
      "Descargando sistemas3.csv: 100%\n",
      "Descargando sistemas8.csv: 100%\n",
      "Descargando electrica10.csv: 100%\n",
      "Descargando electrica9.csv: 100%\n",
      "Descargando electrica8.csv: 100%\n",
      "Descargando electrica7.csv: 100%\n",
      "Descargando electrica6.csv: 100%\n",
      "Descargando electrica5.csv: 100%\n",
      "Descargando electrica4.csv: 100%\n",
      "Descargando electrica3.csv: 100%\n",
      "Descargando electrica2.csv: 100%\n",
      "Descargando catastral2.csv: 100%\n",
      "Descargando catastral5.csv: 100%\n",
      "Descargando electronica7.csv: 100%\n",
      "Descargando electronica5.csv: 100%\n",
      "Descargando catastral10.csv: 100%\n",
      "Descargando catastral9.csv: 100%\n",
      "Descargando catastral8.csv: 100%\n",
      "Descargando catastral3.csv: 100%\n",
      "Descargando catastral7.csv: 100%\n",
      "Descargando catastral6.csv: 100%\n",
      "Descargando catastral4.csv: 100%\n",
      "Descargando electronica10.csv: 100%\n",
      "Descargando electronica9.csv: 100%\n",
      "Descargando electronica8.csv: 100%\n",
      "Descargando electronica6.csv: 100%\n",
      "Descargando electronica4.csv: 100%\n",
      "Descargando electronica3.csv: 100%\n",
      "Descargando electronica2.csv: 100%\n",
      "Descargando electronica1.csv: 100%\n",
      "Descarga completa\n",
      "Archivos descargados:\n",
      "catastral10.csv\n",
      "catastral2.csv\n",
      "catastral3.csv\n",
      "catastral4.csv\n",
      "catastral5.csv\n",
      "catastral6.csv\n",
      "catastral7.csv\n",
      "catastral8.csv\n",
      "catastral9.csv\n",
      "electrica10.csv\n",
      "electrica2.csv\n",
      "electrica3.csv\n",
      "electrica4.csv\n",
      "electrica5.csv\n",
      "electrica6.csv\n",
      "electrica7.csv\n",
      "electrica8.csv\n",
      "electrica9.csv\n",
      "electronica1.csv\n",
      "electronica10.csv\n",
      "electronica2.csv\n",
      "electronica3.csv\n",
      "electronica4.csv\n",
      "electronica5.csv\n",
      "electronica6.csv\n",
      "electronica7.csv\n",
      "electronica8.csv\n",
      "electronica9.csv\n",
      "industrial1.csv\n",
      "industrial10.csv\n",
      "industrial2.csv\n",
      "industrial3.csv\n",
      "industrial4.csv\n",
      "industrial5.csv\n",
      "industrial6.csv\n",
      "industrial7.csv\n",
      "industrial8.csv\n",
      "industrial9.csv\n",
      "Limpieza de datos 1 UD.ipynb\n",
      "sistemas10.csv\n",
      "sistemas2.csv\n",
      "sistemas3.csv\n",
      "sistemas4.csv\n",
      "sistemas5.csv\n",
      "sistemas6.csv\n",
      "sistemas7.csv\n",
      "sistemas8.csv\n",
      "sistemas9.csv\n"
     ]
    }
   ],
   "source": [
    "SCOPES = ['https://www.googleapis.com/auth/drive.readonly']\n",
    "\n",
    "creds = None\n",
    "if os.path.exists('token.json'):\n",
    "    creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "if not creds or not creds.valid:\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "        creds.refresh(Request())\n",
    "    else:\n",
    "        flow = InstalledAppFlow.from_client_secrets_file('C:/Users/Intevo/Desktop/UNIVERSIDAD DISTRITAL PROYECTO FOLDER/credentials.json', SCOPES) # Reemplazar con la ruta correcta\n",
    "        creds = flow.run_local_server(port=0)\n",
    "    with open('C:/Users/Intevo/Desktop/UNIVERSIDAD DISTRITAL PROYECTO FOLDER/token.json', 'w') as token:\n",
    "        token.write(creds.to_json())\n",
    "        \n",
    "# Crear una instancia de la API de Drive\n",
    "drive_service = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "# ID de la carpeta de Google Drive\n",
    "folder_id = '1hQeetmO4XIObUefS_nzePqKqq3VksUEC'\n",
    "\n",
    "# Ruta de destino para guardar los archivos descargados\n",
    "save_path = 'C:/Users/Intevo/Desktop/UNIVERSIDAD DISTRITAL PROYECTO FOLDER/UNIVERSIDAD-DISTRITAL-PROYECTO/MODULO_ANALITICA_PRACTICO/DATOS'  # Reemplazar con la ruta deseada\n",
    "\n",
    "# Función para descargar archivos de la carpeta de Drive\n",
    "def download_folder(folder_id, save_path):\n",
    "    results = drive_service.files().list(\n",
    "        q=f\"'{folder_id}' in parents and trashed=false\",\n",
    "        fields='files(id, name)').execute()\n",
    "    items = results.get('files', [])\n",
    "    for item in items:\n",
    "        file_id = item['id']\n",
    "        file_name = item['name']\n",
    "        request = drive_service.files().get_media(fileId=file_id)\n",
    "        fh = io.FileIO(os.path.join(save_path, file_name), 'wb')\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "        done = False\n",
    "        while done is False:\n",
    "            status, done = downloader.next_chunk()\n",
    "            print(f\"Descargando {file_name}: {int(status.progress() * 100)}%\")\n",
    "    print(\"Descarga completa\")\n",
    "\n",
    "# Descargar archivos de la carpeta\n",
    "download_folder(folder_id, save_path)\n",
    "\n",
    "# Listar archivos descargados\n",
    "files = os.listdir(save_path)\n",
    "print(\"Archivos descargados:\")\n",
    "for file in files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_por_carrera = { \n",
    "    'industrial': {\n",
    "        '1': ['PG_ICFES', 'CON_MAT_ICFES', 'FISICA_ICFES','QUIMICA_ICFES','IDIOMA_ICFES','LOCALIDAD','RENDIMIENTO_UNO'],\n",
    "        '2': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'FISICA_ICFES', 'BIOLOGIA_ICFES', 'IDIOMA_ICFES', 'LOCALIDAD', 'PROMEDIO_UNO', 'CAR_UNO', 'NCC_UNO', 'NAA_UNO', 'NOTA_DIFERENCIAL', 'NOTA_DIBUJO', 'NOTA_QUIMICA', 'NOTA_CFJC', 'NOTA_TEXTOS', 'NOTA_SEMINARIO', 'NOTA_EE_UNO','RENDIMIENTO_DOS'],\n",
    "        '3': ['PROMEDIO_UNO', 'NAA_UNO', 'NOTA_DIFERENCIAL', 'NOTA_DIBUJO', 'NOTA_TEXTOS', 'NOTA_EE_UNO', 'PROMEDIO_DOS', 'NCC_DOS', 'NCA_DOS', 'NAA_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_PBASICA', 'NOTA_EE_DOS', 'RENDIMIENTO_TRES'],\n",
    "        '4': ['PROMEDIO_UNO', 'NOTA_EE_UNO', 'PROMEDIO_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'NAA_TRES', 'NOTA_MULTIVARIADO', 'NOTA_ESTADISTICA_UNO', 'NOTA_TERMODINAMICA', 'NOTA_TGS', 'NOTA_EE_TRES','RENDIMIENTO_CUATRO'],\n",
    "        '5': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_EE_DOS','PROMEDIO_TRES', 'NAA_TRES', 'NOTA_MULTIVARIADO', 'NOTA_TERMODINAMICA', 'NOTA_ECUACIONES', 'NOTA_ESTADISTICA_DOS', 'NOTA_FISICA_DOS', 'NOTA_MECANICA', 'NOTA_PROCESOSQ', 'RENDIMIENTO_CINCO'],\n",
    "        '6': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_ADMINISTRACION', 'NOTA_LENGUA_UNO', 'NOTA_EI_UNO', 'NOTA_EI_DOS', 'RENDIMIENTO_SEIS'],\n",
    "        '7': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_LENGUA_UNO', 'NOTA_EI_DOS', 'PROMEDIO_SEIS', 'NCA_SEIS', 'NOTA_PLINEAL', 'NOTA_DISENO', 'NOTA_EI_TRES','RENDIMIENTO_SIETE'],\n",
    "        '8': ['PROMEDIO_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_LENGUA_UNO','PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'RENDIMIENTO_OCHO'],\n",
    "        '9': ['PROMEDIO_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'PROMEDIO_OCHO', 'NCC_OCHO', 'NOTA_LOG_UNO', 'NOTA_GOPERACIONES','NOTA_CALIDAD_DOS', 'NOTA_LENGUA_DOS', 'NOTA_CONTEXTO', 'RENDIMIENTO_NUEVE'],\n",
    "        '10': ['PROMEDIO_SEIS', 'PROMEDIO_SIETE', 'PROMEDIO_OCHO', 'NOTA_CALIDAD_DOS', 'PROMEDIO_NUEVE', 'NAA_NUEVE', 'NOTA_GRADO_UNO', 'NOTA_LOG_DOS', 'NOTA_FINANZAS', 'NOTA_HISTORIA', 'RENDIMIENTO_DIEZ']\n",
    "    },\n",
    "    'sistemas': {\n",
    "        '1': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'FISICA_ICFES', 'QUIMICA_ICFES', 'IDIOMA_ICFES', 'LOCALIDAD', 'RENDIMIENTO_UNO'],\n",
    "        '2': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'IDIOMA_ICFES', 'PROMEDIO_UNO', 'NOTA_DIFERENCIAL', 'NOTA_PROG_BASICA', 'NOTA_CATEDRA_FJC', 'NOTA_TEXTOS', 'NOTA_SEMINARIO', 'NOTA_CATEDRA_DEM', 'NOTA_CATEDRA_CON', 'NOTA_LOGICA', 'RENDIMIENTO_DOS'],\n",
    "        '3': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'IDIOMA_ICFES', 'PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_PROG_BASICA', 'NOTA_TEXTOS', 'NOTA_CATEDRA_DEM', 'NOTA_INTEGRAL', 'NOTA_PROG_ORIENTADA', 'NOTA_ETICA', 'RENDIMIENTO_TRES'],\n",
    "        '4': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'IDIOMA_ICFES', 'PROMEDIO_UNO', 'PROMEDIO_DOS', 'PROMEDIO_TRES', 'NOTA_PROG_BASICA', 'NOTA_TEXTOS', 'NOTA_CATEDRA_DEM', 'NOTA_INTEGRAL', 'NOTA_PROG_ORIENTADA', 'NOTA_ETICA', 'NOTA_FISICA_DOS', 'NOTA_TGS', 'NOTA_PROG_AVANZADA', 'RENDIMIENTO_CUATRO'],\n",
    "        '5': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NAA_TRES', 'NOTA_MULTIVARIADO', 'NOTA_TERMODINAMICA', 'NOTA_ECUACIONES', 'NOTA_ESTADISTICA_DOS', 'NOTA_FISICA_DOS', 'NOTA_MECANICA', 'NOTA_PROCESOSQ', 'RENDIMIENTO_CINCO'],\n",
    "        '6': ['PROMEDIO_UNO', 'NOTA_EE_UNO', 'PROMEDIO_DOS', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_ECONOMIA_UNO', 'NOTA_FISICA_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_ADMINISTRACION', 'NOTA_LENGUA_UNO', 'NOTA_EI_UNO', 'NOTA_EI_DOS', 'RENDIMIENTO_SEIS'],\n",
    "        '7': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_LENGUA_UNO', 'NOTA_EI_DOS', 'PROMEDIO_SEIS', 'NCA_SEIS', 'NOTA_PLINEAL', 'NOTA_DISE O', 'NOTA_EI_TRES', 'RENDIMIENTO_SIETE'],\n",
    "        '8': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_LENGUA_UNO', 'PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'RENDIMIENTO_OCHO'],\n",
    "        '9': ['PROMEDIO_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'PROMEDIO_OCHO', 'NCC_OCHO', 'NOTA_LOG_UNO', 'NOTA_GOPERACIONES', 'NOTA_CALIDAD_DOS', 'NOTA_LENGUA_DOS', 'NOTA_CONTEXTO', 'RENDIMIENTO_NUEVE'],\n",
    "        '10': ['PROMEDIO_SEIS', 'PROMEDIO_SIETE', 'PROMEDIO_OCHO', 'NOTA_CALIDAD_DOS', 'PROMEDIO_NUEVE', 'NAA_NUEVE', 'NOTA_GRADO_UNO', 'NOTA_LOG_DOS', 'NOTA_FINANZAS', 'NOTA_HISTORIA', 'RENDIMIENTO_DIEZ']\n",
    "    },\n",
    "    'catastral': {\n",
    "        '1': ['variable1_catastral', 'variable2_catastral', 'variable3_catastral'],\n",
    "        '2': ['variable4_catastral', 'variable5_catastral', 'variable6_catastral']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_datos(carrera, semestre):\n",
    "    \n",
    "    ruta_archivo = f'C:/Users/Intevo/Desktop/UNIVERSIDAD DISTRITAL PROYECTO FOLDER/UNIVERSIDAD-DISTRITAL-PROYECTO/MODULO_ANALITICA_PRACTICO/DATOS/{carrera}{semestre}.csv'\n",
    "    datos = pd.read_csv(ruta_archivo,sep=\";\")\n",
    "    \n",
    "    return datos\n",
    "carrera=\"industrial\"\n",
    "semestre=\"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame con columnas filtradas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROMEDIO_UNO</th>\n",
       "      <th>NOTA_EE_UNO</th>\n",
       "      <th>PROMEDIO_DOS</th>\n",
       "      <th>NOTA_ALGEBRA</th>\n",
       "      <th>NOTA_INTEGRAL</th>\n",
       "      <th>NOTA_MATERIALES</th>\n",
       "      <th>NOTA_EE_DOS</th>\n",
       "      <th>NAA_TRES</th>\n",
       "      <th>NOTA_MULTIVARIADO</th>\n",
       "      <th>NOTA_ESTADISTICA_UNO</th>\n",
       "      <th>NOTA_TERMODINAMICA</th>\n",
       "      <th>NOTA_TGS</th>\n",
       "      <th>NOTA_EE_TRES</th>\n",
       "      <th>RENDIMIENTO_CUATRO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>44</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>39</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>38</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>44</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>36</td>\n",
       "      <td>34</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>39</td>\n",
       "      <td>41</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2282</th>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>24</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>41</td>\n",
       "      <td>24</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>19</td>\n",
       "      <td>31</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>35</td>\n",
       "      <td>44</td>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>28</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2285</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>33</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286</th>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>38</td>\n",
       "      <td>36</td>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>46</td>\n",
       "      <td>32</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2287 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PROMEDIO_UNO  NOTA_EE_UNO  PROMEDIO_DOS  NOTA_ALGEBRA  NOTA_INTEGRAL  \\\n",
       "0               26            0            11             4              0   \n",
       "1               39           44            33            34             29   \n",
       "2               35           39            34            32             33   \n",
       "3               30            0            31            30             21   \n",
       "4               38           44            33            32             36   \n",
       "...            ...          ...           ...           ...            ...   \n",
       "2282            34           45            33            33             24   \n",
       "2283            28            0            31            41             24   \n",
       "2284            35           44            35            32             27   \n",
       "2285            34            0            32            30             28   \n",
       "2286            42           41            38            36             28   \n",
       "\n",
       "      NOTA_MATERIALES  NOTA_EE_DOS  NAA_TRES  NOTA_MULTIVARIADO  \\\n",
       "0                   0            0         1                  0   \n",
       "1                  30           32         5                 34   \n",
       "2                  38           30         7                 40   \n",
       "3                  34            0         2                  0   \n",
       "4                  34           40         6                 31   \n",
       "...               ...          ...       ...                ...   \n",
       "2282               35            0         6                 31   \n",
       "2283               34            0         4                 32   \n",
       "2284               32           41         6                 43   \n",
       "2285               31            0         4                 19   \n",
       "2286               33           45         6                  0   \n",
       "\n",
       "      NOTA_ESTADISTICA_UNO  NOTA_TERMODINAMICA  NOTA_TGS  NOTA_EE_TRES  \\\n",
       "0                        0                   0         0             0   \n",
       "1                       34                  29        25            39   \n",
       "2                       32                  30        31            47   \n",
       "3                        0                   0        33             0   \n",
       "4                       39                  41        32             0   \n",
       "...                    ...                 ...       ...           ...   \n",
       "2282                    30                  37        38             0   \n",
       "2283                    19                  31        28             0   \n",
       "2284                    28                  38        39            38   \n",
       "2285                    30                  33        37             0   \n",
       "2286                    33                  46        32            48   \n",
       "\n",
       "      RENDIMIENTO_CUATRO  \n",
       "0                      0  \n",
       "1                      2  \n",
       "2                      2  \n",
       "3                      1  \n",
       "4                      2  \n",
       "...                  ...  \n",
       "2282                   2  \n",
       "2283                   2  \n",
       "2284                   1  \n",
       "2285                   3  \n",
       "2286                   2  \n",
       "\n",
       "[2287 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos = cargar_datos(carrera, semestre)\n",
    "columnas_filtradas = variables_por_carrera[carrera][semestre]\n",
    "df = datos[columnas_filtradas]\n",
    "print(\"DataFrame con columnas filtradas:\")\n",
    "df=df.astype(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuatro\n"
     ]
    }
   ],
   "source": [
    "def numero_a_letras(numero):\n",
    "    numeros_letras = ['cero', 'uno', 'dos', 'tres', 'cuatro', 'cinco', 'seis', 'siete', 'ocho', 'nueve', 'diez']\n",
    "    return numeros_letras[int(numero)]\n",
    "\n",
    "semestre_en_letras = numero_a_letras(semestre)\n",
    "print(semestre_en_letras)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separación de datos usando Pandas\n",
      "(2287, 13) (2287, 1)\n"
     ]
    }
   ],
   "source": [
    "X = df.loc[:, ~df.columns.str.contains(f'RENDIMIENTO_{semestre_en_letras.upper()}')]\n",
    "Y = df.loc[:, df.columns.str.contains(f'RENDIMIENTO_{semestre_en_letras.upper()}')]                                                     \n",
    "print(\"Separación de datos usando Pandas\") \n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2287, 13) (2287,)\n"
     ]
    }
   ],
   "source": [
    "Y = LabelEncoder().fit_transform(Y.astype('str'))                \n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.408 -1.311 -1.7   -1.552 -1.526 -1.529 -0.918 -0.933 -1.141 -1.148\n",
      "  -0.949 -1.439 -0.777]\n",
      " [ 1.464  0.827  0.34   0.67   0.59   0.506  0.99   0.52   0.894  0.846\n",
      "   0.956  0.265  1.269]\n",
      " [ 0.405  0.698  0.458  0.52   0.799  0.905  0.964  1.117  1.023  0.799\n",
      "   0.971  0.526  1.311]\n",
      " [-0.695 -1.311  0.111  0.37   0.144  0.709 -0.918 -0.518 -1.141 -1.148\n",
      "  -0.949  0.609 -0.777]\n",
      " [ 1.184  0.827  0.34   0.52   0.95   0.709  1.08   0.825  0.822  0.954\n",
      "   1.112  0.568 -0.777]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROMEDIO_UNO</th>\n",
       "      <th>NOTA_EE_UNO</th>\n",
       "      <th>PROMEDIO_DOS</th>\n",
       "      <th>NOTA_ALGEBRA</th>\n",
       "      <th>NOTA_INTEGRAL</th>\n",
       "      <th>NOTA_MATERIALES</th>\n",
       "      <th>NOTA_EE_DOS</th>\n",
       "      <th>NAA_TRES</th>\n",
       "      <th>NOTA_MULTIVARIADO</th>\n",
       "      <th>NOTA_ESTADISTICA_UNO</th>\n",
       "      <th>NOTA_TERMODINAMICA</th>\n",
       "      <th>NOTA_TGS</th>\n",
       "      <th>NOTA_EE_TRES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.407894</td>\n",
       "      <td>-1.311423</td>\n",
       "      <td>-1.700437</td>\n",
       "      <td>-1.552472</td>\n",
       "      <td>-1.526473</td>\n",
       "      <td>-1.529305</td>\n",
       "      <td>-0.917952</td>\n",
       "      <td>-0.933482</td>\n",
       "      <td>-1.140782</td>\n",
       "      <td>-1.148031</td>\n",
       "      <td>-0.948981</td>\n",
       "      <td>-1.438778</td>\n",
       "      <td>-0.777211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.463626</td>\n",
       "      <td>0.827276</td>\n",
       "      <td>0.340223</td>\n",
       "      <td>0.669641</td>\n",
       "      <td>0.590328</td>\n",
       "      <td>0.506070</td>\n",
       "      <td>0.990410</td>\n",
       "      <td>0.520149</td>\n",
       "      <td>0.893745</td>\n",
       "      <td>0.845946</td>\n",
       "      <td>0.955762</td>\n",
       "      <td>0.265110</td>\n",
       "      <td>1.269232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PROMEDIO_UNO  NOTA_EE_UNO  PROMEDIO_DOS  NOTA_ALGEBRA  NOTA_INTEGRAL  \\\n",
       "0     -1.407894    -1.311423     -1.700437     -1.552472      -1.526473   \n",
       "1      1.463626     0.827276      0.340223      0.669641       0.590328   \n",
       "\n",
       "   NOTA_MATERIALES  NOTA_EE_DOS  NAA_TRES  NOTA_MULTIVARIADO  \\\n",
       "0        -1.529305    -0.917952 -0.933482          -1.140782   \n",
       "1         0.506070     0.990410  0.520149           0.893745   \n",
       "\n",
       "   NOTA_ESTADISTICA_UNO  NOTA_TERMODINAMICA  NOTA_TGS  NOTA_EE_TRES  \n",
       "0             -1.148031           -0.948981 -1.438778     -0.777211  \n",
       "1              0.845946            0.955762  0.265110      1.269232  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_T_JOHNSON1 = X.copy(deep=True)\n",
    "def transformacion_johnson(X):\n",
    "    transformador_johnson = PowerTransformer(method='yeo-johnson', standardize=True).fit(X)\n",
    "    datos_transformados = transformador_johnson.transform(X)\n",
    "    set_printoptions(precision=3)\n",
    "    print(datos_transformados[:5, :])\n",
    "    datos_transformados_df = pd.DataFrame(data=datos_transformados, columns=X.columns)\n",
    "    return datos_transformados_df\n",
    "Xpandas_T_JOHNSON1 = transformacion_johnson(X_T_JOHNSON1)\n",
    "Xpandas_T_JOHNSON1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATOS: Son 1600 datos para entrenamiento y 687 datos para prueba\n"
     ]
    }
   ],
   "source": [
    "X_trn, X_tst, Y_trn, Y_tst = train_test_split(Xpandas_T_JOHNSON1, Y, test_size=0.3, random_state=2)\n",
    "print('DATOS: Son {} datos para entrenamiento y {} datos para prueba'.format(X_trn.shape[0], X_tst.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNEIGHBORSCLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 80.81250000000001\n",
      "Mejor valor PARAMETRO usando k-fold: {'algorithm': 'auto', 'metric': 'manhattan', 'n_neighbors': 16, 'weights': 'uniform'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'metric': 'manhattan',\n",
       " 'n_neighbors': 16,\n",
       " 'weights': 'uniform'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def entrenar_modelo_knn_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {\n",
    "        'n_neighbors': [i for i in range(1, 18, 1)],\n",
    "        'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "        'algorithm': ['auto', 'kd_tree','ball_tree','brute'],\n",
    "        #'p': [i for i in range(1, 18,1)],\n",
    "        'weights': ['uniform']\n",
    "    }\n",
    "    modelo = KNeighborsClassifier()\n",
    "    semilla = 5\n",
    "    num_folds = 10\n",
    "    kfold = StratifiedKFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn_transformado, Y_trn)\n",
    "    mejores_hiperparametros_knn=grid_resultado.best_params_\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = KNeighborsClassifier(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo ,grid_resultado.best_params_\n",
    "modelo_knn, mejores_hiperparametros_knn = entrenar_modelo_knn_con_transformacion(X_trn, Y_trn)\n",
    "mejores_hiperparametros_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7962154294032023"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_knn.predict(X_tst)\n",
    "accuracy_knn = accuracy_score(Y_tst, Y_pred_prueba)\n",
    "accuracy_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 52.125\n",
      "Mejor valor PARAMETRO usando k-fold: {'C': 0.0011, 'gamma': 1.05, 'kernel': 'poly', 'max_iter': 1, 'random_state': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.0011,\n",
       " 'gamma': 1.05,\n",
       " 'kernel': 'poly',\n",
       " 'max_iter': 1,\n",
       " 'random_state': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def entrenar_modelo_svc_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = { 'kernel':   ['rbf', 'poly', 'sigmoid','linear'], \n",
    "                'C': [i/10000 for i in range(8,12,1)],\n",
    "                'max_iter':[i for i in range(1,3,1)],\n",
    "                'gamma' : [i/100 for i in range(80,110,5)],\n",
    "                'random_state':[i for i in range(1,5,1)],\n",
    "                }\n",
    "    modelo = SVC()\n",
    "    semilla=5\n",
    "    num_folds=10\n",
    "    kfold = StratifiedKFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    mejores_hiperparametros_svc=grid_resultado.best_params_\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = SVC(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo ,grid_resultado.best_params_\n",
    "modelo_svc,mejores_hiperparametros_svc = entrenar_modelo_svc_con_transformacion(X_trn, Y_trn)\n",
    "mejores_hiperparametros_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.537117903930131"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_svc.predict(X_tst)\n",
    "accuracy_svc = accuracy_score(Y_tst, Y_pred_prueba)\n",
    "accuracy_svc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 81.875\n",
      "Mejor valor PARAMETRO usando k-fold: {'max_depth': 6, 'max_features': 6, 'min_samples_leaf': 6, 'min_samples_split': 2, 'random_state': 2, 'splitter': 'random'}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_tree_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {          \n",
    "              'max_depth':[i for i in range(1,7,1)],\n",
    "              'min_samples_split' :  [i for i in range(1,7,1)],  \n",
    "              'min_samples_leaf' : [i for i in range(1,7,1)], \n",
    "              'max_features' : [i for i in range(1,7,1)], \n",
    "              'splitter': [\"best\", \"random\"],\n",
    "              'random_state': [i for i in range(1,5,1)],\n",
    "              #'criterion': ['gini','entropy','log_loss']\n",
    "            \n",
    "}\n",
    "    modelo = DecisionTreeClassifier()\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = StratifiedKFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    mejores_hiperparametros_tree=grid_resultado.best_params_\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = DecisionTreeClassifier(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo,grid_resultado.best_params_\n",
    "\n",
    "modelo_tree,mejores_hiperparametros_tree = entrenar_modelo_tree_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8020378457059679"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_tree.predict(X_tst)\n",
    "accuracy_tree = accuracy_score(Y_tst, Y_pred_prueba)\n",
    "accuracy_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 77.4375\n",
      "Mejor valor PARAMETRO usando k-fold: {}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_gaussian_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {}\n",
    "    modelo = GaussianNB()\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = StratifiedKFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = GaussianNB(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo\n",
    "modelo_gaussian = entrenar_modelo_gaussian_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7903930131004366"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_gaussian.predict(X_tst)\n",
    "accuracy_gaussian = accuracy_score(Y_tst, Y_pred_prueba)\n",
    "accuracy_gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 81.43749999999999\n",
      "Mejor valor PARAMETRO usando k-fold: {'n_components': 1, 'shrinkage': 'auto', 'solver': 'lsqr', 'tol': 0.001}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_LDA_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = { 'solver':  ['svd','lsqr','eigen'],\n",
    "            'n_components':[1,2,3,4,5,6,7,8,9,10],\n",
    "            'shrinkage': ['auto', 0.001, 0.01, 0.1, 0.5,1,10,100,1000],\n",
    "            'tol':[i/1000 for i in range(1,100,1)]}\n",
    "    modelo = LinearDiscriminantAnalysis()\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = StratifiedKFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    mejores_hiperparametros_LDA=grid_resultado.best_params_\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = LinearDiscriminantAnalysis(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo, grid_resultado.best_params_\n",
    "modelo_LDA,mejores_hiperparametros_LDA = entrenar_modelo_LDA_con_transformacion(X_trn, Y_trn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8049490538573508"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_LDA.predict(X_tst)\n",
    "accuracy_LDA = accuracy_score(Y_tst, Y_pred_prueba)\n",
    "accuracy_LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BAGGINGCLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 80.74999999999999\n",
      "Mejor valor PARAMETRO usando k-fold: {'bootstrap': True, 'bootstrap_features': True, 'max_features': 0.75, 'max_samples': 0.85, 'n_estimators': 750}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_BG_con_transformacion(X_trn, Y_trn,mejores_hiperparametros_tree):\n",
    "    # Aplicar la transformación Yeo-Johnson\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {'n_estimators': [i for i in range(750,760,5)],\n",
    "            'max_samples' : [i/100.0 for i in range(70,90,5)],\n",
    "            'max_features': [i/100.0 for i in range(75,85,5)],\n",
    "            'bootstrap': [True], \n",
    "            'bootstrap_features': [True]}\n",
    "    base_estimator= DecisionTreeClassifier(**mejores_hiperparametros_tree)\n",
    "    semilla=7\n",
    "    modelo = BaggingClassifier(estimator=base_estimator,n_estimators=750, random_state=semilla,\n",
    "                             bootstrap= True, bootstrap_features = True, max_features = 0.7,\n",
    "                             max_samples= 0.5)\n",
    "    num_folds=10\n",
    "    kfold = StratifiedKFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    mejores_hiperparametros_BG=grid_resultado.best_params_\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = BaggingClassifier(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo,grid_resultado.best_params_\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "modelo_BG,mejores_hiperparametros_BG = entrenar_modelo_BG_con_transformacion(X_trn, Y_trn,mejores_hiperparametros_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8209606986899564"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_BG.predict(X_tst)\n",
    "accuracy_BG = accuracy_score(Y_tst, Y_pred_prueba)\n",
    "accuracy_BG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 82.5625\n",
      "Mejor valor PARAMETRO usando k-fold: {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 3}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_random_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = { \n",
    "                'min_samples_split' : [1, 2 , 3,  4 , 6 , 8 , 10 , 15, 20 ],  \n",
    "                'min_samples_leaf' : [ 1 , 3 , 5 , 7 , 9, 12, 15 ],\n",
    "                'criterion':('gini','entropy','log_loss'),\n",
    "                #'max_features':('sqrt','log2',None)\n",
    "                #'class_weight':('balanced','balanced_subsample')\n",
    "              }\n",
    "    modelo = RandomForestClassifier()\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = StratifiedKFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    mejores_hiperparametros_random=grid_resultado.best_params_\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = RandomForestClassifier(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo,grid_resultado.best_params_\n",
    "\n",
    "modelo_random,mejores_hiperparametros_random = entrenar_modelo_random_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8195050946142649"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_random.predict(X_tst)\n",
    "accuracy_random = accuracy_score(Y_tst, Y_pred_prueba)\n",
    "accuracy_random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXTRA TREES CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 82.25\n",
      "Mejor valor PARAMETRO usando k-fold: {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 6}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_extra_con_transformacion(X_trn, Y_trn):\n",
    "    # Aplicar la transformación Yeo-Johnson\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {'min_samples_split' : [i for i in range(1,10,1)], \n",
    "                'min_samples_leaf' : [i for i in range(0,10,1)],\n",
    "                'min_samples_leaf':[i for i in range(0,10,1)],\n",
    "                'min_samples_split':[i for i in range(0,10,1)],\n",
    "                'criterion':('gini','entropy','log_loss')}\n",
    "    semilla=7            \n",
    "    modelo = ExtraTreesClassifier(random_state=semilla, \n",
    "                                n_estimators=40,\n",
    "                                bootstrap=True) \n",
    "    num_folds=10\n",
    "    kfold = StratifiedKFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    mejores_hiperparametros_extra=grid_resultado.best_params_\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = ExtraTreesClassifier(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo,grid_resultado.best_params_\n",
    "\n",
    "modelo_extra,mejores_hiperparametros_extra = entrenar_modelo_extra_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8180494905385735"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_extra.predict(X_tst)\n",
    "accuracy_extra = accuracy_score(Y_tst, Y_pred_prueba)\n",
    "accuracy_extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 80.12499999999999\n",
      "Mejor valor PARAMETRO usando k-fold: {'learning_rate': 0.0005, 'n_estimators': 1}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_ADA_con_transformacion(X_trn, Y_trn):\n",
    "    # Aplicar la transformación Yeo-Johnson\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {'learning_rate' : [i/10000.0 for i in range(5,20,5)],\n",
    "                  'n_estimators':[i for i in range(1,50,1)]}\n",
    "    semilla=7            \n",
    "    modelo = AdaBoostClassifier(estimator = None,  algorithm = 'SAMME.R', \n",
    "                                random_state= None) \n",
    "    num_folds=10\n",
    "    kfold = StratifiedKFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    mejores_hiperparametros_ADA=grid_resultado.best_params_\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = AdaBoostClassifier(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo,grid_resultado.best_params_\n",
    "modelo_ADA, mejores_hiperparametros_ADA= entrenar_modelo_ADA_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7976710334788938"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_ADA.predict(X_tst)\n",
    "accuracy_ADA = accuracy_score(Y_tst, Y_pred_prueba)\n",
    "accuracy_ADA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRADIENT BOOSTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 82.0625\n",
      "Mejor valor PARAMETRO usando k-fold: {'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'log_loss', 'n_estimators': 1100}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_GD_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = { \n",
    "                'learning_rate' : [0.01, 0.05, 0.1,0.15],\n",
    "                'n_estimators': [i for i in range(100,1200,100)],\n",
    "                'loss':('log_loss','exponential'),\n",
    "                'criterion':['friedman_mse']     \n",
    "              }\n",
    "    semilla=7\n",
    "    modelo = GradientBoostingClassifier(random_state=semilla,\n",
    "                                    n_estimators= 100,learning_rate= 0.1,max_depth= 2,\n",
    "                                    min_samples_split= 2, min_samples_leaf= 3,max_features= 2)\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = StratifiedKFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    mejores_hiperparametros_GD=grid_resultado.best_params_\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = GradientBoostingClassifier(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo,grid_resultado.best_params_\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_GD,mejores_hiperparametros_GD = entrenar_modelo_GD_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8107714701601164"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_GD.predict(X_tst)\n",
    "accuracy_GD = accuracy_score(Y_tst, Y_pred_prueba)\n",
    "accuracy_GD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 81.62499999999999\n",
      "Mejor valor PARAMETRO usando k-fold: {'colsample_bytree': 1, 'loss': 'log_loss', 'max_features': 'sqrt', 'n_estimators': 9, 'objective': 'binary:logistic', 'reg_alpha': 0, 'reg_lambda': 0.1}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_XB_con_transformacion(X_trn, Y_trn):\n",
    "    # Aplicar la transformación Yeo-Johnson\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {'reg_alpha': [0,0.1,0.2,0.3,0.4,0.5],\n",
    "                'reg_lambda':  [i/1000.0 for i in range(100,150,5)],\n",
    "                'n_estimators':  [i for i in range(1,10,2)],\n",
    "                'colsample_bytree': [0.1,0.3, 0.5,0.6,0.7,0.8, 0.9, 1,1.1],\n",
    "                'objective' : ('binary:logistic', 'Multi: softprob'),\n",
    "                'loss': ['log_loss'],\n",
    "                'max_features':('sqrt','log2')\n",
    "                }\n",
    "    semilla=7\n",
    "    modelo = XGBClassifier(random_state=semilla,subsample =1,max_depth =2)\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = StratifiedKFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    mejores_hiperparametros_XB=grid_resultado.best_params_\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = XGBClassifier(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo,grid_resultado.best_params_\n",
    "\n",
    "modelo_XB,mejores_hiperparametros_XB = entrenar_modelo_XB_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8195050946142649"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_XB.predict(X_tst)\n",
    "accuracy_XB = accuracy_score(Y_tst, Y_pred_prueba)\n",
    "accuracy_XB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CATBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 81.43749999999999\n",
      "Mejor valor PARAMETRO usando k-fold: {'border_count': 53, 'depth': 6, 'l2_leaf_reg': 42, 'learning_rate': 0.01, 'thread_count': 4}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_CB_con_transformacion(X_trn, Y_trn):\n",
    "    # Aplicar la transformación Yeo-Johnson\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {'border_count':[53],'l2_leaf_reg': [42],'learning_rate': [0.01],\n",
    "                  'depth': [4, 6, 8],'thread_count': [4, 8, 12]\n",
    "                  } \n",
    "    semilla=7\n",
    "    modelo = CatBoostClassifier(random_state=semilla, verbose =0)\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = StratifiedKFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    mejores_hiperparametros_CB=grid_resultado.best_params_\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = CatBoostClassifier(verbose=0,**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo,grid_resultado.best_params_\n",
    "\n",
    "modelo_CB,mejores_hiperparametros_CB = entrenar_modelo_CB_con_transformacion(X_trn, Y_trn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8136826783114993"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_CB.predict(X_tst)\n",
    "accuracy_CB = accuracy_score(Y_tst, Y_pred_prueba)\n",
    "accuracy_CB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIGHT GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 462\n",
      "[LightGBM] [Info] Number of data points in the train set: 1600, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score -0.990880\n",
      "[LightGBM] [Info] Start training from score -2.224467\n",
      "[LightGBM] [Info] Start training from score -0.772461\n",
      "[LightGBM] [Info] Start training from score -2.900422\n",
      "[LightGBM] [Info] Start training from score -5.585999\n",
      "Resultados de GridSearchCV para el modelo\n",
      "Mejor valor EXACTITUD usando k-fold: 82.31249999999999\n",
      "Mejor valor PARAMETRO usando k-fold: {'boosting_type': 'gbdt', 'colsample_bytree': 1.0, 'min_child_samples': 500, 'objective': 'multiclass', 'random_state': 42}\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_LIGHT_con_transformacion(X_trn, Y_trn):\n",
    "    # Aplicar la transformación Yeo-Johnson\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {\n",
    "    'min_child_samples' : [i for i in range(200, 10000, 100)],'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'boosting_type': ['gbdt', 'dart', 'goss'],'objective': ['binary', 'multiclass'],'random_state': [42]}\n",
    "    semilla=7\n",
    "    modelo = LGBMClassifier (random_state=semilla,                           \n",
    "                            num_leaves =  10,max_depth = 1, n_estimators = 100,    \n",
    "                            learning_rate = 0.1 ,class_weight=  None, subsample = 1,\n",
    "                            colsample_bytree= 1, reg_alpha=  0, reg_lambda = 0,\n",
    "                            min_split_gain = 0, boosting_type = 'gbdt')\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = StratifiedKFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'accuracy'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    mejores_hiperparametros_LIGHT=grid_resultado.best_params_\n",
    "    print(\"Resultados de GridSearchCV para el modelo\")\n",
    "    print(\"Mejor valor EXACTITUD usando k-fold:\", grid_resultado.best_score_*100)\n",
    "    print(\"Mejor valor PARAMETRO usando k-fold:\", grid_resultado.best_params_)\n",
    "    mejor_modelo = LGBMClassifier(verbose=-1,**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo,grid_resultado.best_params_\n",
    "\n",
    "modelo_LIGHT,mejores_hiperparametros_LIGHT = entrenar_modelo_LIGHT_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8064046579330422"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_LIGHT.predict(X_tst)\n",
    "accuracy_LIGHT = accuracy_score(Y_tst, Y_pred_prueba)\n",
    "accuracy_LIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'multi:softprob',\n",
       " 'base_score': None,\n",
       " 'booster': None,\n",
       " 'callbacks': None,\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'colsample_bytree': 1,\n",
       " 'device': None,\n",
       " 'early_stopping_rounds': None,\n",
       " 'enable_categorical': False,\n",
       " 'eval_metric': None,\n",
       " 'feature_types': None,\n",
       " 'gamma': None,\n",
       " 'grow_policy': None,\n",
       " 'importance_type': None,\n",
       " 'interaction_constraints': None,\n",
       " 'learning_rate': None,\n",
       " 'max_bin': None,\n",
       " 'max_cat_threshold': None,\n",
       " 'max_cat_to_onehot': None,\n",
       " 'max_delta_step': None,\n",
       " 'max_depth': None,\n",
       " 'max_leaves': None,\n",
       " 'min_child_weight': None,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': None,\n",
       " 'multi_strategy': None,\n",
       " 'n_estimators': 9,\n",
       " 'n_jobs': None,\n",
       " 'num_parallel_tree': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': 0,\n",
       " 'reg_lambda': 0.1,\n",
       " 'sampling_method': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': None,\n",
       " 'tree_method': None,\n",
       " 'validate_parameters': None,\n",
       " 'verbosity': None,\n",
       " 'loss': 'log_loss',\n",
       " 'max_features': 'sqrt'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mejores_hiperparametros_knn = modelo_knn.get_params()\n",
    "mejores_hiperparametros_knn\n",
    "\n",
    "mejores_hiperparametros_GD = modelo_GD.get_params()\n",
    "mejores_hiperparametros_GD\n",
    "\n",
    "mejores_hiperparametros_tree = modelo_tree.get_params()\n",
    "mejores_hiperparametros_tree\n",
    "\n",
    "mejores_hiperparametros_ADA = modelo_ADA.get_params()\n",
    "mejores_hiperparametros_ADA\n",
    "\n",
    "mejores_hiperparametros_extra = modelo_extra.get_params()\n",
    "mejores_hiperparametros_extra\n",
    "\n",
    "mejores_hiperparametros_random = modelo_random.get_params()\n",
    "mejores_hiperparametros_random\n",
    "\n",
    "mejores_hiperparametros_BG = modelo_BG.get_params()\n",
    "mejores_hiperparametros_BG\n",
    "\n",
    "mejores_hiperparametros_XB = modelo_XB.get_params()\n",
    "mejores_hiperparametros_XB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VOTACION DURA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento del modelo:\n",
      "Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold: 82.25  % \n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_voting_hard_con_transformacion(X_trn, Y_trn,\n",
    "                                                   mejores_hiperparametros_GD,\n",
    "                                                   mejores_hiperparametros_tree,\n",
    "                                                   mejores_hiperparametros_ADA,\n",
    "                                                   mejores_hiperparametros_extra,\n",
    "                                                   mejores_hiperparametros_random,\n",
    "                                                   mejores_hiperparametros_BG,\n",
    "                                                   mejores_hiperparametros_XB):\n",
    "    X_trn_transformado = X_trn\n",
    "    semilla= 7 \n",
    "    kfold = StratifiedKFold(n_splits=10, random_state=semilla, shuffle=True)\n",
    "    modelo1 = GradientBoostingClassifier(**mejores_hiperparametros_GD)\n",
    "    base_estimator=DecisionTreeClassifier(**mejores_hiperparametros_tree)\n",
    "    modelo2 = AdaBoostClassifier(**mejores_hiperparametros_ADA)\n",
    "    modelo3 = ExtraTreesClassifier(**mejores_hiperparametros_extra)\n",
    "    modelo4 = RandomForestClassifier (**mejores_hiperparametros_random)\n",
    "    model = DecisionTreeClassifier(**mejores_hiperparametros_tree)\n",
    "    modelo5 = BaggingClassifier(**mejores_hiperparametros_BG)\n",
    "    modelo6 = DecisionTreeClassifier(**mejores_hiperparametros_tree)\n",
    "    modelo7 = XGBClassifier(**mejores_hiperparametros_XB)\n",
    "    metrica = 'accuracy'\n",
    "    mejor_modelo = VotingClassifier(\n",
    "    estimators=[('Gradient', modelo1), ('Adaboost', modelo2), \n",
    "                                    ('Extratrees', modelo3),('Random Forest',modelo4),\n",
    "                                    ('Bagging',modelo5),('Decision tree',modelo6),\n",
    "                                    ('XGB',modelo7)],voting='hard') \n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    resultados = cross_val_score(mejor_modelo, X_trn_transformado, Y_trn, \n",
    "                                    cv=kfold,scoring = metrica)\n",
    "    mejores_hiperparametros_voting_hard=mejor_modelo.get_params\n",
    "    print(\"Rendimiento del modelo:\") \n",
    "    print (\"Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold:\", resultados.mean()*100,\" % \") \n",
    "    return mejor_modelo, mejores_hiperparametros_voting_hard\n",
    "modelo_voting_hard, mejores_hiperparametros_voting_hard= entrenar_modelo_voting_hard_con_transformacion(X_trn, Y_trn,\n",
    "                                                   mejores_hiperparametros_GD,\n",
    "                                                   mejores_hiperparametros_tree,\n",
    "                                                   mejores_hiperparametros_ADA,\n",
    "                                                   mejores_hiperparametros_extra,\n",
    "                                                   mejores_hiperparametros_random,\n",
    "                                                   mejores_hiperparametros_BG,\n",
    "                                                   mejores_hiperparametros_XB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8136826783114993"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_voting_hard.predict(X_tst)\n",
    "accuracy_voting_hard = accuracy_score(Y_tst, Y_pred_prueba)\n",
    "accuracy_voting_hard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VOTACION SUAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento del modelo:\n",
      "Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold: 82.25  % \n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_voting_soft_con_transformacion(X_trn, Y_trn,\n",
    "                                                   mejores_hiperparametros_GD,\n",
    "                                                   mejores_hiperparametros_tree,\n",
    "                                                   mejores_hiperparametros_ADA,\n",
    "                                                   mejores_hiperparametros_extra,\n",
    "                                                   mejores_hiperparametros_random,\n",
    "                                                   mejores_hiperparametros_BG):\n",
    "    X_trn_transformado = X_trn\n",
    "    semilla= 7 \n",
    "    kfold = StratifiedKFold(n_splits=10, random_state=semilla, shuffle=True)\n",
    "    modelo1 = GradientBoostingClassifier(**mejores_hiperparametros_GD)\n",
    "    base_estimator=DecisionTreeClassifier(**mejores_hiperparametros_tree)\n",
    "    modelo2 = AdaBoostClassifier(**mejores_hiperparametros_ADA)\n",
    "    modelo3 = ExtraTreesClassifier(**mejores_hiperparametros_extra)\n",
    "    modelo4 = RandomForestClassifier (**mejores_hiperparametros_random)\n",
    "    model = DecisionTreeClassifier(**mejores_hiperparametros_tree)\n",
    "    modelo5 = BaggingClassifier(**mejores_hiperparametros_BG)\n",
    "    modelo6 = DecisionTreeClassifier(**mejores_hiperparametros_tree)\n",
    "    metrica = 'accuracy'\n",
    "    mejor_modelo = VotingClassifier(\n",
    "    estimators=[('Gradient', modelo1), ('Adaboost', modelo2), ('Extratrees', modelo3),\n",
    "                                    ('Random Forest',modelo4),\n",
    "                                    ('Bagging',modelo5),('Decision tree',modelo6)],\n",
    "    voting='soft',weights=[0.9,0.7,0.9,0.9,0.9,0.9]) \n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    mejores_hiperparametros_voting_soft=mejor_modelo.get_params\n",
    "    resultados = cross_val_score(mejor_modelo, X_trn_transformado, Y_trn, cv=kfold,scoring = metrica)\n",
    "    print(\"Rendimiento del modelo:\") \n",
    "    print (\"Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold:\", resultados.mean()*100,\" % \") \n",
    "    return mejor_modelo,mejores_hiperparametros_voting_soft\n",
    "\n",
    "# Entrenar el modelo KNN con transformación Yeo-Johnson\n",
    "modelo_voting_soft,mejores_hiperparametros_voting_soft = entrenar_modelo_voting_soft_con_transformacion(X_trn, Y_trn,\n",
    "                                                   mejores_hiperparametros_GD,\n",
    "                                                   mejores_hiperparametros_tree,\n",
    "                                                   mejores_hiperparametros_ADA,\n",
    "                                                   mejores_hiperparametros_extra,\n",
    "                                                   mejores_hiperparametros_random,\n",
    "                                                   mejores_hiperparametros_BG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8151382823871907"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_voting_soft.predict(X_tst)\n",
    "accuracy_voting_soft = accuracy_score(Y_tst, Y_pred_prueba)\n",
    "accuracy_voting_soft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STACKING ( METAMODELO LINEAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento del modelo:\n",
      "Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold: 81.74999999999999  % \n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_stacking_lineal_con_transformacion(X_trn, Y_trn,\n",
    "                                                   mejores_hiperparametros_tree,\n",
    "                                                   mejores_hiperparametros_ADA,\n",
    "                                                   mejores_hiperparametros_extra,\n",
    "                                                   mejores_hiperparametros_random,\n",
    "                                                   mejores_hiperparametros_BG):\n",
    "    X_trn_transformado = X_trn\n",
    "    semilla= 7 \n",
    "    kfold = StratifiedKFold(n_splits=10, random_state=semilla, shuffle=True)\n",
    "    base_estimator=DecisionTreeClassifier(**mejores_hiperparametros_tree)\n",
    "    modelo2 = AdaBoostClassifier(**mejores_hiperparametros_ADA)\n",
    "    modelo3 = ExtraTreesClassifier(**mejores_hiperparametros_extra)\n",
    "    modelo4 = RandomForestClassifier (**mejores_hiperparametros_random)\n",
    "    model = DecisionTreeClassifier(**mejores_hiperparametros_tree)\n",
    "    modelo5 = BaggingClassifier(**mejores_hiperparametros_BG)\n",
    "    modelo6 = DecisionTreeClassifier(**mejores_hiperparametros_tree)\n",
    "    estimador_final = LogisticRegression()\n",
    "    metrica = 'accuracy'\n",
    "    mejor_modelo = StackingClassifier(\n",
    "    estimators=[ ('Adaboost', modelo2), ('Extratrees', modelo3),('Random Forest',modelo4),\n",
    "                                    ('Bagging',modelo5),('Decision tree',modelo6)], \n",
    "                                    final_estimator=estimador_final) \n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    mejores_hiperparametros_stacking_lineal=mejor_modelo.get_params\n",
    "    resultados = cross_val_score(mejor_modelo, X_trn_transformado, Y_trn, cv=kfold,scoring = metrica)\n",
    "    print(\"Rendimiento del modelo:\") \n",
    "    print (\"Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold:\", resultados.mean()*100,\" % \") \n",
    "    return mejor_modelo,mejores_hiperparametros_stacking_lineal\n",
    "\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "\n",
    "modelo_stacking_lineal,mejores_hiperparametros_stacking_lineal = entrenar_modelo_stacking_lineal_con_transformacion(X_trn, Y_trn,\n",
    "                                                   mejores_hiperparametros_tree,\n",
    "                                                   mejores_hiperparametros_ADA,\n",
    "                                                   mejores_hiperparametros_extra,\n",
    "                                                   mejores_hiperparametros_random,\n",
    "                                                   mejores_hiperparametros_BG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8209606986899564"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_stacking_lineal.predict(X_tst)\n",
    "accuracy_stacking_lineal = accuracy_score(Y_tst, Y_pred_prueba)\n",
    "accuracy_stacking_lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STACKING (METAMODELO NO LINEAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento del modelo:\n",
      "Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold: 81.5625  % \n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_stacking_nolineal_con_transformacion(X_trn, Y_trn,\n",
    "                                                   mejores_hiperparametros_tree,\n",
    "                                                   mejores_hiperparametros_extra,\n",
    "                                                   mejores_hiperparametros_random,\n",
    "                                                   mejores_hiperparametros_BG):\n",
    "    X_trn_transformado = X_trn\n",
    "    semilla= 7 \n",
    "    kfold = StratifiedKFold(n_splits=10, random_state=semilla, shuffle=True)\n",
    "    modelo1 = ExtraTreesClassifier(**mejores_hiperparametros_extra)\n",
    "    modelo2 = RandomForestClassifier (**mejores_hiperparametros_random)\n",
    "    model = DecisionTreeClassifier(**mejores_hiperparametros_tree)\n",
    "    modelo3 = BaggingClassifier(**mejores_hiperparametros_BG)\n",
    "    modelo4 = DecisionTreeClassifier(**mejores_hiperparametros_tree)\n",
    "    estimador_final = ExtraTreesClassifier(**mejores_hiperparametros_extra)\n",
    "    metrica = 'accuracy'\n",
    "    mejor_modelo = StackingClassifier(\n",
    "    estimators=[  ('Extratrees', modelo1),('Random Forest',modelo2),('Bagging',modelo3),\n",
    "                                    ('Decision tree',modelo4)], \n",
    "                                    final_estimator=estimador_final) \n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    mejores_hiperparametros_stacking_nolineal=mejor_modelo.get_params\n",
    "    resultados = cross_val_score(mejor_modelo, X_trn_transformado, Y_trn, cv=kfold,scoring = metrica)\n",
    "    print(\"Rendimiento del modelo:\") \n",
    "    print (\"Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold:\", resultados.mean()*100,\" % \") \n",
    "    return mejor_modelo,mejores_hiperparametros_stacking_nolineal\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "modelo_stacking_nolineal,mejores_hiperparametros_stacking_nolineal = entrenar_modelo_stacking_nolineal_con_transformacion(X_trn, Y_trn,\n",
    "                                                   mejores_hiperparametros_tree,\n",
    "                                                   mejores_hiperparametros_extra,\n",
    "                                                   mejores_hiperparametros_random,\n",
    "                                                   mejores_hiperparametros_BG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8282387190684134"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_stacking_nolineal.predict(X_tst)\n",
    "accuracy_stacking_nolineal = accuracy_score(Y_tst, Y_pred_prueba)\n",
    "accuracy_stacking_nolineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VOTING WEIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier, RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def weighted_voting_ensemble(X_trn, Y_trn, mejores_hiperparametros_GD,\n",
    "                            mejores_hiperparametros_tree,mejores_hiperparametros_ADA,\n",
    "                            mejores_hiperparametros_extra,mejores_hiperparametros_random,\n",
    "                            mejores_hiperparametros_BG,mejores_hiperparametros_XB):\n",
    "    X_trn_transformado = X_trn\n",
    "    modelos = [\n",
    "        GradientBoostingClassifier(**mejores_hiperparametros_GD),\n",
    "        AdaBoostClassifier(**mejores_hiperparametros_ADA),\n",
    "        ExtraTreesClassifier(**mejores_hiperparametros_extra),\n",
    "        RandomForestClassifier(**mejores_hiperparametros_random),\n",
    "        BaggingClassifier(**mejores_hiperparametros_BG),\n",
    "        DecisionTreeClassifier(**mejores_hiperparametros_tree),\n",
    "        XGBClassifier(**mejores_hiperparametros_XB)\n",
    "    ]\n",
    "    pesos = np.ones(len(modelos))\n",
    "    precisión_modelos = []\n",
    "    for modelo in modelos:\n",
    "        modelo.fit(X_trn_transformado, Y_trn)\n",
    "        precisión = np.mean(cross_val_score(modelo, X_trn_transformado, Y_trn, cv=KFold(n_splits=10, random_state=7, shuffle=True), scoring='accuracy'))\n",
    "        precisión_modelos.append(precisión)\n",
    "    suma_precisión = sum(precisión_modelos)\n",
    "    for i in range(len(precisión_modelos)):\n",
    "        pesos[i] = suma_precisión / (precisión_modelos[i] * len(modelos))\n",
    "\n",
    "    return modelos, pesos\n",
    "\n",
    "def weighted_voting_predict(modelos, pesos, X_test):\n",
    "    predicciones_modelos = [modelo.predict(X_test) for modelo in modelos]\n",
    "    pesos_float64 = np.array(pesos, dtype=np.float64)\n",
    "    predicciones_ponderadas = np.zeros_like(predicciones_modelos[0], dtype=np.float64)\n",
    "    for i, predicciones_modelo in enumerate(predicciones_modelos):\n",
    "        predicciones_ponderadas += predicciones_modelo * pesos_float64[i]\n",
    "    predicciones_ponderadas /= len(modelos)\n",
    "    predicciones_ponderadas = np.round(predicciones_ponderadas).astype(int)\n",
    "    \n",
    "    return predicciones_ponderadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8136826783114993"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelos, pesos = weighted_voting_ensemble(X_trn, Y_trn, mejores_hiperparametros_GD,\n",
    "                            mejores_hiperparametros_tree,mejores_hiperparametros_ADA,\n",
    "                            mejores_hiperparametros_extra,mejores_hiperparametros_random,\n",
    "                            mejores_hiperparametros_BG,mejores_hiperparametros_XB)\n",
    "Y_pred_prueba= weighted_voting_predict(modelos, pesos, X_tst)\n",
    "accuracy_voting_weighted = accuracy_score(Y_tst, Y_pred_prueba)\n",
    "accuracy_voting_weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUPER APRENDIZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             done | 00:00:01\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:02\n",
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             done | 00:00:01\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:02\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             done | 00:00:01\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:02\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             done | 00:00:02\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:02\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             done | 00:00:04\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:05\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             done | 00:00:03\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:04\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             done | 00:00:03\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:03\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             done | 00:00:02\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:03\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             done | 00:00:03\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:03\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             done | 00:00:02\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:03\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             done | 00:00:02\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:03\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "Rendimiento del modelo:\n",
      "Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold: 81.875 %\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_super_aprendiz(X_trn, Y_trn, \n",
    "                            mejores_hiperparametros_tree,mejores_hiperparametros_extra,\n",
    "                            mejores_hiperparametros_random):\n",
    "    X_trn_transformado = X_trn\n",
    "    semilla = 7 \n",
    "    kfold = StratifiedKFold(n_splits=10, random_state=semilla, shuffle=True)\n",
    "    modelo1 = ExtraTreesClassifier(**mejores_hiperparametros_extra)\n",
    "    modelo2 = RandomForestClassifier(**mejores_hiperparametros_random)\n",
    "    model = DecisionTreeClassifier(**mejores_hiperparametros_tree)\n",
    "    modelo4 = DecisionTreeClassifier(**mejores_hiperparametros_tree)\n",
    "    estimadores = [('Extratrees', modelo1), ('Random Forest', modelo2),('DecisionTree',modelo4)\n",
    "                ]\n",
    "    super_learner = SuperLearner(folds=10, random_state=semilla, verbose=2)\n",
    "    super_learner.add(estimadores)\n",
    "    estimador_final = ExtraTreesClassifier(n_estimators=100, max_features=None,\n",
    "                                        bootstrap=False, max_depth=11, min_samples_split=4, \n",
    "                                        min_samples_leaf=1)\n",
    "    super_learner.add_meta(estimador_final)\n",
    "    super_learner.fit(X_trn_transformado, Y_trn)\n",
    "    mejores_hiperparametros_super_learner=super_learner.get_params\n",
    "    resultados = cross_val_score(super_learner, X_trn_transformado, Y_trn, cv=kfold, scoring='accuracy')\n",
    "    print(\"Rendimiento del modelo:\") \n",
    "    print(\"Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold:\", resultados.mean() * 100, \"%\") \n",
    "    return super_learner,mejores_hiperparametros_super_learner,estimadores\n",
    "modelo_superaprendiz,mejores_hiperparametros_super_learner,estimadores = entrenar_modelo_super_aprendiz(X_trn, Y_trn,\n",
    "                            mejores_hiperparametros_tree,mejores_hiperparametros_extra,\n",
    "                            mejores_hiperparametros_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8122270742358079"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_superaprendiz.predict(X_tst)\n",
    "accuracy_superaprendiz = accuracy_score(Y_tst, Y_pred_prueba)\n",
    "accuracy_superaprendiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUPER APRENDIZ DOS CAPAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting 3 layers\n",
      "Processing layer-1             done | 00:00:01\n",
      "Processing layer-2             done | 00:00:01\n",
      "Processing layer-3             done | 00:00:00\n",
      "Fit complete                        | 00:00:04\n",
      "\n",
      "Fitting 3 layers\n",
      "Processing layer-1             done | 00:00:01\n",
      "Processing layer-2             done | 00:00:01\n",
      "Processing layer-3             done | 00:00:00\n",
      "Fit complete                        | 00:00:03\n",
      "\n",
      "Predicting 3 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Processing layer-3             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 3 layers\n",
      "Processing layer-1             done | 00:00:01\n",
      "Processing layer-2             done | 00:00:01\n",
      "Processing layer-3             done | 00:00:00\n",
      "Fit complete                        | 00:00:04\n",
      "\n",
      "Predicting 3 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Processing layer-3             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 3 layers\n",
      "Processing layer-1             done | 00:00:03\n",
      "Processing layer-2             done | 00:00:02\n",
      "Processing layer-3             done | 00:00:00\n",
      "Fit complete                        | 00:00:06\n",
      "\n",
      "Predicting 3 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Processing layer-3             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 3 layers\n",
      "Processing layer-1             done | 00:00:02\n",
      "Processing layer-2             done | 00:00:02\n",
      "Processing layer-3             done | 00:00:00\n",
      "Fit complete                        | 00:00:05\n",
      "\n",
      "Predicting 3 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Processing layer-3             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 3 layers\n",
      "Processing layer-1             done | 00:00:02\n",
      "Processing layer-2             done | 00:00:02\n",
      "Processing layer-3             done | 00:00:00\n",
      "Fit complete                        | 00:00:05\n",
      "\n",
      "Predicting 3 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Processing layer-3             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 3 layers\n",
      "Processing layer-1             done | 00:00:02\n",
      "Processing layer-2             done | 00:00:02\n",
      "Processing layer-3             done | 00:00:00\n",
      "Fit complete                        | 00:00:05\n",
      "\n",
      "Predicting 3 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Processing layer-3             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 3 layers\n",
      "Processing layer-1             done | 00:00:02\n",
      "Processing layer-2             done | 00:00:02\n",
      "Processing layer-3             done | 00:00:00\n",
      "Fit complete                        | 00:00:05\n",
      "\n",
      "Predicting 3 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Processing layer-3             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 3 layers\n",
      "Processing layer-1             done | 00:00:02\n",
      "Processing layer-2             done | 00:00:02\n",
      "Processing layer-3             done | 00:00:00\n",
      "Fit complete                        | 00:00:05\n",
      "\n",
      "Predicting 3 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Processing layer-3             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 3 layers\n",
      "Processing layer-1             done | 00:00:03\n",
      "Processing layer-2             done | 00:00:02\n",
      "Processing layer-3             done | 00:00:00\n",
      "Fit complete                        | 00:00:06\n",
      "\n",
      "Predicting 3 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Processing layer-3             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 3 layers\n",
      "Processing layer-1             done | 00:00:03\n",
      "Processing layer-2             done | 00:00:02\n",
      "Processing layer-3             done | 00:00:00\n",
      "Fit complete                        | 00:00:06\n",
      "\n",
      "Predicting 3 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Processing layer-3             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "Rendimiento del modelo:\n",
      "Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold: 81.81249999999999 %\n"
     ]
    }
   ],
   "source": [
    "Y_trn = Y_trn.astype(int)\n",
    "def entrenar_modelo_super_aprendiz_dos_capas(X_trn, Y_trn, mejores_hiperparametros_tree,\n",
    "                                            mejores_hiperparametros_extra,mejores_hiperparametros_random\n",
    "                                            ):\n",
    "    X_trn_transformado = X_trn\n",
    "    semilla = 7 \n",
    "    kfold = StratifiedKFold(n_splits=10, random_state=semilla, shuffle=True)\n",
    "    modelo1 = ExtraTreesClassifier(**mejores_hiperparametros_extra)\n",
    "    modelo2 = RandomForestClassifier(**mejores_hiperparametros_random)\n",
    "    model = DecisionTreeClassifier(**mejores_hiperparametros_tree)\n",
    "    estimadores = [('Extratrees', modelo1), ('Random Forest', modelo2)\n",
    "                 ]\n",
    "    superaprendiz_dos_capas = SuperLearner(folds=10, random_state=semilla, verbose=2)\n",
    "    superaprendiz_dos_capas.add(estimadores)\n",
    "    superaprendiz_dos_capas.add(estimadores)\n",
    "    estimador_final = ExtraTreesClassifier(n_estimators=100, max_features=None,\n",
    "                                        bootstrap=False, max_depth=11, min_samples_split=4, \n",
    "                                        min_samples_leaf=1)\n",
    "    superaprendiz_dos_capas.add_meta(estimador_final)\n",
    "    \n",
    "    superaprendiz_dos_capas.fit(X_trn_transformado, Y_trn)\n",
    "    mejores_hiperparametros_superaprendiz_dos_capas=superaprendiz_dos_capas.get_params\n",
    "    resultados = cross_val_score(superaprendiz_dos_capas, X_trn_transformado, Y_trn, cv=kfold, scoring='accuracy')\n",
    "    print(\"Rendimiento del modelo:\") \n",
    "    print(\"Promedio de Exactitud (DATOS ENTRENAMIENTO) usando k-fold:\", resultados.mean() * 100, \"%\") \n",
    "    return superaprendiz_dos_capas,mejores_hiperparametros_superaprendiz_dos_capas,estimadores\n",
    "modelo_superaprendiz_dos_capas,mejores_hiperparametros_superaprendiz_dos_capas,estimadores = entrenar_modelo_super_aprendiz_dos_capas(X_trn, Y_trn, mejores_hiperparametros_tree,\n",
    "                                            mejores_hiperparametros_extra,mejores_hiperparametros_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting 3 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Processing layer-3             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8136826783114993"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_superaprendiz_dos_capas.predict(X_tst)\n",
    "accuracy_superaprendiz_dos_capas = accuracy_score(Y_tst, Y_pred_prueba)\n",
    "accuracy_superaprendiz_dos_capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RED NEURONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 1.1126\n",
      "Epoch [20/100], Loss: 0.7597\n",
      "Epoch [30/100], Loss: 0.6702\n",
      "Epoch [40/100], Loss: 0.6291\n",
      "Epoch [50/100], Loss: 0.6114\n",
      "Epoch [60/100], Loss: 0.5959\n",
      "Epoch [70/100], Loss: 0.5841\n",
      "Epoch [80/100], Loss: 0.5742\n",
      "Epoch [90/100], Loss: 0.5657\n",
      "Epoch [100/100], Loss: 0.5582\n",
      "Accuracy: 80.20%\n",
      "Precisión:  0.7195437620559635\n",
      "Exhaustividad (Recall):  0.8020378457059679\n",
      "Puntuación F1:  0.74558032665812\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "np.random.seed(42)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "def train_neural_network(X_train, y_train, input_size, hidden_size, num_classes, num_epochs=100, learning_rate=0.0015):\n",
    "    # Convertir datos de entrenamiento a tensores de PyTorch\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "    \n",
    "    # Inicializar modelo y función de pérdida\n",
    "    model = NeuralNetwork(input_size, hidden_size, num_classes)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Entrenamiento del modelo\n",
    "    for epoch in range(num_epochs):\n",
    "        # Forward pass y pérdida\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        \n",
    "        # Backward pass y optimización\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "\n",
    "    return model,num_epochs,learning_rate\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    # Convertir datos de prueba a tensores de PyTorch\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "    # Obtener las predicciones del modelo\n",
    "    outputs = model(X_test_tensor)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # Calcular las métricas del modelo\n",
    "    accuracy = accuracy_score(y_test_tensor.numpy(), predicted.numpy())\n",
    "    precision = precision_score(y_test, predicted.numpy(), average='weighted')\n",
    "    recall = recall_score(y_test, predicted.numpy(), average='weighted')\n",
    "    f1 = f1_score(y_test, predicted.numpy(), average='weighted')\n",
    "\n",
    "    print('Accuracy: {:.2f}%'.format(accuracy * 100))\n",
    "    print(\"Precisión: \", precision)\n",
    "    print(\"Exhaustividad (Recall): \", recall)\n",
    "    print(\"Puntuación F1: \", f1)\n",
    "\n",
    "X_train_array = X_trn.values\n",
    "X_test_array = X_tst.values\n",
    "Y_trn = Y_trn \n",
    "input_size = X_trn.shape[1]\n",
    "num_classes = 5\n",
    "hidden_size =155\n",
    "\n",
    "# Supongamos que X_train, y_train, X_test, y_test son tus datos de entrenamiento y prueba\n",
    "modelo_red_reuronal,num_epochs,learning_rate = train_neural_network(X_train_array , Y_trn, input_size, hidden_size, num_classes)\n",
    "evaluate_model(modelo_red_reuronal, X_test_array , Y_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8020378457059679"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tensor = torch.tensor(X_test_array, dtype=torch.float32)\n",
    "outputs = modelo_red_reuronal(X_test_tensor)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "Y_pred_prueba = predicted.numpy()\n",
    "accuracy_red_neuronal = accuracy_score(Y_tst, Y_pred_prueba)\n",
    "accuracy_red_neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMPARACIÓN DE MÉTRICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo: STACKING NO LINEAL\n",
      "R^2 en prueba: 0.8282387190684134\n"
     ]
    }
   ],
   "source": [
    "exactitudes = {\n",
    "    'KNEIGHBORSCLASSIFIER': accuracy_knn,\n",
    "    'SVC': accuracy_svc,\n",
    "    'DECISION TREE': accuracy_tree,\n",
    "    'NAIVE BAYES':accuracy_gaussian,\n",
    "    'LDA':accuracy_LDA,\n",
    "    'BAGGING':accuracy_BG,\n",
    "    'RANDOM FOREST':accuracy_random,\n",
    "    'EXTRATREES':accuracy_extra,\n",
    "    'ADABOOST':accuracy_ADA,\n",
    "    'GRADIENTBOOST': accuracy_GD,\n",
    "    'XGBOOST':accuracy_XB,\n",
    "    'CATBOOST':accuracy_CB,\n",
    "    'LIGHT':accuracy_LIGHT,\n",
    "    'VOTING HARD':accuracy_voting_hard,\n",
    "    'VOTING SOFT':accuracy_voting_soft,\n",
    "    'STACKING LINEAL':accuracy_stacking_lineal,\n",
    "    'STACKING NO LINEAL':accuracy_stacking_nolineal,\n",
    "    'VOTING WEIGHTED':accuracy_voting_weighted,\n",
    "    'SUPER APRENDIZ':accuracy_superaprendiz,\n",
    "    'SUPER APRENDIZ DOS CAPAS':accuracy_superaprendiz_dos_capas,\n",
    "    #'RED NEURONAL':accuracy_red_neuronal\n",
    "}\n",
    "best_model = max(exactitudes, key=exactitudes.get)\n",
    "best_accuracy = exactitudes[best_model]\n",
    "\n",
    "print(\"Mejor modelo:\", best_model)\n",
    "print(\"R^2 en prueba:\", best_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
