{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MLENS] backend: threading\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI, Request\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "import pickle \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from numpy import set_printoptions\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "pd.options.display.max_columns=None\n",
    "import seaborn as sns \n",
    "from pandas import read_csv\n",
    "import io\n",
    "import base64\n",
    "import json\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.drawing.image import Image as XLImage\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "from unidecode import unidecode\n",
    "\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from mlens.ensemble import SuperLearner\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics import mean_squared_log_error, median_absolute_error\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C, WhiteKernel\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CARGUE DE DATOS Y CONEXIÓN A DRIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please visit this URL to authorize this application: https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=899973764197-biu188dkvsgi2al0fh29udm7keak0lh0.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A55265%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.readonly&state=xZfg34fiYc5j2brEGhjb763vh9hPML&access_type=offline\n",
      "Descargando Limpieza de datos 1 UD.ipynb: 100%\n",
      "Descargando industrial9.csv: 100%\n",
      "Descargando industrial4.csv: 100%\n",
      "Descargando industrial3.csv: 100%\n",
      "Descargando industrial10.csv: 100%\n",
      "Descargando industrial6.csv: 100%\n",
      "Descargando industrial5.csv: 100%\n",
      "Descargando industrial2.csv: 100%\n",
      "Descargando industrial8.csv: 100%\n",
      "Descargando industrial7.csv: 100%\n",
      "Descargando industrial1.csv: 100%\n",
      "Descargando sistemas10.csv: 100%\n",
      "Descargando sistemas6.csv: 100%\n",
      "Descargando sistemas2.csv: 100%\n",
      "Descargando sistemas7.csv: 100%\n",
      "Descargando sistemas4.csv: 100%\n",
      "Descargando sistemas9.csv: 100%\n",
      "Descargando sistemas5.csv: 100%\n",
      "Descargando sistemas3.csv: 100%\n",
      "Descargando sistemas8.csv: 100%\n",
      "Descargando electrica10.csv: 100%\n",
      "Descargando electrica9.csv: 100%\n",
      "Descargando electrica8.csv: 100%\n",
      "Descargando electrica7.csv: 100%\n",
      "Descargando electrica6.csv: 100%\n",
      "Descargando electrica5.csv: 100%\n",
      "Descargando electrica4.csv: 100%\n",
      "Descargando electrica3.csv: 100%\n",
      "Descargando electrica2.csv: 100%\n",
      "Descargando catastral2.csv: 100%\n",
      "Descargando catastral5.csv: 100%\n",
      "Descargando electronica7.csv: 100%\n",
      "Descargando electronica5.csv: 100%\n",
      "Descargando catastral10.csv: 100%\n",
      "Descargando catastral9.csv: 100%\n",
      "Descargando catastral8.csv: 100%\n",
      "Descargando catastral3.csv: 100%\n",
      "Descargando catastral7.csv: 100%\n",
      "Descargando catastral6.csv: 100%\n",
      "Descargando catastral4.csv: 100%\n",
      "Descargando electronica10.csv: 100%\n",
      "Descargando electronica9.csv: 100%\n",
      "Descargando electronica8.csv: 100%\n",
      "Descargando electronica6.csv: 100%\n",
      "Descargando electronica4.csv: 100%\n",
      "Descargando electronica3.csv: 100%\n",
      "Descargando electronica2.csv: 100%\n",
      "Descargando electronica1.csv: 100%\n",
      "Descarga completa\n",
      "Archivos descargados:\n",
      "catastral10.csv\n",
      "catastral2.csv\n",
      "catastral3.csv\n",
      "catastral4.csv\n",
      "catastral5.csv\n",
      "catastral6.csv\n",
      "catastral7.csv\n",
      "catastral8.csv\n",
      "catastral9.csv\n",
      "electrica10.csv\n",
      "electrica2.csv\n",
      "electrica3.csv\n",
      "electrica4.csv\n",
      "electrica5.csv\n",
      "electrica6.csv\n",
      "electrica7.csv\n",
      "electrica8.csv\n",
      "electrica9.csv\n",
      "electronica1.csv\n",
      "electronica10.csv\n",
      "electronica2.csv\n",
      "electronica3.csv\n",
      "electronica4.csv\n",
      "electronica5.csv\n",
      "electronica6.csv\n",
      "electronica7.csv\n",
      "electronica8.csv\n",
      "electronica9.csv\n",
      "industrial1.csv\n",
      "industrial10.csv\n",
      "industrial1_prediccion_grupal.csv\n",
      "industrial2.csv\n",
      "industrial3.csv\n",
      "industrial4.csv\n",
      "industrial5.csv\n",
      "industrial6.csv\n",
      "industrial7.csv\n",
      "industrial8.csv\n",
      "industrial9.csv\n",
      "Limpieza de datos 1 UD.ipynb\n",
      "sistemas10.csv\n",
      "sistemas2.csv\n",
      "sistemas3.csv\n",
      "sistemas4.csv\n",
      "sistemas5.csv\n",
      "sistemas6.csv\n",
      "sistemas7.csv\n",
      "sistemas8.csv\n",
      "sistemas9.csv\n"
     ]
    }
   ],
   "source": [
    "SCOPES = ['https://www.googleapis.com/auth/drive.readonly']\n",
    "\n",
    "creds = None\n",
    "if os.path.exists('token.json'):\n",
    "    creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "if not creds or not creds.valid:\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "        creds.refresh(Request())\n",
    "    else:\n",
    "        flow = InstalledAppFlow.from_client_secrets_file('C:/Users/Intevo/Desktop/UNIVERSIDAD DISTRITAL PROYECTO FOLDER/credentials.json', SCOPES) # Reemplazar con la ruta correcta\n",
    "        creds = flow.run_local_server(port=0)\n",
    "    with open('C:/Users/Intevo/Desktop/UNIVERSIDAD DISTRITAL PROYECTO FOLDER/token.json', 'w') as token:\n",
    "        token.write(creds.to_json())\n",
    "        \n",
    "# Crear una instancia de la API de Drive\n",
    "drive_service = build('drive', 'v3', credentials=creds)\n",
    "\n",
    "# ID de la carpeta de Google Drive\n",
    "folder_id = '1hQeetmO4XIObUefS_nzePqKqq3VksUEC'\n",
    "\n",
    "# Ruta de destino para guardar los archivos descargados\n",
    "save_path = 'C:/Users/Intevo/Desktop/UNIVERSIDAD DISTRITAL PROYECTO FOLDER/UNIVERSIDAD-DISTRITAL-PROYECTO/MODULO_ANALITICA_PRACTICO/DATOS'  # Reemplazar con la ruta deseada\n",
    "\n",
    "# Función para descargar archivos de la carpeta de Drive\n",
    "def download_folder(folder_id, save_path):\n",
    "    results = drive_service.files().list(\n",
    "        q=f\"'{folder_id}' in parents and trashed=false\",\n",
    "        fields='files(id, name)').execute()\n",
    "    items = results.get('files', [])\n",
    "    for item in items:\n",
    "        file_id = item['id']\n",
    "        file_name = item['name']\n",
    "        request = drive_service.files().get_media(fileId=file_id)\n",
    "        fh = io.FileIO(os.path.join(save_path, file_name), 'wb')\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "        done = False\n",
    "        while done is False:\n",
    "            status, done = downloader.next_chunk()\n",
    "            print(f\"Descargando {file_name}: {int(status.progress() * 100)}%\")\n",
    "    print(\"Descarga completa\")\n",
    "\n",
    "# Descargar archivos de la carpeta\n",
    "download_folder(folder_id, save_path)\n",
    "\n",
    "# Listar archivos descargados\n",
    "files = os.listdir(save_path)\n",
    "print(\"Archivos descargados:\")\n",
    "for file in files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_por_carrera = {\n",
    "    'industrial': {\n",
    "        '1': ['PG_ICFES', 'CON_MAT_ICFES', 'FISICA_ICFES','QUIMICA_ICFES','IDIOMA_ICFES','LOCALIDAD', 'PROMEDIO_UNO'],\n",
    "        '2': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'FISICA_ICFES', 'BIOLOGIA_ICFES', 'IDIOMA_ICFES', 'LOCALIDAD', 'PROMEDIO_UNO', 'CAR_UNO', 'NCC_UNO', 'NAA_UNO', 'NOTA_DIFERENCIAL', 'NOTA_DIBUJO', 'NOTA_QUIMICA', 'NOTA_CFJC', 'NOTA_TEXTOS', 'NOTA_SEMINARIO', 'NOTA_EE_UNO','PROMEDIO_DOS'],\n",
    "        '3': ['PROMEDIO_UNO', 'NAA_UNO', 'NOTA_DIFERENCIAL', 'NOTA_DIBUJO', 'NOTA_TEXTOS', 'NOTA_EE_UNO', 'PROMEDIO_DOS', 'NCC_DOS', 'NCA_DOS', 'NAA_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_PBASICA', 'NOTA_EE_DOS', 'PROMEDIO_TRES'],\n",
    "        '4': ['PROMEDIO_UNO', 'NOTA_EE_UNO', 'PROMEDIO_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'NAA_TRES', 'NOTA_MULTIVARIADO', 'NOTA_ESTADISTICA_UNO', 'NOTA_TERMODINAMICA', 'NOTA_TGS', 'NOTA_EE_TRES','PROMEDIO_CUATRO'],\n",
    "        '5': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_EE_DOS','PROMEDIO_TRES', 'NAA_TRES', 'NOTA_MULTIVARIADO', 'NOTA_TERMODINAMICA', 'NOTA_ECUACIONES', 'NOTA_ESTADISTICA_DOS', 'NOTA_FISICA_DOS', 'NOTA_MECANICA', 'NOTA_PROCESOSQ','PROMEDIO_CINCO'],\n",
    "        '6': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_ADMINISTRACION', 'NOTA_LENGUA_UNO', 'NOTA_EI_UNO', 'NOTA_EI_DOS', 'PROMEDIO_SEIS'],\n",
    "        '7': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_LENGUA_UNO', 'NOTA_EI_DOS', 'PROMEDIO_SEIS', 'NCA_SEIS', 'NOTA_PLINEAL', 'NOTA_DISENO', 'NOTA_EI_TRES','PROMEDIO_SIETE'],\n",
    "        '8': ['PROMEDIO_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_LENGUA_UNO','PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'PROMEDIO_OCHO'],\n",
    "        '9': ['PROMEDIO_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'PROMEDIO_OCHO', 'NCC_OCHO', 'NOTA_LOG_UNO', 'NOTA_GOPERACIONES','NOTA_CALIDAD_DOS', 'NOTA_LENGUA_DOS', 'NOTA_CONTEXTO','PROMEDIO_NUEVE'],\n",
    "        '10': ['PROMEDIO_SEIS', 'PROMEDIO_SIETE', 'PROMEDIO_OCHO', 'NOTA_CALIDAD_DOS', 'PROMEDIO_NUEVE', 'NAA_NUEVE', 'NOTA_GRADO_UNO', 'NOTA_LOG_DOS', 'NOTA_FINANZAS', 'NOTA_HISTORIA', 'PROMEDIO_DIEZ']\n",
    "    },\n",
    "    'sistemas': {\n",
    "        '1': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'FISICA_ICFES', 'QUIMICA_ICFES', 'IDIOMA_ICFES', 'LOCALIDAD','PROMEDIO_UNO'],\n",
    "        '2': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'IDIOMA_ICFES', 'PROMEDIO_UNO', 'NOTA_DIFERENCIAL', 'NOTA_PROG_BASICA', 'NOTA_CATEDRA_FJC', 'NOTA_TEXTOS', 'NOTA_SEMINARIO', 'NOTA_CATEDRA_DEM', 'NOTA_CATEDRA_CON', 'NOTA_LOGICA','PROMEDIO_DOS'],\n",
    "        '3': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'IDIOMA_ICFES', 'PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_PROG_BASICA', 'NOTA_TEXTOS', 'NOTA_CATEDRA_DEM', 'NOTA_INTEGRAL', 'NOTA_PROG_ORIENTADA', 'NOTA_ETICA', 'PROMEDIO_TRES'],\n",
    "        '4': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'IDIOMA_ICFES', 'PROMEDIO_UNO', 'PROMEDIO_DOS', 'PROMEDIO_TRES', 'NOTA_PROG_BASICA', 'NOTA_TEXTOS', 'NOTA_CATEDRA_DEM', 'NOTA_INTEGRAL', 'NOTA_PROG_ORIENTADA', 'NOTA_ETICA', 'NOTA_FISICA_DOS', 'NOTA_TGS', 'NOTA_PROG_AVANZADA', 'PROMEDIO_CUATRO'],\n",
    "        '5': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NAA_TRES', 'NOTA_MULTIVARIADO', 'NOTA_TERMODINAMICA', 'NOTA_ECUACIONES', 'NOTA_ESTADISTICA_DOS', 'NOTA_FISICA_DOS', 'NOTA_MECANICA', 'NOTA_PROCESOSQ', 'PROMEDIO_CINCO'],\n",
    "        '6': ['PROMEDIO_UNO', 'NOTA_EE_UNO', 'PROMEDIO_DOS', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_ECONOMIA_UNO', 'NOTA_FISICA_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_ADMINISTRACION', 'NOTA_LENGUA_UNO', 'NOTA_EI_UNO', 'NOTA_EI_DOS','PROMEDIO_SEIS'],\n",
    "        '7': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_LENGUA_UNO', 'NOTA_EI_DOS', 'PROMEDIO_SEIS', 'NCA_SEIS', 'NOTA_PLINEAL', 'NOTA_DISE O', 'NOTA_EI_TRES','PROMEDIO_SIETE'],\n",
    "        '8': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_LENGUA_UNO', 'PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'PROMEDIO_OCHO'],\n",
    "        '9': ['PROMEDIO_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'PROMEDIO_OCHO', 'NCC_OCHO', 'NOTA_LOG_UNO', 'NOTA_GOPERACIONES', 'NOTA_CALIDAD_DOS', 'NOTA_LENGUA_DOS', 'NOTA_CONTEXTO', 'PROMEDIO_NUEVE'],\n",
    "        '10': ['PROMEDIO_SEIS', 'PROMEDIO_SIETE', 'PROMEDIO_OCHO', 'NOTA_CALIDAD_DOS', 'PROMEDIO_NUEVE', 'NAA_NUEVE', 'NOTA_GRADO_UNO', 'NOTA_LOG_DOS', 'NOTA_FINANZAS', 'NOTA_HISTORIA','PROMEDIO_DIEZ']\n",
    "    },\n",
    "    'catastral': {\n",
    "        '1': ['variable1_catastral', 'variable2_catastral', 'variable3_catastral'],\n",
    "        '2': ['variable4_catastral', 'variable5_catastral', 'variable6_catastral']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_por_carrera2 = { \n",
    "    'industrial': {\n",
    "        '1': ['PG_ICFES', 'CON_MAT_ICFES', 'FISICA_ICFES','QUIMICA_ICFES','IDIOMA_ICFES','LOCALIDAD'],\n",
    "        '2': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'FISICA_ICFES', 'BIOLOGIA_ICFES', 'IDIOMA_ICFES', 'LOCALIDAD', 'PROMEDIO_UNO', 'CAR_UNO', 'NCC_UNO', 'NAA_UNO', 'NOTA_DIFERENCIAL', 'NOTA_DIBUJO', 'NOTA_QUIMICA', 'NOTA_CFJC', 'NOTA_TEXTOS', 'NOTA_SEMINARIO', 'NOTA_EE_UNO'],\n",
    "        '3': ['PROMEDIO_UNO', 'NAA_UNO', 'NOTA_DIFERENCIAL', 'NOTA_DIBUJO', 'NOTA_TEXTOS', 'NOTA_EE_UNO', 'PROMEDIO_DOS', 'NCC_DOS', 'NCA_DOS', 'NAA_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_PBASICA', 'NOTA_EE_DOS'],\n",
    "        '4': ['PROMEDIO_UNO', 'NOTA_EE_UNO', 'PROMEDIO_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'NAA_TRES', 'NOTA_MULTIVARIADO', 'NOTA_ESTADISTICA_UNO', 'NOTA_TERMODINAMICA', 'NOTA_TGS', 'NOTA_EE_TRES'],\n",
    "        '5': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_EE_DOS','PROMEDIO_TRES', 'NAA_TRES', 'NOTA_MULTIVARIADO', 'NOTA_TERMODINAMICA', 'NOTA_ECUACIONES', 'NOTA_ESTADISTICA_DOS', 'NOTA_FISICA_DOS', 'NOTA_MECANICA', 'NOTA_PROCESOSQ'],\n",
    "        '6': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_ADMINISTRACION', 'NOTA_LENGUA_UNO', 'NOTA_EI_UNO', 'NOTA_EI_DOS'],\n",
    "        '7': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_LENGUA_UNO', 'NOTA_EI_DOS', 'PROMEDIO_SEIS', 'NCA_SEIS', 'NOTA_PLINEAL', 'NOTA_DISENO', 'NOTA_EI_TRES'],\n",
    "        '8': ['PROMEDIO_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_LENGUA_UNO','PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO'],\n",
    "        '9': ['PROMEDIO_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'PROMEDIO_OCHO', 'NCC_OCHO', 'NOTA_LOG_UNO', 'NOTA_GOPERACIONES','NOTA_CALIDAD_DOS', 'NOTA_LENGUA_DOS', 'NOTA_CONTEXTO'],\n",
    "        '10': ['PROMEDIO_SEIS', 'PROMEDIO_SIETE', 'PROMEDIO_OCHO', 'NOTA_CALIDAD_DOS', 'PROMEDIO_NUEVE', 'NAA_NUEVE', 'NOTA_GRADO_UNO', 'NOTA_LOG_DOS', 'NOTA_FINANZAS', 'NOTA_HISTORIA']\n",
    "    },\n",
    "    'sistemas': {\n",
    "        '1': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'FISICA_ICFES', 'QUIMICA_ICFES', 'IDIOMA_ICFES', 'LOCALIDAD',],\n",
    "        '2': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'IDIOMA_ICFES', 'PROMEDIO_UNO', 'NOTA_DIFERENCIAL', 'NOTA_PROG_BASICA', 'NOTA_CATEDRA_FJC', 'NOTA_TEXTOS', 'NOTA_SEMINARIO', 'NOTA_CATEDRA_DEM', 'NOTA_CATEDRA_CON', 'NOTA_LOGICA'],\n",
    "        '3': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'IDIOMA_ICFES', 'PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_PROG_BASICA', 'NOTA_TEXTOS', 'NOTA_CATEDRA_DEM', 'NOTA_INTEGRAL', 'NOTA_PROG_ORIENTADA', 'NOTA_ETICA'],\n",
    "        '4': ['LOCALIDAD_COLEGIO', 'PG_ICFES', 'CON_MAT_ICFES', 'IDIOMA_ICFES', 'PROMEDIO_UNO', 'PROMEDIO_DOS', 'PROMEDIO_TRES', 'NOTA_PROG_BASICA', 'NOTA_TEXTOS', 'NOTA_CATEDRA_DEM', 'NOTA_INTEGRAL', 'NOTA_PROG_ORIENTADA', 'NOTA_ETICA', 'NOTA_FISICA_DOS', 'NOTA_TGS', 'NOTA_PROG_AVANZADA'],\n",
    "        '5': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_ALGEBRA', 'NOTA_INTEGRAL', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NAA_TRES', 'NOTA_MULTIVARIADO', 'NOTA_TERMODINAMICA', 'NOTA_ECUACIONES', 'NOTA_ESTADISTICA_DOS', 'NOTA_FISICA_DOS', 'NOTA_MECANICA', 'NOTA_PROCESOSQ'],\n",
    "        '6': ['PROMEDIO_UNO', 'NOTA_EE_UNO', 'PROMEDIO_DOS', 'NOTA_MATERIALES', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_ECONOMIA_UNO', 'NOTA_FISICA_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_ADMINISTRACION', 'NOTA_LENGUA_UNO', 'NOTA_EI_UNO', 'NOTA_EI_DOS'],\n",
    "        '7': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'PROMEDIO_CINCO', 'NOTA_PROCESOSM', 'NOTA_LENGUA_UNO', 'NOTA_EI_DOS', 'PROMEDIO_SEIS', 'NCA_SEIS', 'NOTA_PLINEAL', 'NOTA_DISE O', 'NOTA_EI_TRES'],\n",
    "        '8': ['PROMEDIO_UNO', 'PROMEDIO_DOS', 'NOTA_EE_DOS', 'PROMEDIO_TRES', 'NOTA_MULTIVARIADO', 'NOTA_FISICA_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'NOTA_LENGUA_UNO', 'PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO'],\n",
    "        '9': ['PROMEDIO_DOS', 'NOTA_EE_CUATRO', 'PROMEDIO_CINCO', 'PROMEDIO_SEIS', 'NOTA_IECONOMICA', 'PROMEDIO_SIETE', 'NAA_SIETE', 'NOTA_GRAFOS', 'NOTA_CALIDAD_UNO', 'NOTA_ERGONOMIA', 'NOTA_EI_CINCO', 'PROMEDIO_OCHO', 'NCC_OCHO', 'NOTA_LOG_UNO', 'NOTA_GOPERACIONES', 'NOTA_CALIDAD_DOS', 'NOTA_LENGUA_DOS', 'NOTA_CONTEXTO'],\n",
    "        '10': ['PROMEDIO_SEIS', 'PROMEDIO_SIETE', 'PROMEDIO_OCHO', 'NOTA_CALIDAD_DOS', 'PROMEDIO_NUEVE', 'NAA_NUEVE', 'NOTA_GRADO_UNO', 'NOTA_LOG_DOS', 'NOTA_FINANZAS', 'NOTA_HISTORIA']\n",
    "    },\n",
    "    'catastral': {\n",
    "        '1': ['variable1_catastral', 'variable2_catastral', 'variable3_catastral'],\n",
    "        '2': ['variable4_catastral', 'variable5_catastral', 'variable6_catastral']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_datos(carrera, semestre):\n",
    "    \n",
    "    ruta_archivo = f'C:/Users/Intevo/Desktop/UNIVERSIDAD DISTRITAL PROYECTO FOLDER/UNIVERSIDAD-DISTRITAL-PROYECTO/MODULO_ANALITICA_PRACTICO/DATOS/{carrera}{semestre}.csv'\n",
    "    datos = pd.read_csv(ruta_archivo,sep=\";\")\n",
    "    ruta_archivo_prediccion= f'C:/Users/Intevo/Desktop/UNIVERSIDAD DISTRITAL PROYECTO FOLDER/UNIVERSIDAD-DISTRITAL-PROYECTO/MODULO_ANALITICA_PRACTICO/DATOS/{carrera}{semestre}_prediccion_grupal.csv'\n",
    "    datos_prediccion=pd.read_csv(ruta_archivo_prediccion,sep=';')\n",
    "    return datos,datos_prediccion\n",
    "carrera=\"industrial\"\n",
    "semestre=\"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame con columnas filtradas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PG_ICFES</th>\n",
       "      <th>CON_MAT_ICFES</th>\n",
       "      <th>FISICA_ICFES</th>\n",
       "      <th>QUIMICA_ICFES</th>\n",
       "      <th>IDIOMA_ICFES</th>\n",
       "      <th>LOCALIDAD</th>\n",
       "      <th>PROMEDIO_UNO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>419</td>\n",
       "      <td>65</td>\n",
       "      <td>60</td>\n",
       "      <td>66</td>\n",
       "      <td>75</td>\n",
       "      <td>20</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>425</td>\n",
       "      <td>72</td>\n",
       "      <td>65</td>\n",
       "      <td>55</td>\n",
       "      <td>65</td>\n",
       "      <td>15</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>425</td>\n",
       "      <td>76</td>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>454</td>\n",
       "      <td>79</td>\n",
       "      <td>62</td>\n",
       "      <td>65</td>\n",
       "      <td>83</td>\n",
       "      <td>10</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>523</td>\n",
       "      <td>99</td>\n",
       "      <td>69</td>\n",
       "      <td>78</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>302</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>415</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>56</td>\n",
       "      <td>47</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>350</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>20</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>436</td>\n",
       "      <td>68</td>\n",
       "      <td>72</td>\n",
       "      <td>64</td>\n",
       "      <td>69</td>\n",
       "      <td>11</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>412</td>\n",
       "      <td>60</td>\n",
       "      <td>66</td>\n",
       "      <td>50</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2017 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PG_ICFES  CON_MAT_ICFES  FISICA_ICFES  QUIMICA_ICFES  IDIOMA_ICFES  \\\n",
       "0          419             65            60             66            75   \n",
       "1          425             72            65             55            65   \n",
       "2          425             76            60             59            50   \n",
       "3          454             79            62             65            83   \n",
       "4          523             99            69             78            60   \n",
       "...        ...            ...           ...            ...           ...   \n",
       "2012       302             59             0              0            58   \n",
       "2013       415             63            80             56            47   \n",
       "2014       350             66             0              0            55   \n",
       "2015       436             68            72             64            69   \n",
       "2016       412             60            66             50            46   \n",
       "\n",
       "      LOCALIDAD  PROMEDIO_UNO  \n",
       "0            20            39  \n",
       "1            15            35  \n",
       "2             9            30  \n",
       "3            10            38  \n",
       "4             1            37  \n",
       "...         ...           ...  \n",
       "2012         20            28  \n",
       "2013          8            24  \n",
       "2014         20            35  \n",
       "2015         11            34  \n",
       "2016         11            42  \n",
       "\n",
       "[2017 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos,datos_prediccion = cargar_datos(carrera, semestre)\n",
    "columnas_filtradas = variables_por_carrera[carrera][semestre]\n",
    "df = datos[columnas_filtradas]\n",
    "print(\"DataFrame con columnas filtradas:\")\n",
    "df=df.astype(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame con columnas filtradas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PG_ICFES</th>\n",
       "      <th>CON_MAT_ICFES</th>\n",
       "      <th>FISICA_ICFES</th>\n",
       "      <th>QUIMICA_ICFES</th>\n",
       "      <th>IDIOMA_ICFES</th>\n",
       "      <th>LOCALIDAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>419</td>\n",
       "      <td>65</td>\n",
       "      <td>60</td>\n",
       "      <td>66</td>\n",
       "      <td>75</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>425</td>\n",
       "      <td>72</td>\n",
       "      <td>65</td>\n",
       "      <td>55</td>\n",
       "      <td>65</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>425</td>\n",
       "      <td>76</td>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>454</td>\n",
       "      <td>79</td>\n",
       "      <td>62</td>\n",
       "      <td>65</td>\n",
       "      <td>83</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>523</td>\n",
       "      <td>99</td>\n",
       "      <td>69</td>\n",
       "      <td>78</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>451</td>\n",
       "      <td>67</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>83</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>437</td>\n",
       "      <td>74</td>\n",
       "      <td>62</td>\n",
       "      <td>57</td>\n",
       "      <td>56</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>429</td>\n",
       "      <td>77</td>\n",
       "      <td>62</td>\n",
       "      <td>59</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>429</td>\n",
       "      <td>90</td>\n",
       "      <td>52</td>\n",
       "      <td>58</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>439</td>\n",
       "      <td>77</td>\n",
       "      <td>61</td>\n",
       "      <td>56</td>\n",
       "      <td>57</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PG_ICFES  CON_MAT_ICFES  FISICA_ICFES  QUIMICA_ICFES  IDIOMA_ICFES  \\\n",
       "0         419             65            60             66            75   \n",
       "1         425             72            65             55            65   \n",
       "2         425             76            60             59            50   \n",
       "3         454             79            62             65            83   \n",
       "4         523             99            69             78            60   \n",
       "..        ...            ...           ...            ...           ...   \n",
       "324       451             67            64             65            83   \n",
       "325       437             74            62             57            56   \n",
       "326       429             77            62             59            68   \n",
       "327       429             90            52             58            50   \n",
       "328       439             77            61             56            57   \n",
       "\n",
       "     LOCALIDAD  \n",
       "0           20  \n",
       "1           15  \n",
       "2            9  \n",
       "3           10  \n",
       "4            1  \n",
       "..         ...  \n",
       "324         11  \n",
       "325         19  \n",
       "326          8  \n",
       "327          8  \n",
       "328         11  \n",
       "\n",
       "[329 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos,datos_prediccion = cargar_datos(carrera, semestre)\n",
    "columnas_filtradas = variables_por_carrera2[carrera][semestre]\n",
    "df_prediccion = datos_prediccion[columnas_filtradas]\n",
    "print(\"DataFrame con columnas filtradas:\")\n",
    "df_prediccion=df_prediccion.astype(int)\n",
    "df_prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uno\n"
     ]
    }
   ],
   "source": [
    "def numero_a_letras(numero):\n",
    "    numeros_letras = ['cero', 'uno', 'dos', 'tres', 'cuatro', 'cinco', 'seis', 'siete', 'ocho', 'nueve', 'diez']\n",
    "    return numeros_letras[int(numero)]\n",
    "\n",
    "semestre_en_letras = numero_a_letras(semestre)\n",
    "print(semestre_en_letras)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separación de datos usando Pandas\n",
      "(2017, 6) (2017, 1)\n"
     ]
    }
   ],
   "source": [
    "X = df.loc[:, ~df.columns.str.contains(f'PROMEDIO_{semestre_en_letras.upper()}')]\n",
    "Y = df.loc[:, df.columns.str.contains(f'PROMEDIO_{semestre_en_letras.upper()}')]                                                     \n",
    "print(\"Separación de datos usando Pandas\") \n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2017, 6) (2017, 1)\n"
     ]
    }
   ],
   "source": [
    "X = X.astype('float32')                         \n",
    "#Y = LabelEncoder().fit_transform(Y.astype('str'))                \n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.531 -0.894  0.882  0.965  0.933  1.357]\n",
      " [ 0.651 -0.072  0.932  0.851  0.104  0.571]\n",
      " [ 0.651  0.391  0.882  0.895 -1.102 -0.488]\n",
      " [ 1.218  0.735  0.903  0.955  1.609 -0.3  ]\n",
      " [ 2.506  2.974  0.969  1.072 -0.304 -2.357]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PG_ICFES</th>\n",
       "      <th>CON_MAT_ICFES</th>\n",
       "      <th>FISICA_ICFES</th>\n",
       "      <th>QUIMICA_ICFES</th>\n",
       "      <th>IDIOMA_ICFES</th>\n",
       "      <th>LOCALIDAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.531471</td>\n",
       "      <td>-0.894366</td>\n",
       "      <td>0.882446</td>\n",
       "      <td>0.964925</td>\n",
       "      <td>0.932902</td>\n",
       "      <td>1.357424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.650876</td>\n",
       "      <td>-0.072121</td>\n",
       "      <td>0.931926</td>\n",
       "      <td>0.851496</td>\n",
       "      <td>0.103605</td>\n",
       "      <td>0.570894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PG_ICFES  CON_MAT_ICFES  FISICA_ICFES  QUIMICA_ICFES  IDIOMA_ICFES  \\\n",
       "0  0.531471      -0.894366      0.882446       0.964925      0.932902   \n",
       "1  0.650876      -0.072121      0.931926       0.851496      0.103605   \n",
       "\n",
       "   LOCALIDAD  \n",
       "0   1.357424  \n",
       "1   0.570894  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_T_JOHNSON1 = X.copy(deep=True)\n",
    "def transformacion_johnson(X):\n",
    "    transformador_johnson = PowerTransformer(method='yeo-johnson', standardize=True).fit(X)\n",
    "    datos_transformados = transformador_johnson.transform(X)\n",
    "    set_printoptions(precision=3)\n",
    "    print(datos_transformados[:5, :])\n",
    "    datos_transformados_df = pd.DataFrame(data=datos_transformados, columns=X.columns)\n",
    "    return datos_transformados_df\n",
    "Xpandas_T_JOHNSON1 = transformacion_johnson(X_T_JOHNSON1)\n",
    "Xpandas_T_JOHNSON1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATOS: Son 1411 datos para entrenamiento y 606 datos para prueba\n"
     ]
    }
   ],
   "source": [
    "X_trn, X_tst, Y_trn, Y_tst = train_test_split(Xpandas_T_JOHNSON1, Y, test_size=0.3, random_state=2)\n",
    "print('DATOS: Son {} datos para entrenamiento y {} datos para prueba'.format(X_trn.shape[0], X_tst.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separación de datos usando Pandas\n",
      "(329, 6) (329, 0)\n"
     ]
    }
   ],
   "source": [
    "X_prediccion = df_prediccion.loc[:, ~df_prediccion.columns.str.contains(f'PROMEDIO_{semestre_en_letras.upper()}')]\n",
    "Y_prediccion = df_prediccion.loc[:, df_prediccion.columns.str.contains(f'PROMEDIO_{semestre_en_letras.upper()}')]                                                     \n",
    "print(\"Separación de datos usando Pandas\") \n",
    "print(X_prediccion.shape, Y_prediccion.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-7.000e-01 -7.954e-01 -2.798e-01  6.410e-01  1.130e+00  1.858e+00]\n",
      " [-5.012e-01 -2.353e-02  4.003e-01 -6.398e-01  3.927e-01  9.656e-01]\n",
      " [-5.012e-01  3.907e-01 -2.798e-01 -1.061e-01 -1.033e+00 -2.337e-01]\n",
      " [ 3.873e-01  6.900e-01 -1.209e-03  5.463e-01  1.637e+00 -2.069e-02]\n",
      " [ 2.113e+00  2.480e+00  9.078e-01  1.550e+00 -3.209e-02 -2.340e+00]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PG_ICFES</th>\n",
       "      <th>CON_MAT_ICFES</th>\n",
       "      <th>FISICA_ICFES</th>\n",
       "      <th>QUIMICA_ICFES</th>\n",
       "      <th>IDIOMA_ICFES</th>\n",
       "      <th>LOCALIDAD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.700004</td>\n",
       "      <td>-0.795373</td>\n",
       "      <td>-0.279768</td>\n",
       "      <td>0.641039</td>\n",
       "      <td>1.130423</td>\n",
       "      <td>1.857982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.501183</td>\n",
       "      <td>-0.023532</td>\n",
       "      <td>0.400294</td>\n",
       "      <td>-0.639813</td>\n",
       "      <td>0.392655</td>\n",
       "      <td>0.965575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PG_ICFES  CON_MAT_ICFES  FISICA_ICFES  QUIMICA_ICFES  IDIOMA_ICFES  \\\n",
       "0 -0.700004      -0.795373     -0.279768       0.641039      1.130423   \n",
       "1 -0.501183      -0.023532      0.400294      -0.639813      0.392655   \n",
       "\n",
       "   LOCALIDAD  \n",
       "0   1.857982  \n",
       "1   0.965575  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_T_JOHNSON2 = X_prediccion.copy(deep=True)\n",
    "def transformacion_johnson(X_prediccion):\n",
    "    transformador_johnson = PowerTransformer(method='yeo-johnson', standardize=True).fit(X_prediccion)\n",
    "    datos_transformados = transformador_johnson.transform(X_prediccion)\n",
    "    set_printoptions(precision=3)\n",
    "    print(datos_transformados[:5, :])\n",
    "    datos_transformados_df = pd.DataFrame(data=datos_transformados, columns=X_prediccion.columns)\n",
    "    return datos_transformados_df\n",
    "Xpandas_T_JOHNSON2 = transformacion_johnson(X_T_JOHNSON2)\n",
    "Xpandas_T_JOHNSON2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNEIGHBORSREGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'metric': 'manhattan',\n",
       " 'n_neighbors': 17,\n",
       " 'p': 1,\n",
       " 'weights': 'uniform'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def entrenar_modelo_knn_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {\n",
    "        'n_neighbors': [i for i in range(1, 18, 1)],\n",
    "        'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "        'algorithm': ['auto'],\n",
    "        'p': [i for i in range(1, 6)],\n",
    "        'weights': ['uniform']\n",
    "    }\n",
    "    modelo = KNeighborsRegressor()\n",
    "    semilla = 5\n",
    "    num_folds = 10\n",
    "    kfold =StratifiedKFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'neg_mean_squared_error'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn_transformado, Y_trn)\n",
    "    mejor_modelo = KNeighborsRegressor(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    mejores_hiperparametros_knn=grid_resultado.best_params_\n",
    "    return mejor_modelo,grid_resultado.best_params_\n",
    "modelo_knn,mejores_hiperparametros_knn  = entrenar_modelo_knn_con_transformacion(X_trn, Y_trn)\n",
    "mejores_hiperparametros_knn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0230339271539044"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_knn.predict(X_tst)\n",
    "r2_knn = r2_score(Y_tst, Y_pred_prueba)\n",
    "r2_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_modelo_svc_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = { 'kernel':  ['rbf', 'poly', 'sigmoid','linear'], \n",
    "            'C': [i/10000 for i in range(8,12,1)],\n",
    "            'max_iter':[i for i in range(1,3,1)],\n",
    "            'gamma' : [i/100 for i in range(90,110,5)]}\n",
    "    modelo = SVR()\n",
    "    semilla=5\n",
    "    num_folds=10\n",
    "    kfold =StratifiedKFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'neg_mean_squared_error'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn_transformado, Y_trn)\n",
    "    mejor_modelo = SVR(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    mejores_hiperparametros_svc=grid_resultado.best_params_\n",
    "    return mejor_modelo,grid_resultado.best_params_\n",
    "\n",
    "modelo_svc,mejores_hiperparametros_svc = entrenar_modelo_svc_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7698765550800049"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_svc.predict(X_tst)\n",
    "r2_svc = r2_score(Y_tst, Y_pred_prueba)\n",
    "r2_svc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_modelo_tree_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {          \n",
    "            'max_depth':[i for i in range(1,7,1)], \n",
    "            'min_samples_leaf' : [i for i in range(1,7,1)], \n",
    "            'max_features' : [i for i in range(1,7,1)], \n",
    "            'splitter': [\"best\", \"random\"],\n",
    "            'random_state': [i for i in range(1,7,1)]}\n",
    "    modelo = DecisionTreeRegressor()\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = StratifiedKFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'neg_mean_squared_error'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    mejor_modelo = DecisionTreeRegressor(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    mejores_hiperparametros_tree=grid_resultado.best_params_\n",
    "    return mejor_modelo, grid_resultado.best_params_\n",
    "\n",
    "modelo_tree,mejores_hiperparametros_tree = entrenar_modelo_tree_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.006564783343039116"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_tree.predict(X_tst)\n",
    "r2_tree = r2_score(Y_tst, Y_pred_prueba)\n",
    "r2_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_modelo_gaussian_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    kernel1 = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-4, 1e4))\n",
    "    kernel2 = C(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-4, 1e4)) + WhiteKernel(noise_level=1, noise_level_bounds=(1e-10, 1e1))\n",
    "    parameters = {\n",
    "        #'kernel': [kernel1, kernel2],\n",
    "        'alpha': [1e-10, 1e-5, 1e-2, 1e-1],\n",
    "        'n_restarts_optimizer': [0, 1, 2, 3],\n",
    "        'normalize_y': [True, False],\n",
    "        'optimizer': ['fmin_l_bfgs_b']\n",
    "    }\n",
    "    modelo = GaussianProcessRegressor()\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold =StratifiedKFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica = 'neg_mean_squared_error'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    mejor_modelo = GaussianProcessRegressor(**grid_resultado.best_params_)\n",
    "    mejores_hiperparametros_gaussian=grid_resultado.best_params_\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo,grid_resultado.best_params_\n",
    "\n",
    "modelo_gaussian,mejores_hiperparametros_gaussian = entrenar_modelo_gaussian_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0979077605646328"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_gaussian.predict(X_tst)\n",
    "r2_gaussian = r2_score(Y_tst, Y_pred_prueba)\n",
    "r2_gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_modelo_LDA_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = { 'solver':  ['svd','lsqr','eigen'],\n",
    "            'n_components':[1,2,3,4,5,6,7,8,9,10],\n",
    "            'shrinkage': ['auto', 0.001, 0.01, 0.1, 0.5,1,10,100,1000]\n",
    "            #'tol':[i/1000 for i in range(1,100,1)]\n",
    "            }\n",
    "    modelo = LinearDiscriminantAnalysis()\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = StratifiedKFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica= 'neg_mean_squared_error'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    mejor_modelo = LinearDiscriminantAnalysis(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    mejores_hiperparametros_LDA=grid_resultado.best_params_\n",
    "    return mejor_modelo,grid_resultado.best_params_\n",
    "\n",
    "modelo_LDA,mejores_hiperparametros_LDA = entrenar_modelo_LDA_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.26259991622575796"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_LDA.predict(X_tst)\n",
    "r2_LDA = r2_score(Y_tst, Y_pred_prueba)\n",
    "r2_LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BAGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_modelo_BG_con_transformacion(X_trn, Y_trn,mejores_hiperparametros_tree):\n",
    "    # Aplicar la transformación Yeo-Johnson\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {'n_estimators': [i for i in range(750,760,5)],\n",
    "            'max_samples' : [i/100.0 for i in range(70,90,5)],\n",
    "            'max_features': [i/100.0 for i in range(75,85,5)],\n",
    "            'bootstrap': [True], \n",
    "            'bootstrap_features': [True]}\n",
    "    base_estimator= DecisionTreeRegressor(**mejores_hiperparametros_tree)\n",
    "    semilla=7\n",
    "    modelo = BaggingRegressor(estimator=base_estimator,n_estimators=750, random_state=semilla,\n",
    "                             bootstrap= True, bootstrap_features = True, max_features = 0.7,\n",
    "                             max_samples= 0.5)\n",
    "    num_folds=10\n",
    "    kfold = StratifiedKFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica =  'neg_mean_squared_error'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    mejores_hiperparametros_BG=grid_resultado.best_params_\n",
    "    mejor_modelo = BaggingRegressor(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo,grid_resultado.best_params_\n",
    "X_trn = X_trn\n",
    "Y_trn = Y_trn \n",
    "modelo_BG,mejores_hiperparametros_BG = entrenar_modelo_BG_con_transformacion(X_trn, Y_trn,mejores_hiperparametros_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.006528797321458724"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_BG.predict(X_tst)\n",
    "r2_BG = r2_score(Y_tst, Y_pred_prueba)\n",
    "r2_BG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_modelo_random_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = { \n",
    "                'min_samples_split' : [1, 2 , 3,  4 , 6 , 8 , 10 , 15, 20 ],  \n",
    "                'min_samples_leaf' : [ 1 , 3 , 5 , 7 , 9, 12, 15 ],\n",
    "            }\n",
    "    modelo = RandomForestRegressor()\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = StratifiedKFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica =  'neg_mean_squared_error'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    mejores_hiperparametros_random=grid_resultado.best_params_\n",
    "    mejor_modelo = RandomForestRegressor(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo,grid_resultado.best_params_\n",
    "\n",
    "modelo_random,mejores_hiperparametros_random = entrenar_modelo_random_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004868276774511515"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_random.predict(X_tst)\n",
    "r2_random = r2_score(Y_tst, Y_pred_prueba)\n",
    "r2_random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXTRATREES REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_modelo_extra_con_transformacion(X_trn, Y_trn):\n",
    "    # Aplicar la transformación Yeo-Johnson\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {'min_samples_split' : [i for i in range(1,10,1)], \n",
    "                #'min_samples_leaf' : [i for i in range(0,10,1)],\n",
    "                #'max_features':[i for i in range(0,5,1)],\n",
    "                #'max_depth':[i for i in range(0,5,1)],\n",
    "                #'min_samples_leaf':[i for i in range(0,10,1)],\n",
    "                #'min_samples_split':[i for i in range(0,10,1)],\n",
    "                'criterion':('absolute_error', 'squared_error', 'friedman_mse', 'poisson')}\n",
    "    semilla=7            \n",
    "    modelo = ExtraTreesRegressor(random_state=semilla, \n",
    "                                n_estimators=40,\n",
    "                                bootstrap=True) \n",
    "    num_folds=10\n",
    "    kfold = StratifiedKFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica ='neg_mean_squared_error'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    mejores_hiperparametros_extra=grid_resultado.best_params_\n",
    "    mejor_modelo = ExtraTreesRegressor(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo,grid_resultado.best_params_\n",
    "\n",
    "modelo_extra,mejores_hiperparametros_extra = entrenar_modelo_extra_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012539342319807245"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_extra.predict(X_tst)\n",
    "r2_extra = r2_score(Y_tst, Y_pred_prueba)\n",
    "r2_extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_modelo_ADA_con_transformacion(X_trn, Y_trn):\n",
    "    # Aplicar la transformación Yeo-Johnson\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {'learning_rate' : [i/10000.0 for i in range(5,20,5)],\n",
    "                  'n_estimators':[i for i in range(1,50,1)]}\n",
    "    semilla=7            \n",
    "    modelo = AdaBoostRegressor(estimator = None,random_state= None) \n",
    "    num_folds=10\n",
    "    kfold = StratifiedKFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica ='neg_mean_squared_error'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    mejores_hiperparametros_ADA=grid_resultado.best_params_\n",
    "    mejor_modelo = AdaBoostRegressor(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo,grid_resultado.best_params_\n",
    "\n",
    "modelo_ADA, mejores_hiperparametros_ADA= entrenar_modelo_ADA_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012844154465691537"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_ADA.predict(X_tst)\n",
    "r2_ADA = r2_score(Y_tst, Y_pred_prueba)\n",
    "r2_ADA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRADIENTBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_modelo_GD_con_transformacion(X_trn, Y_trn):\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = { \n",
    "                'learning_rate' : [0.01, 0.05, 0.1,0.15],\n",
    "                #'n_estimators': [i for i in range(100,1200,100)],\n",
    "                'loss':('absolute_error', 'squared_error', 'quantile', 'huber'),\n",
    "                'criterion':['friedman_mse']}\n",
    "    semilla=7\n",
    "    modelo = GradientBoostingRegressor(random_state=semilla,\n",
    "                                    n_estimators= 100,learning_rate= 0.1,max_depth= 2,\n",
    "                                    min_samples_split= 2, min_samples_leaf= 3,max_features= 2)\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = StratifiedKFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica ='neg_mean_squared_error'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    mejores_hiperparametros_GD=grid_resultado.best_params_\n",
    "    mejor_modelo = GradientBoostingRegressor(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo,grid_resultado.best_params_\n",
    "\n",
    "modelo_GD,mejores_hiperparametros_GD = entrenar_modelo_GD_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014136152556050607"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_GD.predict(X_tst)\n",
    "r2_GD = r2_score(Y_tst, Y_pred_prueba)\n",
    "r2_GD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_modelo_XB_con_transformacion(X_trn, Y_trn):\n",
    "    # Aplicar la transformación Yeo-Johnson\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {'reg_alpha': [0,0.1,0.2,0.3,0.4,0.5],\n",
    "                'reg_lambda':  [i/1000.0 for i in range(100,150,5)],\n",
    "                #'n_estimators':  [i for i in range(1,10,2)],\n",
    "                'colsample_bytree': [0.1,0.3, 0.5,0.6,0.7,0.8, 0.9, 1,1.1],\n",
    "                #'objective' : ('binary:logistic', 'Multi: softprob'),\n",
    "                #'loss': ['log_loss'],\n",
    "                'max_features':('sqrt','log2')\n",
    "                }\n",
    "    semilla=7\n",
    "    modelo = XGBRegressor(random_state=semilla,subsample =1,max_depth =2)\n",
    "    num_folds=10\n",
    "    kfold = StratifiedKFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica ='neg_mean_squared_error'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    mejores_hiperparametros_XB=grid_resultado.best_params_\n",
    "    mejor_modelo = XGBRegressor(**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo,grid_resultado.best_params_\n",
    "\n",
    "modelo_XB,mejores_hiperparametros_XB = entrenar_modelo_XB_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2249264225131029"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_XB.predict(X_tst)\n",
    "r2_XB = r2_score(Y_tst, Y_pred_prueba)\n",
    "r2_XB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CATBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_modelo_CB_con_transformacion(X_trn, Y_trn):\n",
    "    # Aplicar la transformación Yeo-Johnson\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {} \n",
    "    semilla=7\n",
    "    modelo = CatBoostRegressor(random_state=semilla, verbose =0)\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = StratifiedKFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica ='neg_mean_squared_error'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    mejores_hiperparametros_CB=grid_resultado.best_params_\n",
    "    mejor_modelo = CatBoostRegressor(verbose=0,**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo,grid_resultado.best_params_\n",
    "\n",
    "modelo_CB,mejores_hiperparametros_CB = entrenar_modelo_CB_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.03910104595770769"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_CB.predict(X_tst)\n",
    "r2_CB = r2_score(Y_tst, Y_pred_prueba)\n",
    "r2_CB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIGHT GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1395, number of negative: 16\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 375\n",
      "[LightGBM] [Info] Number of data points in the train set: 1411, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.988661 -> initscore=4.468061\n",
      "[LightGBM] [Info] Start training from score 4.468061\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_LIGHT_con_transformacion(X_trn, Y_trn):\n",
    "    # Aplicar la transformación Yeo-Johnson\n",
    "    X_trn_transformado = X_trn\n",
    "    parameters = {\n",
    "    'min_child_samples' : [i for i in range(1, 1000, 100)],'colsample_bytree': [0.6, 0.8, 1.0,1.5],\n",
    "    'boosting_type': ['gbdt', 'dart', 'goss'],'objective': ['binary', 'multiclass'],'random_state': [42]}\n",
    "    semilla=7\n",
    "    modelo = LGBMRegressor(random_state=semilla,                           \n",
    "                            num_leaves =  10,max_depth = 1, n_estimators = 100,    \n",
    "                            learning_rate = 0.1 ,class_weight=  None, subsample = 1,\n",
    "                            colsample_bytree= 1, reg_alpha=  0, reg_lambda = 0,\n",
    "                            min_split_gain = 0, boosting_type = 'gbdt')\n",
    "    semilla=7\n",
    "    num_folds=10\n",
    "    kfold = StratifiedKFold(n_splits=num_folds, random_state=semilla, shuffle=True)\n",
    "    metrica ='neg_mean_squared_error'\n",
    "    grid = GridSearchCV(estimator=modelo, param_grid=parameters, scoring=metrica, cv=kfold, n_jobs=-1)\n",
    "    grid_resultado = grid.fit(X_trn, Y_trn)\n",
    "    mejores_hiperparametros_LIGHT=grid_resultado.best_params_\n",
    "    mejor_modelo = LGBMRegressor(verbose=-1,**grid_resultado.best_params_)\n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    return mejor_modelo,grid_resultado.best_params_\n",
    "\n",
    "modelo_LIGHT,mejores_hiperparametros_LIGHT = entrenar_modelo_LIGHT_con_transformacion(X_trn, Y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10.506175596577277"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_LIGHT.predict(X_tst)\n",
    "r2_LIGHT = r2_score(Y_tst, Y_pred_prueba)\n",
    "r2_LIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'reg:squarederror',\n",
       " 'base_score': None,\n",
       " 'booster': None,\n",
       " 'callbacks': None,\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'colsample_bytree': 0.1,\n",
       " 'device': None,\n",
       " 'early_stopping_rounds': None,\n",
       " 'enable_categorical': False,\n",
       " 'eval_metric': None,\n",
       " 'feature_types': None,\n",
       " 'gamma': None,\n",
       " 'grow_policy': None,\n",
       " 'importance_type': None,\n",
       " 'interaction_constraints': None,\n",
       " 'learning_rate': None,\n",
       " 'max_bin': None,\n",
       " 'max_cat_threshold': None,\n",
       " 'max_cat_to_onehot': None,\n",
       " 'max_delta_step': None,\n",
       " 'max_depth': None,\n",
       " 'max_leaves': None,\n",
       " 'min_child_weight': None,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': None,\n",
       " 'multi_strategy': None,\n",
       " 'n_estimators': None,\n",
       " 'n_jobs': None,\n",
       " 'num_parallel_tree': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': 0.2,\n",
       " 'reg_lambda': 0.135,\n",
       " 'sampling_method': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': None,\n",
       " 'tree_method': None,\n",
       " 'validate_parameters': None,\n",
       " 'verbosity': None,\n",
       " 'max_features': 'sqrt'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mejores_hiperparametros_knn = modelo_knn.get_params()\n",
    "mejores_hiperparametros_knn\n",
    "\n",
    "mejores_hiperparametros_GD = modelo_GD.get_params()\n",
    "mejores_hiperparametros_GD\n",
    "\n",
    "mejores_hiperparametros_tree = modelo_tree.get_params()\n",
    "mejores_hiperparametros_tree\n",
    "\n",
    "mejores_hiperparametros_ADA = modelo_ADA.get_params()\n",
    "mejores_hiperparametros_ADA\n",
    "\n",
    "mejores_hiperparametros_extra = modelo_extra.get_params()\n",
    "mejores_hiperparametros_extra\n",
    "\n",
    "mejores_hiperparametros_random = modelo_random.get_params()\n",
    "mejores_hiperparametros_random\n",
    "\n",
    "mejores_hiperparametros_BG = modelo_BG.get_params()\n",
    "mejores_hiperparametros_BG\n",
    "\n",
    "mejores_hiperparametros_XB = modelo_XB.get_params()\n",
    "mejores_hiperparametros_XB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VOTING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_modelo_voting_con_transformacion(X_trn, Y_trn,\n",
    "                                                   mejores_hiperparametros_GD,\n",
    "                                                   mejores_hiperparametros_tree,\n",
    "                                                   mejores_hiperparametros_ADA,\n",
    "                                                   mejores_hiperparametros_extra,\n",
    "                                                   mejores_hiperparametros_random,\n",
    "                                                   mejores_hiperparametros_BG,\n",
    "                                                   mejores_hiperparametros_XB):\n",
    "    X_trn_transformado = X_trn\n",
    "    semilla= 7 \n",
    "    kfold = StratifiedKFold(n_splits=10, random_state=semilla, shuffle=True)\n",
    "    modelo1 = GradientBoostingRegressor(**mejores_hiperparametros_GD)\n",
    "    base_estimator=DecisionTreeRegressor(**mejores_hiperparametros_tree)\n",
    "    modelo2 = AdaBoostRegressor(**mejores_hiperparametros_ADA)\n",
    "    modelo3 = ExtraTreesRegressor(**mejores_hiperparametros_extra)\n",
    "    modelo4 = RandomForestRegressor(**mejores_hiperparametros_random)\n",
    "    model = DecisionTreeRegressor(**mejores_hiperparametros_tree)\n",
    "    modelo5 = BaggingRegressor(**mejores_hiperparametros_BG)\n",
    "    modelo6 = DecisionTreeRegressor(**mejores_hiperparametros_tree)\n",
    "    modelo7 = XGBRegressor(**mejores_hiperparametros_XB)\n",
    "    metrica ='neg_mean_squared_error'\n",
    "    mejor_modelo = VotingRegressor(\n",
    "    estimators=[('Gradient', modelo1), ('Adaboost', modelo2), \n",
    "                                    ('Extratrees', modelo3),('Random Forest',modelo4),\n",
    "                                    ('Bagging',modelo5),('Decision tree',modelo6),\n",
    "                                    ('XGB',modelo7)]) \n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    resultados = cross_val_score(mejor_modelo, X_trn_transformado, Y_trn, \n",
    "                                    cv=kfold,scoring = metrica)\n",
    "    mejores_hiperparametros_voting=mejor_modelo.get_params\n",
    "\n",
    "    return mejor_modelo, mejores_hiperparametros_voting\n",
    "modelo_voting, mejores_hiperparametros_voting= entrenar_modelo_voting_con_transformacion(X_trn, Y_trn,\n",
    "                                                   mejores_hiperparametros_GD,\n",
    "                                                   mejores_hiperparametros_tree,\n",
    "                                                   mejores_hiperparametros_ADA,\n",
    "                                                   mejores_hiperparametros_extra,\n",
    "                                                   mejores_hiperparametros_random,\n",
    "                                                   mejores_hiperparametros_BG,\n",
    "                                                   mejores_hiperparametros_XB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01028973158339097"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_voting.predict(X_tst)\n",
    "r2_voting = r2_score(Y_tst, Y_pred_prueba)\n",
    "r2_voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STACKING LINEAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_modelo_stacking_lineal_con_transformacion(X_trn, Y_trn,\n",
    "                                                   mejores_hiperparametros_tree,\n",
    "                                                   mejores_hiperparametros_ADA,\n",
    "                                                   mejores_hiperparametros_extra,\n",
    "                                                   mejores_hiperparametros_random,\n",
    "                                                   mejores_hiperparametros_BG):\n",
    "    X_trn_transformado = X_trn\n",
    "    semilla= 7 \n",
    "    kfold = StratifiedKFold(n_splits=10, random_state=semilla, shuffle=True)\n",
    "    base_estimator=DecisionTreeRegressor(**mejores_hiperparametros_tree)\n",
    "    modelo2 = AdaBoostRegressor(**mejores_hiperparametros_ADA)\n",
    "    modelo3 = ExtraTreesRegressor(**mejores_hiperparametros_extra)\n",
    "    modelo4 = RandomForestRegressor (**mejores_hiperparametros_random)\n",
    "    model = DecisionTreeRegressor(**mejores_hiperparametros_tree)\n",
    "    modelo5 = BaggingRegressor(**mejores_hiperparametros_BG)\n",
    "    modelo6 = DecisionTreeRegressor(**mejores_hiperparametros_tree)\n",
    "    estimador_final = LinearRegression()\n",
    "    metrica ='neg_mean_squared_error'\n",
    "    mejor_modelo = StackingRegressor(\n",
    "    estimators=[ ('Adaboost', modelo2), ('Extratrees', modelo3),\n",
    "                ('Random Forest',modelo4),\n",
    "                #('Bagging',modelo5)\n",
    "                ('Decision tree',modelo6)\n",
    "                ], \n",
    "                                    final_estimator=estimador_final) \n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    mejores_hiperparametros_stacking_lineal=mejor_modelo.get_params\n",
    "    resultados = cross_val_score(mejor_modelo, X_trn_transformado, Y_trn, cv=kfold,scoring = metrica)\n",
    "    return mejor_modelo,mejores_hiperparametros_stacking_lineal\n",
    "\n",
    "\n",
    "modelo_stacking_lineal,mejores_hiperparametros_stacking_lineal = entrenar_modelo_stacking_lineal_con_transformacion(X_trn, Y_trn,\n",
    "                                                   mejores_hiperparametros_tree,\n",
    "                                                   mejores_hiperparametros_ADA,\n",
    "                                                   mejores_hiperparametros_extra,\n",
    "                                                   mejores_hiperparametros_random,\n",
    "                                                   mejores_hiperparametros_BG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013963711968497217"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_stacking_lineal.predict(X_tst)\n",
    "r2_stacking_lineal = r2_score(Y_tst, Y_pred_prueba)\n",
    "r2_stacking_lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STACKING NO LINEAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_modelo_stacking_nolineal_con_transformacion(X_trn, Y_trn,\n",
    "                                                   mejores_hiperparametros_tree,\n",
    "                                                   mejores_hiperparametros_ADA,\n",
    "                                                   mejores_hiperparametros_extra,\n",
    "                                                   mejores_hiperparametros_random,\n",
    "                                                   mejores_hiperparametros_BG):\n",
    "    X_trn_transformado = X_trn\n",
    "    semilla= 7 \n",
    "    kfold = StratifiedKFold(n_splits=10, random_state=semilla, shuffle=True)\n",
    "    base_estimator=DecisionTreeRegressor(**mejores_hiperparametros_tree)\n",
    "    modelo2 = AdaBoostRegressor(**mejores_hiperparametros_ADA)\n",
    "    modelo3 = ExtraTreesRegressor(**mejores_hiperparametros_extra)\n",
    "    modelo4 = RandomForestRegressor (**mejores_hiperparametros_random)\n",
    "    model = DecisionTreeRegressor(**mejores_hiperparametros_tree)\n",
    "    modelo5 = BaggingRegressor(**mejores_hiperparametros_BG)\n",
    "    modelo6 = DecisionTreeRegressor(**mejores_hiperparametros_tree)\n",
    "    estimador_final = ExtraTreesRegressor()\n",
    "    metrica ='neg_mean_squared_error'\n",
    "    mejor_modelo = StackingRegressor(\n",
    "    estimators=[ ('Adaboost', modelo2), ('Extratrees', modelo3),\n",
    "                ('Random Forest',modelo4),\n",
    "                #('Bagging',modelo5)\n",
    "                ('Decision tree',modelo6)\n",
    "                ], \n",
    "                                    final_estimator=estimador_final) \n",
    "    mejor_modelo.fit(X_trn_transformado, Y_trn)\n",
    "    mejores_hiperparametros_stacking_nolineal=mejor_modelo.get_params\n",
    "    resultados = cross_val_score(mejor_modelo, X_trn_transformado, Y_trn, cv=kfold,scoring = metrica)\n",
    "    return mejor_modelo,mejores_hiperparametros_stacking_nolineal\n",
    "\n",
    "\n",
    "modelo_stacking_nolineal,mejores_hiperparametros_stacking_nolineal = entrenar_modelo_stacking_nolineal_con_transformacion(X_trn, Y_trn,\n",
    "                                                   mejores_hiperparametros_tree,\n",
    "                                                   mejores_hiperparametros_ADA,\n",
    "                                                   mejores_hiperparametros_extra,\n",
    "                                                   mejores_hiperparametros_random,\n",
    "                                                   mejores_hiperparametros_BG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.43038208473497086"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_stacking_nolineal.predict(X_tst)\n",
    "r2_stacking_nolineal = r2_score(Y_tst, Y_pred_prueba)\n",
    "r2_stacking_nolineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUPER APRENDIZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting 2 layers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing layer-1             done | 00:00:07\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:07\n",
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             done | 00:00:05\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:06\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             done | 00:00:06\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:06\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             done | 00:00:05\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:06\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             done | 00:00:05\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:05\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             done | 00:00:05\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:05\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             done | 00:00:05\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:06\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             done | 00:00:05\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:05\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             done | 00:00:06\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:06\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             done | 00:00:05\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:06\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             done | 00:00:05\n",
      "Processing layer-2             done | 00:00:00\n",
      "Fit complete                        | 00:00:06\n",
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "Rendimiento del modelo:\n"
     ]
    }
   ],
   "source": [
    "Y_trn = Y_trn.astype(int)\n",
    "def entrenar_modelo_super_aprendiz(X_trn, Y_trn, mejores_hiperparametros_GD,\n",
    "                            mejores_hiperparametros_tree,mejores_hiperparametros_extra,\n",
    "                            mejores_hiperparametros_random):\n",
    "    X_trn_transformado = X_trn\n",
    "    semilla = 7 \n",
    "    kfold = StratifiedKFold(n_splits=10, random_state=semilla, shuffle=True)\n",
    "    modelo1 = ExtraTreesRegressor(**mejores_hiperparametros_extra)\n",
    "    modelo2 = RandomForestRegressor(**mejores_hiperparametros_random)\n",
    "    model = DecisionTreeRegressor(**mejores_hiperparametros_tree)\n",
    "    #modelo3 = BaggingRegressor(**mejores_hiperparametros_BG)\n",
    "    modelo4 = DecisionTreeRegressor(**mejores_hiperparametros_tree)\n",
    "    modelo5 = GradientBoostingRegressor(**mejores_hiperparametros_GD) \n",
    "    estimadores = [('Extratrees', modelo1), \n",
    "                   ('Random Forest', modelo2), \n",
    "                #('Bagging', modelo3), \n",
    "                ('Decision tree', modelo4),\n",
    "                ('Gradient',modelo5)]\n",
    "    super_learner = SuperLearner(folds=10, random_state=semilla, verbose=2)\n",
    "    super_learner.add(estimadores)\n",
    "    estimador_final = ExtraTreesRegressor(n_estimators=100, max_features=None,\n",
    "                                        bootstrap=False, max_depth=11, min_samples_split=4, \n",
    "                                        min_samples_leaf=1)\n",
    "    super_learner.add_meta(estimador_final)\n",
    "    super_learner.fit(X_trn_transformado, Y_trn)\n",
    "    mejores_hiperparametros_super_learner=super_learner.get_params\n",
    "    resultados = cross_val_score(super_learner, X_trn_transformado, Y_trn, cv=kfold, scoring='neg_mean_squared_error')\n",
    "    print(\"Rendimiento del modelo:\") \n",
    "    return super_learner,mejores_hiperparametros_super_learner,estimadores\n",
    "modelo_superaprendiz,mejores_hiperparametros_super_learner,estimadores = entrenar_modelo_super_aprendiz(X_trn, Y_trn, mejores_hiperparametros_GD,\n",
    "                            mejores_hiperparametros_tree,mejores_hiperparametros_extra,\n",
    "                            mejores_hiperparametros_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.00037767922630038697"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_superaprendiz.predict(X_tst)\n",
    "r2_superaprendiz = r2_score(Y_tst, Y_pred_prueba)\n",
    "r2_superaprendiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUPER APRENDIZ DOS CAPAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting 3 layers\n",
      "Processing layer-1             done | 00:00:06\n",
      "Processing layer-2             done | 00:00:04\n",
      "Processing layer-3             done | 00:00:00\n",
      "Fit complete                        | 00:00:11\n",
      "\n",
      "Fitting 3 layers\n",
      "Processing layer-1             done | 00:00:05\n",
      "Processing layer-2             done | 00:00:03\n",
      "Processing layer-3             done | 00:00:00\n",
      "Fit complete                        | 00:00:09\n",
      "\n",
      "Predicting 3 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Processing layer-3             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 3 layers\n",
      "Processing layer-1             done | 00:00:05\n",
      "Processing layer-2             done | 00:00:03\n",
      "Processing layer-3             done | 00:00:00\n",
      "Fit complete                        | 00:00:09\n",
      "\n",
      "Predicting 3 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Processing layer-3             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 3 layers\n",
      "Processing layer-1             done | 00:00:05\n",
      "Processing layer-2             done | 00:00:03\n",
      "Processing layer-3             done | 00:00:00\n",
      "Fit complete                        | 00:00:09\n",
      "\n",
      "Predicting 3 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Processing layer-3             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 3 layers\n",
      "Processing layer-1             done | 00:00:05\n",
      "Processing layer-2             done | 00:00:03\n",
      "Processing layer-3             done | 00:00:00\n",
      "Fit complete                        | 00:00:08\n",
      "\n",
      "Predicting 3 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Processing layer-3             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 3 layers\n",
      "Processing layer-1             done | 00:00:05\n",
      "Processing layer-2             done | 00:00:03\n",
      "Processing layer-3             done | 00:00:00\n",
      "Fit complete                        | 00:00:09\n",
      "\n",
      "Predicting 3 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Processing layer-3             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 3 layers\n",
      "Processing layer-1             done | 00:00:05\n",
      "Processing layer-2             done | 00:00:03\n",
      "Processing layer-3             done | 00:00:00\n",
      "Fit complete                        | 00:00:09\n",
      "\n",
      "Predicting 3 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Processing layer-3             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 3 layers\n",
      "Processing layer-1             done | 00:00:05\n",
      "Processing layer-2             done | 00:00:03\n",
      "Processing layer-3             done | 00:00:00\n",
      "Fit complete                        | 00:00:09\n",
      "\n",
      "Predicting 3 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Processing layer-3             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 3 layers\n",
      "Processing layer-1             done | 00:00:06\n",
      "Processing layer-2             done | 00:00:03\n",
      "Processing layer-3             done | 00:00:00\n",
      "Fit complete                        | 00:00:10\n",
      "\n",
      "Predicting 3 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Processing layer-3             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 3 layers\n",
      "Processing layer-1             done | 00:00:05\n",
      "Processing layer-2             done | 00:00:03\n",
      "Processing layer-3             done | 00:00:00\n",
      "Fit complete                        | 00:00:09\n",
      "\n",
      "Predicting 3 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Processing layer-3             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n",
      "\n",
      "Fitting 3 layers\n",
      "Processing layer-1             done | 00:00:05\n",
      "Processing layer-2             done | 00:00:03\n",
      "Processing layer-3             done | 00:00:00\n",
      "Fit complete                        | 00:00:09\n",
      "\n",
      "Predicting 3 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Processing layer-3             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n"
     ]
    }
   ],
   "source": [
    "def entrenar_modelo_super_aprendiz_dos_capas(X_trn, Y_trn, mejores_hiperparametros_tree,\n",
    "                                            mejores_hiperparametros_extra,mejores_hiperparametros_random):\n",
    "    X_trn_transformado = X_trn\n",
    "    semilla = 7 \n",
    "    kfold = StratifiedKFold(n_splits=10, random_state=semilla, shuffle=True)\n",
    "    modelo1 = ExtraTreesRegressor(**mejores_hiperparametros_extra)\n",
    "    modelo2 = RandomForestRegressor(**mejores_hiperparametros_random)\n",
    "    model = DecisionTreeRegressor(**mejores_hiperparametros_tree)\n",
    "    #modelo3 = BaggingRegressor(**mejores_hiperparametros_BG)\n",
    "    modelo4 = DecisionTreeRegressor(**mejores_hiperparametros_tree)\n",
    "    estimadores = [('Extratrees', modelo1), \n",
    "                   ('Random Forest', modelo2), \n",
    "                #('Bagging', modelo3), \n",
    "                ('Decision tree', modelo4)]\n",
    "    superaprendiz_dos_capas = SuperLearner(folds=10, random_state=semilla, verbose=2)\n",
    "    superaprendiz_dos_capas.add(estimadores)\n",
    "    superaprendiz_dos_capas.add(estimadores)\n",
    "    estimador_final = ExtraTreesRegressor(n_estimators=100, max_features=None,\n",
    "                                        bootstrap=False, max_depth=11, min_samples_split=4, \n",
    "                                        min_samples_leaf=1)\n",
    "    superaprendiz_dos_capas.add_meta(estimador_final)\n",
    "    \n",
    "    superaprendiz_dos_capas.fit(X_trn_transformado, Y_trn)\n",
    "    mejores_hiperparametros_superaprendiz_dos_capas=superaprendiz_dos_capas.get_params\n",
    "    resultados = cross_val_score(superaprendiz_dos_capas, X_trn_transformado, Y_trn, cv=kfold, scoring='neg_mean_squared_error')\n",
    "    return superaprendiz_dos_capas,mejores_hiperparametros_superaprendiz_dos_capas,estimadores\n",
    "modelo_superaprendiz_dos_capas,mejores_hiperparametros_superaprendiz_dos_capas,estimadores = entrenar_modelo_super_aprendiz_dos_capas(X_trn, Y_trn, mejores_hiperparametros_tree,\n",
    "                                            mejores_hiperparametros_extra,mejores_hiperparametros_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting 3 layers\n",
      "Processing layer-1             done | 00:00:00\n",
      "Processing layer-2             done | 00:00:00\n",
      "Processing layer-3             done | 00:00:00\n",
      "Predict complete                    | 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.006147064831972582"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_prueba = modelo_superaprendiz_dos_capas.predict(X_tst)\n",
    "r2_superaprendiz_dos_capas = r2_score(Y_tst, Y_pred_prueba)\n",
    "r2_superaprendiz_dos_capas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo: GRADIENTBOOST\n",
      "R^2 en prueba: 0.014136152556050607\n"
     ]
    }
   ],
   "source": [
    "exactitudes = {\n",
    "    'KNEIGHBORSCLASSIFIER': r2_knn,\n",
    "    'SVC': r2_svc,\n",
    "    'DECISION TREE': r2_tree,\n",
    "    'NAIVE BAYES':r2_gaussian,\n",
    "    'LDA':r2_LDA,\n",
    "    'BAGGING':r2_BG,\n",
    "    'RANDOM FOREST':r2_random,\n",
    "    'EXTRATREES':r2_extra,\n",
    "    'ADABOOST':r2_ADA,\n",
    "    'GRADIENTBOOST': r2_GD,\n",
    "    'XGBOOST':r2_XB,\n",
    "    'CATBOOST':r2_CB,\n",
    "    'LIGHT':r2_LIGHT,\n",
    "    'VOTING':r2_voting,\n",
    "    'STACKING LINEAL':r2_stacking_lineal,\n",
    "    'STACKING NO LINEAL':r2_stacking_nolineal,\n",
    "    'SUPER APRENDIZ':r2_superaprendiz,\n",
    "    'SUPER APRENDIZ DOS CAPAS':r2_superaprendiz_dos_capas\n",
    "}\n",
    "mejor_modelo = max(exactitudes, key=exactitudes.get)\n",
    "mejor_r2 = exactitudes[mejor_modelo]\n",
    "\n",
    "print(\"Mejor modelo:\", mejor_modelo)\n",
    "print(\"R^2 en prueba:\", mejor_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELECCIÓN DE MODELOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos_entrenados = {\n",
    "    'KNEIGHBORSCLASSIFIER': modelo_knn,\n",
    "    'SVC': modelo_svc,\n",
    "    'DECISION TREE': modelo_tree,\n",
    "    'NAIVE BAYES': modelo_gaussian,\n",
    "    'LDA': modelo_LDA,\n",
    "    'BAGGING': modelo_BG,\n",
    "    'RANDOM FOREST':modelo_random,\n",
    "    'EXTRATREE': modelo_extra,\n",
    "    'ADA': modelo_ADA,\n",
    "    'GRADIENTBOOST': modelo_GD,\n",
    "    'XGBOOST':modelo_XB,\n",
    "    'CATBOOST':modelo_CB,\n",
    "    'LIGHT':modelo_LIGHT,\n",
    "    'VOTING':modelo_voting,\n",
    "    'STACKING LINEAL':modelo_stacking_lineal,\n",
    "    'STACKING NO LINEAL':modelo_stacking_nolineal,\n",
    "    'SUPER APRENDIZ':modelo_superaprendiz,\n",
    "    'SUPER APRENDIZ DOS CAPAS':modelo_superaprendiz_dos_capas\n",
    "}\n",
    "mejor_modelo = max(exactitudes, key=exactitudes.get)\n",
    "modelo_seleccionado = modelos_entrenados.get(mejor_modelo)\n",
    "if modelo_seleccionado is not None:\n",
    "    predicciones_nuevos_datos = modelo_seleccionado.predict(Xpandas_T_JOHNSON2)\n",
    "else:\n",
    "    print(\"El modelo seleccionado no está disponible.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PG_ICFES</th>\n",
       "      <th>CON_MAT_ICFES</th>\n",
       "      <th>FISICA_ICFES</th>\n",
       "      <th>QUIMICA_ICFES</th>\n",
       "      <th>IDIOMA_ICFES</th>\n",
       "      <th>LOCALIDAD</th>\n",
       "      <th>PROMEDIO_UNO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>419</td>\n",
       "      <td>65</td>\n",
       "      <td>60</td>\n",
       "      <td>66</td>\n",
       "      <td>75</td>\n",
       "      <td>20</td>\n",
       "      <td>29.534502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>425</td>\n",
       "      <td>72</td>\n",
       "      <td>65</td>\n",
       "      <td>55</td>\n",
       "      <td>65</td>\n",
       "      <td>15</td>\n",
       "      <td>29.534502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>425</td>\n",
       "      <td>76</td>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>28.898325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>454</td>\n",
       "      <td>79</td>\n",
       "      <td>62</td>\n",
       "      <td>65</td>\n",
       "      <td>83</td>\n",
       "      <td>10</td>\n",
       "      <td>28.925402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>523</td>\n",
       "      <td>99</td>\n",
       "      <td>69</td>\n",
       "      <td>78</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>29.838975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>451</td>\n",
       "      <td>67</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>83</td>\n",
       "      <td>11</td>\n",
       "      <td>28.925402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>437</td>\n",
       "      <td>74</td>\n",
       "      <td>62</td>\n",
       "      <td>57</td>\n",
       "      <td>56</td>\n",
       "      <td>19</td>\n",
       "      <td>29.534502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>429</td>\n",
       "      <td>77</td>\n",
       "      <td>62</td>\n",
       "      <td>59</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>29.534502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>429</td>\n",
       "      <td>90</td>\n",
       "      <td>52</td>\n",
       "      <td>58</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>28.898325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>439</td>\n",
       "      <td>77</td>\n",
       "      <td>61</td>\n",
       "      <td>56</td>\n",
       "      <td>57</td>\n",
       "      <td>11</td>\n",
       "      <td>29.534502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PG_ICFES  CON_MAT_ICFES  FISICA_ICFES  QUIMICA_ICFES  IDIOMA_ICFES  \\\n",
       "0         419             65            60             66            75   \n",
       "1         425             72            65             55            65   \n",
       "2         425             76            60             59            50   \n",
       "3         454             79            62             65            83   \n",
       "4         523             99            69             78            60   \n",
       "..        ...            ...           ...            ...           ...   \n",
       "324       451             67            64             65            83   \n",
       "325       437             74            62             57            56   \n",
       "326       429             77            62             59            68   \n",
       "327       429             90            52             58            50   \n",
       "328       439             77            61             56            57   \n",
       "\n",
       "     LOCALIDAD  PROMEDIO_UNO  \n",
       "0           20     29.534502  \n",
       "1           15     29.534502  \n",
       "2            9     28.898325  \n",
       "3           10     28.925402  \n",
       "4            1     29.838975  \n",
       "..         ...           ...  \n",
       "324         11     28.925402  \n",
       "325         19     29.534502  \n",
       "326          8     29.534502  \n",
       "327          8     28.898325  \n",
       "328         11     29.534502  \n",
       "\n",
       "[329 rows x 7 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prediccion[f'PROMEDIO_{semestre_en_letras.upper()}']=predicciones_nuevos_datos\n",
    "df_prediccion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
